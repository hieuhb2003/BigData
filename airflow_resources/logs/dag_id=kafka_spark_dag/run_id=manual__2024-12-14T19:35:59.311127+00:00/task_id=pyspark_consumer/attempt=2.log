[2024-12-14T19:39:48.834+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: kafka_spark_dag.pyspark_consumer manual__2024-12-14T19:35:59.311127+00:00 [queued]>
[2024-12-14T19:39:48.858+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: kafka_spark_dag.pyspark_consumer manual__2024-12-14T19:35:59.311127+00:00 [queued]>
[2024-12-14T19:39:48.859+0000] {taskinstance.py:1361} INFO - Starting attempt 2 of 2
[2024-12-14T19:39:48.885+0000] {taskinstance.py:1382} INFO - Executing <Task(DockerOperator): pyspark_consumer> on 2024-12-14 19:35:59.311127+00:00
[2024-12-14T19:39:48.894+0000] {standard_task_runner.py:57} INFO - Started process 2515 to run task
[2024-12-14T19:39:48.902+0000] {standard_task_runner.py:84} INFO - Running: ['airflow', 'tasks', 'run', 'kafka_spark_dag', 'pyspark_consumer', 'manual__2024-12-14T19:35:59.311127+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/dag_kafka_spark.py', '--cfg-path', '/tmp/tmp4royw1ma']
[2024-12-14T19:39:48.907+0000] {standard_task_runner.py:85} INFO - Job 5: Subtask pyspark_consumer
[2024-12-14T19:39:49.044+0000] {task_command.py:416} INFO - Running <TaskInstance: kafka_spark_dag.pyspark_consumer manual__2024-12-14T19:35:59.311127+00:00 [running]> on host d74372a514c6
[2024-12-14T19:39:49.330+0000] {taskinstance.py:1662} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='kafka_spark_dag' AIRFLOW_CTX_TASK_ID='pyspark_consumer' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T19:35:59.311127+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T19:35:59.311127+00:00'
[2024-12-14T19:39:49.655+0000] {docker.py:343} INFO - Starting docker container from image reddit-consumer/spark:latest
[2024-12-14T19:39:49.722+0000] {docker.py:351} WARNING - Using remote engine or docker-in-docker and mounting temporary volume from host is not supported. Falling back to `mount_tmp_dir=False` mode. You can set `mount_tmp_dir` parameter to False to disable mounting and remove the warning
[2024-12-14T19:39:50.505+0000] {docker.py:413} INFO - [38;5;6mspark [38;5;5m19:39:50.49 [0m[38;5;2mINFO [0m ==>
[2024-12-14T19:39:50.514+0000] {docker.py:413} INFO - [38;5;6mspark [38;5;5m19:39:50.50 [0m[38;5;2mINFO [0m ==> [1mWelcome to the Bitnami spark container[0m
[2024-12-14T19:39:50.524+0000] {docker.py:413} INFO - [38;5;6mspark [38;5;5m19:39:50.51 [0m[38;5;2mINFO [0m ==> Subscribe to project updates by watching [1mhttps://github.com/bitnami/containers[0m
[2024-12-14T19:39:50.535+0000] {docker.py:413} INFO - [38;5;6mspark [38;5;5m19:39:50.52 [0m[38;5;2mINFO [0m ==> Submit issues and feature requests at [1mhttps://github.com/bitnami/containers/issues[0m
[2024-12-14T19:39:50.547+0000] {docker.py:413} INFO - [38;5;6mspark [38;5;5m19:39:50.53 [0m[38;5;2mINFO [0m ==>
[2024-12-14T19:39:50.565+0000] {docker.py:413} INFO - 
[2024-12-14T19:39:55.145+0000] {docker.py:413} INFO - :: loading settings :: url = jar:file:/opt/bitnami/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
[2024-12-14T19:39:55.386+0000] {docker.py:413} INFO - Ivy Default Cache set to: /root/.ivy2/cache
The jars for the packages stored in: /root/.ivy2/jars
[2024-12-14T19:39:55.397+0000] {docker.py:413} INFO - org.***ql#***ql added as a dependency
org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
[2024-12-14T19:39:55.400+0000] {docker.py:413} INFO - :: resolving dependencies :: org.apache.spark#spark-submit-parent-6358f99f-9c0f-40bc-9a96-278c0001f6c1;1.0
	confs: [default]
[2024-12-14T19:39:58.084+0000] {docker.py:413} INFO - found org.***ql#***ql;42.5.4 in central
[2024-12-14T19:39:58.567+0000] {docker.py:413} INFO - found org.checkerframework#checker-qual;3.5.0 in central
[2024-12-14T19:40:03.079+0000] {docker.py:413} INFO - found org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0 in central
[2024-12-14T19:40:04.064+0000] {docker.py:413} INFO - found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0 in central
[2024-12-14T19:40:04.570+0000] {docker.py:413} INFO - found org.apache.kafka#kafka-clients;3.4.1 in central
[2024-12-14T19:40:05.099+0000] {docker.py:413} INFO - found org.lz4#lz4-java;1.8.0 in central
[2024-12-14T19:40:05.639+0000] {docker.py:413} INFO - found org.xerial.snappy#snappy-java;1.1.10.3 in central
[2024-12-14T19:40:07.357+0000] {docker.py:413} INFO - found org.slf4j#slf4j-api;2.0.7 in central
[2024-12-14T19:40:10.552+0000] {docker.py:413} INFO - found org.apache.hadoop#hadoop-client-runtime;3.3.4 in central
[2024-12-14T19:40:11.099+0000] {docker.py:413} INFO - found org.apache.hadoop#hadoop-client-api;3.3.4 in central
[2024-12-14T19:40:13.179+0000] {docker.py:413} INFO - found commons-logging#commons-logging;1.1.3 in central
[2024-12-14T19:40:13.684+0000] {docker.py:413} INFO - found com.google.code.findbugs#jsr305;3.0.0 in central
[2024-12-14T19:40:16.974+0000] {docker.py:413} INFO - found org.apache.commons#commons-pool2;2.11.1 in central
[2024-12-14T19:40:17.270+0000] {docker.py:413} INFO - downloading https://repo1.maven.org/maven2/org/***ql/***ql/42.5.4/***ql-42.5.4.jar ...
[2024-12-14T19:40:18.755+0000] {docker.py:413} INFO - [SUCCESSFUL ] org.***ql#***ql;42.5.4!***ql.jar (1756ms)
[2024-12-14T19:40:19.011+0000] {docker.py:413} INFO - downloading https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.12/3.5.0/spark-sql-kafka-0-10_2.12-3.5.0.jar ...
[2024-12-14T19:40:19.780+0000] {docker.py:413} INFO - [SUCCESSFUL ] org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0!spark-sql-kafka-0-10_2.12.jar (1018ms)
[2024-12-14T19:40:20.043+0000] {docker.py:413} INFO - downloading https://repo1.maven.org/maven2/org/checkerframework/checker-qual/3.5.0/checker-qual-3.5.0.jar ...
[2024-12-14T19:40:20.517+0000] {docker.py:413} INFO - [SUCCESSFUL ] org.checkerframework#checker-qual;3.5.0!checker-qual.jar (736ms)
[2024-12-14T19:40:20.751+0000] {docker.py:413} INFO - downloading https://repo1.maven.org/maven2/org/apache/spark/spark-token-provider-kafka-0-10_2.12/3.5.0/spark-token-provider-kafka-0-10_2.12-3.5.0.jar ...
[2024-12-14T19:40:20.983+0000] {docker.py:413} INFO - [SUCCESSFUL ] org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0!spark-token-provider-kafka-0-10_2.12.jar (462ms)
[2024-12-14T19:40:21.265+0000] {docker.py:413} INFO - downloading https://repo1.maven.org/maven2/org/apache/kafka/kafka-clients/3.4.1/kafka-clients-3.4.1.jar ...
[2024-12-14T19:40:29.311+0000] {docker.py:413} INFO - [SUCCESSFUL ] org.apache.kafka#kafka-clients;3.4.1!kafka-clients.jar (8324ms)
[2024-12-14T19:40:29.563+0000] {docker.py:413} INFO - downloading https://repo1.maven.org/maven2/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar ...
[2024-12-14T19:40:29.770+0000] {docker.py:413} INFO - [SUCCESSFUL ] com.google.code.findbugs#jsr305;3.0.0!jsr305.jar (456ms)
[2024-12-14T19:40:29.966+0000] {docker.py:413} INFO - downloading https://repo1.maven.org/maven2/org/apache/commons/commons-pool2/2.11.1/commons-pool2-2.11.1.jar ...
[2024-12-14T19:40:30.345+0000] {docker.py:413} INFO - [SUCCESSFUL ] org.apache.commons#commons-pool2;2.11.1!commons-pool2.jar (569ms)
[2024-12-14T19:40:30.518+0000] {docker.py:413} INFO - downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-client-runtime/3.3.4/hadoop-client-runtime-3.3.4.jar ...
[2024-12-14T19:40:47.401+0000] {docker.py:413} INFO - [SUCCESSFUL ] org.apache.hadoop#hadoop-client-runtime;3.3.4!hadoop-client-runtime.jar (17055ms)
[2024-12-14T19:40:47.680+0000] {docker.py:413} INFO - downloading https://repo1.maven.org/maven2/org/lz4/lz4-java/1.8.0/lz4-java-1.8.0.jar ...
[2024-12-14T19:40:49.121+0000] {docker.py:413} INFO - [SUCCESSFUL ] org.lz4#lz4-java;1.8.0!lz4-java.jar (1718ms)
[2024-12-14T19:40:49.318+0000] {docker.py:413} INFO - downloading https://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.1.10.3/snappy-java-1.1.10.3.jar ...
[2024-12-14T19:40:51.041+0000] {docker.py:413} INFO - [SUCCESSFUL ] org.xerial.snappy#snappy-java;1.1.10.3!snappy-java.jar(bundle) (1918ms)
[2024-12-14T19:40:51.267+0000] {docker.py:413} INFO - downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/2.0.7/slf4j-api-2.0.7.jar ...
[2024-12-14T19:40:53.111+0000] {docker.py:413} INFO - [SUCCESSFUL ] org.slf4j#slf4j-api;2.0.7!slf4j-api.jar (2069ms)
[2024-12-14T19:40:53.315+0000] {docker.py:413} INFO - downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-client-api/3.3.4/hadoop-client-api-3.3.4.jar ...
[2024-12-14T19:40:57.568+0000] {docker.py:413} INFO - [SUCCESSFUL ] org.apache.hadoop#hadoop-client-api;3.3.4!hadoop-client-api.jar (4455ms)
[2024-12-14T19:40:57.819+0000] {docker.py:413} INFO - downloading https://repo1.maven.org/maven2/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar ...
[2024-12-14T19:40:59.680+0000] {docker.py:413} INFO - [SUCCESSFUL ] commons-logging#commons-logging;1.1.3!commons-logging.jar (2100ms)
[2024-12-14T19:40:59.684+0000] {docker.py:413} INFO - :: resolution report :: resolve 21598ms :: artifacts dl 42674ms
	:: modules in use:
[2024-12-14T19:40:59.688+0000] {docker.py:413} INFO - com.google.code.findbugs#jsr305;3.0.0 from central in [default]
	commons-logging#commons-logging;1.1.3 from central in [default]
	org.apache.commons#commons-pool2;2.11.1 from central in [default]
	org.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]
	org.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]
	org.apache.kafka#kafka-clients;3.4.1 from central in [default]
	org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0 from central in [default]
	org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0 from central in [default]
	org.checkerframework#checker-qual;3.5.0 from central in [default]
	org.lz4#lz4-java;1.8.0 from central in [default]
	org.***ql#***ql;42.5.4 from central in [default]
	org.slf4j#slf4j-api;2.0.7 from central in [default]
	org.xerial.snappy#snappy-java;1.1.10.3 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
[2024-12-14T19:40:59.694+0000] {docker.py:413} INFO - |      default     |   13  |   13  |   13  |   0   ||   13  |   13  |
	---------------------------------------------------------------------
[2024-12-14T19:40:59.712+0000] {docker.py:413} INFO - :: retrieving :: org.apache.spark#spark-submit-parent-6358f99f-9c0f-40bc-9a96-278c0001f6c1
[2024-12-14T19:40:59.716+0000] {docker.py:413} INFO - confs: [default]
[2024-12-14T19:40:59.921+0000] {docker.py:413} INFO - 13 artifacts copied, 0 already retrieved (58001kB/207ms)
[2024-12-14T19:41:00.435+0000] {docker.py:413} INFO - 24/12/14 19:41:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2024-12-14T19:41:04.688+0000] {docker.py:413} INFO - 2024-12-14 19:41:04,685 [INFO] Starting Spark Streaming job
2024-12-14 19:41:04,685 [INFO] Starting stream processing...
2024-12-14 19:41:04,685 [INFO] Creating Spark session...
[2024-12-14T19:41:04.898+0000] {docker.py:413} INFO - 24/12/14 19:41:04 INFO SparkContext: Running Spark version 3.5.0
[2024-12-14T19:41:04.900+0000] {docker.py:413} INFO - 24/12/14 19:41:04 INFO SparkContext: OS info Linux, 6.10.11-linuxkit, amd64
[2024-12-14T19:41:04.901+0000] {docker.py:413} INFO - 24/12/14 19:41:04 INFO SparkContext: Java version 17.0.10
[2024-12-14T19:41:04.964+0000] {docker.py:413} INFO - 24/12/14 19:41:04 INFO ResourceUtils: ==============================================================
[2024-12-14T19:41:04.966+0000] {docker.py:413} INFO - 24/12/14 19:41:04 INFO ResourceUtils: No custom resources configured for spark.driver.
[2024-12-14T19:41:04.968+0000] {docker.py:413} INFO - 24/12/14 19:41:04 INFO ResourceUtils: ==============================================================
[2024-12-14T19:41:04.969+0000] {docker.py:413} INFO - 24/12/14 19:41:04 INFO SparkContext: Submitted application: RedditSoccerAnalysis
[2024-12-14T19:41:05.022+0000] {docker.py:413} INFO - 24/12/14 19:41:05 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2024-12-14T19:41:05.039+0000] {docker.py:413} INFO - 24/12/14 19:41:05 INFO ResourceProfile: Limiting resource is cpu
[2024-12-14T19:41:05.040+0000] {docker.py:413} INFO - 24/12/14 19:41:05 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2024-12-14T19:41:05.142+0000] {docker.py:413} INFO - 24/12/14 19:41:05 INFO SecurityManager: Changing view acls to: root,spark
[2024-12-14T19:41:05.143+0000] {docker.py:413} INFO - 24/12/14 19:41:05 INFO SecurityManager: Changing modify acls to: root,spark
[2024-12-14T19:41:05.144+0000] {docker.py:413} INFO - 24/12/14 19:41:05 INFO SecurityManager: Changing view acls groups to:
[2024-12-14T19:41:05.145+0000] {docker.py:413} INFO - 24/12/14 19:41:05 INFO SecurityManager: Changing modify acls groups to:
[2024-12-14T19:41:05.146+0000] {docker.py:413} INFO - 24/12/14 19:41:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
[2024-12-14T19:41:05.588+0000] {docker.py:413} INFO - 24/12/14 19:41:05 INFO Utils: Successfully started service 'sparkDriver' on port 45995.
[2024-12-14T19:41:05.642+0000] {docker.py:413} INFO - 24/12/14 19:41:05 INFO SparkEnv: Registering MapOutputTracker
[2024-12-14T19:41:05.700+0000] {docker.py:413} INFO - 24/12/14 19:41:05 INFO SparkEnv: Registering BlockManagerMaster
[2024-12-14T19:41:05.742+0000] {docker.py:413} INFO - 24/12/14 19:41:05 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2024-12-14T19:41:05.743+0000] {docker.py:413} INFO - 24/12/14 19:41:05 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2024-12-14T19:41:05.751+0000] {docker.py:413} INFO - 24/12/14 19:41:05 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2024-12-14T19:41:05.784+0000] {docker.py:413} INFO - 24/12/14 19:41:05 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9ba13208-e2e0-45d4-955a-2da5eb38213b
[2024-12-14T19:41:05.807+0000] {docker.py:413} INFO - 24/12/14 19:41:05 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2024-12-14T19:41:05.834+0000] {docker.py:413} INFO - 24/12/14 19:41:05 INFO SparkEnv: Registering OutputCommitCoordinator
[2024-12-14T19:41:06.012+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2024-12-14T19:41:06.127+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2024-12-14T19:41:06.213+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.***ql_***ql-42.5.4.jar at spark://localhost:45995/jars/org.***ql_***ql-42.5.4.jar with timestamp 1734205264874
[2024-12-14T19:41:06.215+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar at spark://localhost:45995/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar with timestamp 1734205264874
[2024-12-14T19:41:06.216+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.checkerframework_checker-qual-3.5.0.jar at spark://localhost:45995/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1734205264874
[2024-12-14T19:41:06.217+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar at spark://localhost:45995/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar with timestamp 1734205264874
[2024-12-14T19:41:06.218+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar at spark://localhost:45995/jars/org.apache.kafka_kafka-clients-3.4.1.jar with timestamp 1734205264874
[2024-12-14T19:41:06.219+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://localhost:45995/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1734205264874
[2024-12-14T19:41:06.220+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar at spark://localhost:45995/jars/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1734205264874
[2024-12-14T19:41:06.221+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar at spark://localhost:45995/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1734205264874
[2024-12-14T19:41:06.222+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar at spark://localhost:45995/jars/org.lz4_lz4-java-1.8.0.jar with timestamp 1734205264874
[2024-12-14T19:41:06.223+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar at spark://localhost:45995/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1734205264874
[2024-12-14T19:41:06.224+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar at spark://localhost:45995/jars/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1734205264874
[2024-12-14T19:41:06.225+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar at spark://localhost:45995/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1734205264874
[2024-12-14T19:41:06.225+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO SparkContext: Added JAR file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at spark://localhost:45995/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1734205264874
[2024-12-14T19:41:06.230+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO SparkContext: Added file file:///root/.ivy2/jars/org.***ql_***ql-42.5.4.jar at file:///root/.ivy2/jars/org.***ql_***ql-42.5.4.jar with timestamp 1734205264874
[2024-12-14T19:41:06.235+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Utils: Copying /root/.ivy2/jars/org.***ql_***ql-42.5.4.jar to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.***ql_***ql-42.5.4.jar
[2024-12-14T19:41:06.259+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar at file:///root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar with timestamp 1734205264874
[2024-12-14T19:41:06.260+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Utils: Copying /root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar
[2024-12-14T19:41:06.264+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO SparkContext: Added file file:///root/.ivy2/jars/org.checkerframework_checker-qual-3.5.0.jar at file:///root/.ivy2/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1734205264874
[2024-12-14T19:41:06.266+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Utils: Copying /root/.ivy2/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.checkerframework_checker-qual-3.5.0.jar
[2024-12-14T19:41:06.272+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar at file:///root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar with timestamp 1734205264874
[2024-12-14T19:41:06.278+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Utils: Copying /root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar
[2024-12-14T19:41:06.280+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar at file:///root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar with timestamp 1734205264874
[2024-12-14T19:41:06.285+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Utils: Copying /root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.apache.kafka_kafka-clients-3.4.1.jar
[2024-12-14T19:41:06.294+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO SparkContext: Added file file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1734205264874
[2024-12-14T19:41:06.295+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Utils: Copying /root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/com.google.code.findbugs_jsr305-3.0.0.jar
[2024-12-14T19:41:06.302+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar at file:///root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1734205264874
[2024-12-14T19:41:06.304+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Utils: Copying /root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.apache.commons_commons-pool2-2.11.1.jar
[2024-12-14T19:41:06.312+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar at file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1734205264874
[2024-12-14T19:41:06.314+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Utils: Copying /root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar
[2024-12-14T19:41:06.351+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO SparkContext: Added file file:///root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar at file:///root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar with timestamp 1734205264874
[2024-12-14T19:41:06.352+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Utils: Copying /root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.lz4_lz4-java-1.8.0.jar
[2024-12-14T19:41:06.357+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO SparkContext: Added file file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar at file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1734205264874
[2024-12-14T19:41:06.359+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Utils: Copying /root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.xerial.snappy_snappy-java-1.1.10.3.jar
[2024-12-14T19:41:06.366+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO SparkContext: Added file file:///root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar at file:///root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1734205264874
[2024-12-14T19:41:06.368+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Utils: Copying /root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.slf4j_slf4j-api-2.0.7.jar
[2024-12-14T19:41:06.372+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar at file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1734205264874
[2024-12-14T19:41:06.374+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Utils: Copying /root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.apache.hadoop_hadoop-client-api-3.3.4.jar
[2024-12-14T19:41:06.397+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO SparkContext: Added file file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1734205264874
[2024-12-14T19:41:06.398+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Utils: Copying /root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/commons-logging_commons-logging-1.1.3.jar
[2024-12-14T19:41:06.506+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Executor: Starting executor ID driver on host localhost
[2024-12-14T19:41:06.507+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Executor: OS info Linux, 6.10.11-linuxkit, amd64
[2024-12-14T19:41:06.509+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Executor: Java version 17.0.10
[2024-12-14T19:41:06.525+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2024-12-14T19:41:06.527+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@505cfa73 for default.
[2024-12-14T19:41:06.552+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar with timestamp 1734205264874
[2024-12-14T19:41:06.580+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Utils: /root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar has been previously copied to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar
[2024-12-14T19:41:06.584+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Executor: Fetching file:///root/.ivy2/jars/org.***ql_***ql-42.5.4.jar with timestamp 1734205264874
[2024-12-14T19:41:06.587+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Utils: /root/.ivy2/jars/org.***ql_***ql-42.5.4.jar has been previously copied to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.***ql_***ql-42.5.4.jar
[2024-12-14T19:41:06.593+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1734205264874
[2024-12-14T19:41:06.618+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Utils: /root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar has been previously copied to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.apache.hadoop_hadoop-client-api-3.3.4.jar
[2024-12-14T19:41:06.625+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Executor: Fetching file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1734205264874
24/12/14 19:41:06 INFO Utils: /root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar has been previously copied to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/com.google.code.findbugs_jsr305-3.0.0.jar
[2024-12-14T19:41:06.632+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1734205264874
[2024-12-14T19:41:06.670+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Utils: /root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar has been previously copied to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar
[2024-12-14T19:41:06.677+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Executor: Fetching file:///root/.ivy2/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1734205264874
[2024-12-14T19:41:06.678+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Utils: /root/.ivy2/jars/org.checkerframework_checker-qual-3.5.0.jar has been previously copied to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.checkerframework_checker-qual-3.5.0.jar
[2024-12-14T19:41:06.684+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Executor: Fetching file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1734205264874
[2024-12-14T19:41:06.689+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Utils: /root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar has been previously copied to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.xerial.snappy_snappy-java-1.1.10.3.jar
[2024-12-14T19:41:06.695+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar with timestamp 1734205264874
[2024-12-14T19:41:06.696+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Utils: /root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar has been previously copied to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar
[2024-12-14T19:41:06.702+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Executor: Fetching file:///root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1734205264874
[2024-12-14T19:41:06.704+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Utils: /root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar has been previously copied to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.slf4j_slf4j-api-2.0.7.jar
[2024-12-14T19:41:06.710+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1734205264874
[2024-12-14T19:41:06.711+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Utils: /root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar has been previously copied to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.apache.commons_commons-pool2-2.11.1.jar
[2024-12-14T19:41:06.718+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Executor: Fetching file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1734205264874
[2024-12-14T19:41:06.719+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Utils: /root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar has been previously copied to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/commons-logging_commons-logging-1.1.3.jar
[2024-12-14T19:41:06.735+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Executor: Fetching file:///root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar with timestamp 1734205264874
[2024-12-14T19:41:06.737+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Utils: /root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar has been previously copied to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.lz4_lz4-java-1.8.0.jar
[2024-12-14T19:41:06.745+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar with timestamp 1734205264874
[2024-12-14T19:41:06.755+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Utils: /root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar has been previously copied to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.apache.kafka_kafka-clients-3.4.1.jar
[2024-12-14T19:41:06.772+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Executor: Fetching spark://localhost:45995/jars/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1734205264874
[2024-12-14T19:41:06.854+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:45995 after 57 ms (0 ms spent in bootstraps)
[2024-12-14T19:41:06.870+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Utils: Fetching spark://localhost:45995/jars/org.slf4j_slf4j-api-2.0.7.jar to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/fetchFileTemp13661719389255320650.tmp
[2024-12-14T19:41:06.917+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Utils: /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/fetchFileTemp13661719389255320650.tmp has been previously copied to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.slf4j_slf4j-api-2.0.7.jar
[2024-12-14T19:41:06.925+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Executor: Adding file:/tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.slf4j_slf4j-api-2.0.7.jar to class loader default
[2024-12-14T19:41:06.926+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Executor: Fetching spark://localhost:45995/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar with timestamp 1734205264874
[2024-12-14T19:41:06.928+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Utils: Fetching spark://localhost:45995/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/fetchFileTemp5710801193177161821.tmp
[2024-12-14T19:41:06.933+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Utils: /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/fetchFileTemp5710801193177161821.tmp has been previously copied to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar
[2024-12-14T19:41:06.939+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Executor: Adding file:/tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar to class loader default
[2024-12-14T19:41:06.941+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Executor: Fetching spark://localhost:45995/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1734205264874
[2024-12-14T19:41:06.942+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Utils: Fetching spark://localhost:45995/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/fetchFileTemp3671336305198456476.tmp
[2024-12-14T19:41:06.973+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Utils: /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/fetchFileTemp3671336305198456476.tmp has been previously copied to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.xerial.snappy_snappy-java-1.1.10.3.jar
[2024-12-14T19:41:06.979+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Executor: Adding file:/tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.xerial.snappy_snappy-java-1.1.10.3.jar to class loader default
[2024-12-14T19:41:06.980+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Executor: Fetching spark://localhost:45995/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar with timestamp 1734205264874
[2024-12-14T19:41:06.982+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Utils: Fetching spark://localhost:45995/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/fetchFileTemp13674729457021712958.tmp
[2024-12-14T19:41:06.990+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Utils: /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/fetchFileTemp13674729457021712958.tmp has been previously copied to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar
[2024-12-14T19:41:06.997+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Executor: Adding file:/tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar to class loader default
[2024-12-14T19:41:06.998+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Executor: Fetching spark://localhost:45995/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1734205264874
[2024-12-14T19:41:07.000+0000] {docker.py:413} INFO - 24/12/14 19:41:06 INFO Utils: Fetching spark://localhost:45995/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/fetchFileTemp16604433002538322350.tmp
[2024-12-14T19:41:07.171+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO Utils: /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/fetchFileTemp16604433002538322350.tmp has been previously copied to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar
[2024-12-14T19:41:07.182+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO Executor: Adding file:/tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar to class loader default
[2024-12-14T19:41:07.184+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO Executor: Fetching spark://localhost:45995/jars/org.lz4_lz4-java-1.8.0.jar with timestamp 1734205264874
[2024-12-14T19:41:07.185+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO Utils: Fetching spark://localhost:45995/jars/org.lz4_lz4-java-1.8.0.jar to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/fetchFileTemp10392519125759640844.tmp
[2024-12-14T19:41:07.193+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO Utils: /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/fetchFileTemp10392519125759640844.tmp has been previously copied to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.lz4_lz4-java-1.8.0.jar
[2024-12-14T19:41:07.199+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO Executor: Adding file:/tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.lz4_lz4-java-1.8.0.jar to class loader default
[2024-12-14T19:41:07.201+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO Executor: Fetching spark://localhost:45995/jars/org.apache.kafka_kafka-clients-3.4.1.jar with timestamp 1734205264874
[2024-12-14T19:41:07.202+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO Utils: Fetching spark://localhost:45995/jars/org.apache.kafka_kafka-clients-3.4.1.jar to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/fetchFileTemp3460505538198914301.tmp
[2024-12-14T19:41:07.228+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO Utils: /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/fetchFileTemp3460505538198914301.tmp has been previously copied to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.apache.kafka_kafka-clients-3.4.1.jar
[2024-12-14T19:41:07.235+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO Executor: Adding file:/tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.apache.kafka_kafka-clients-3.4.1.jar to class loader default
[2024-12-14T19:41:07.236+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO Executor: Fetching spark://localhost:45995/jars/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1734205264874
[2024-12-14T19:41:07.239+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO Utils: Fetching spark://localhost:45995/jars/org.apache.commons_commons-pool2-2.11.1.jar to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/fetchFileTemp378013256035250755.tmp
[2024-12-14T19:41:07.242+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO Utils: /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/fetchFileTemp378013256035250755.tmp has been previously copied to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.apache.commons_commons-pool2-2.11.1.jar
[2024-12-14T19:41:07.250+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO Executor: Adding file:/tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.apache.commons_commons-pool2-2.11.1.jar to class loader default
[2024-12-14T19:41:07.251+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO Executor: Fetching spark://localhost:45995/jars/org.***ql_***ql-42.5.4.jar with timestamp 1734205264874
[2024-12-14T19:41:07.253+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO Utils: Fetching spark://localhost:45995/jars/org.***ql_***ql-42.5.4.jar to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/fetchFileTemp13108598617884440988.tmp
[2024-12-14T19:41:07.264+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO Utils: /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/fetchFileTemp13108598617884440988.tmp has been previously copied to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.***ql_***ql-42.5.4.jar
[2024-12-14T19:41:07.271+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO Executor: Adding file:/tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.***ql_***ql-42.5.4.jar to class loader default
24/12/14 19:41:07 INFO Executor: Fetching spark://localhost:45995/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1734205264874
[2024-12-14T19:41:07.272+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO Utils: Fetching spark://localhost:45995/jars/commons-logging_commons-logging-1.1.3.jar to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/fetchFileTemp4883669320587907205.tmp
[2024-12-14T19:41:07.274+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO Utils: /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/fetchFileTemp4883669320587907205.tmp has been previously copied to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/commons-logging_commons-logging-1.1.3.jar
[2024-12-14T19:41:07.282+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO Executor: Adding file:/tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/commons-logging_commons-logging-1.1.3.jar to class loader default
[2024-12-14T19:41:07.283+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO Executor: Fetching spark://localhost:45995/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1734205264874
[2024-12-14T19:41:07.284+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO Utils: Fetching spark://localhost:45995/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/fetchFileTemp1054794483208240106.tmp
[2024-12-14T19:41:07.287+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO Utils: /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/fetchFileTemp1054794483208240106.tmp has been previously copied to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.checkerframework_checker-qual-3.5.0.jar
[2024-12-14T19:41:07.296+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO Executor: Adding file:/tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.checkerframework_checker-qual-3.5.0.jar to class loader default
[2024-12-14T19:41:07.297+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO Executor: Fetching spark://localhost:45995/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1734205264874
[2024-12-14T19:41:07.299+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO Utils: Fetching spark://localhost:45995/jars/com.google.code.findbugs_jsr305-3.0.0.jar to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/fetchFileTemp638022443176700195.tmp
[2024-12-14T19:41:07.302+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO Utils: /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/fetchFileTemp638022443176700195.tmp has been previously copied to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/com.google.code.findbugs_jsr305-3.0.0.jar
[2024-12-14T19:41:07.309+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO Executor: Adding file:/tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/com.google.code.findbugs_jsr305-3.0.0.jar to class loader default
[2024-12-14T19:41:07.310+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO Executor: Fetching spark://localhost:45995/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1734205264874
[2024-12-14T19:41:07.311+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO Utils: Fetching spark://localhost:45995/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/fetchFileTemp8292006138052812639.tmp
[2024-12-14T19:41:07.408+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO Utils: /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/fetchFileTemp8292006138052812639.tmp has been previously copied to /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.apache.hadoop_hadoop-client-api-3.3.4.jar
[2024-12-14T19:41:07.418+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO Executor: Adding file:/tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/userFiles-fe4f9625-3c57-444b-8513-25f0aabb4f64/org.apache.hadoop_hadoop-client-api-3.3.4.jar to class loader default
[2024-12-14T19:41:07.435+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 32963.
24/12/14 19:41:07 INFO NettyBlockTransferService: Server created on localhost:32963
[2024-12-14T19:41:07.438+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2024-12-14T19:41:07.452+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 32963, None)
[2024-12-14T19:41:07.462+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO BlockManagerMasterEndpoint: Registering block manager localhost:32963 with 434.4 MiB RAM, BlockManagerId(driver, localhost, 32963, None)
[2024-12-14T19:41:07.469+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 32963, None)
[2024-12-14T19:41:07.472+0000] {docker.py:413} INFO - 24/12/14 19:41:07 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 32963, None)
[2024-12-14T19:41:08.418+0000] {docker.py:413} INFO - 2024-12-14 19:41:08,415 [INFO] Successfully created Spark session
2024-12-14 19:41:08,415 [INFO] Initializing RedditTransformer...
2024-12-14 19:41:08,415 [INFO] Loading spaCy model...
[2024-12-14T19:41:10.269+0000] {docker.py:413} INFO - 2024-12-14 19:41:10,266 [INFO] Successfully loaded spaCy model
2024-12-14 19:41:10,267 [INFO] Initialized database configuration with host: host.docker.internal
2024-12-14 19:41:10,267 [INFO] Schema initialized
2024-12-14 19:41:10,267 [INFO] Expected schema: StructType([StructField('id', StringType(), True), StructField('title', StringType(), True), StructField('author', StringType(), True), StructField('post_time', FloatType(), True), StructField('upvotes', IntegerType(), True), StructField('downvotes', IntegerType(), True), StructField('num_comments', IntegerType(), True), StructField('score', IntegerType(), True), StructField('selftext', StringType(), True), StructField('first_level_comments_count', IntegerType(), True), StructField('second_level_comments_count', IntegerType(), True), StructField('text', StringType(), True), StructField('subreddit', StringType(), True), StructField('processing_timestamp', StringType(), True)])
2024-12-14 19:41:10,267 [INFO] Database config: jdbc:***ql://host.docker.internal:5432/reddit-data
2024-12-14 19:41:10,267 [INFO] Setting up Kafka stream reader with broker: kafka:9092
[2024-12-14T19:41:10.282+0000] {docker.py:413} INFO - 24/12/14 19:41:10 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2024-12-14T19:41:10.286+0000] {docker.py:413} INFO - 24/12/14 19:41:10 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
[2024-12-14T19:41:11.575+0000] {docker.py:413} INFO - 24/12/14 19:41:11 WARN KafkaSourceProvider: Kafka option 'kafka.group.id' has been set on this query, it is
 not recommended to set this option. This option is unsafe to use since multiple concurrent
 queries or sources using the same group id will interfere with each other as they are part
 of the same consumer group. Restarted queries may also suffer interference from the
 previous run having the same group id. The user should have only one query per group id,
 and/or set the option 'kafka.session.timeout.ms' to be very small so that the Kafka
 consumers from the previous query are marked dead by the Kafka group coordinator before the
 restarted query starts running.
[2024-12-14T19:41:12.771+0000] {docker.py:413} INFO - 2024-12-14 19:41:12,769 [INFO] Kafka reader configuration:
2024-12-14 19:41:12,769 [INFO] Raw Kafka schema:
[2024-12-14T19:41:12.810+0000] {docker.py:413} INFO - root
 |-- key: binary (nullable = true)
 |-- value: binary (nullable = true)
 |-- topic: string (nullable = true)
 |-- partition: integer (nullable = true)
 |-- offset: long (nullable = true)
 |-- timestamp: timestamp (nullable = true)
 |-- timestampType: integer (nullable = true)

2024-12-14 19:41:12,807 [INFO] Setting up JSON parsing...
[2024-12-14T19:41:13.320+0000] {docker.py:413} INFO - 2024-12-14 19:41:13,316 [INFO] Starting streaming query...
[2024-12-14T19:41:13.373+0000] {docker.py:413} INFO - 2024-12-14 19:41:13,370 [INFO] Callback Server Starting
2024-12-14 19:41:13,371 [INFO] Socket listening on ('127.0.0.1', 37853)
[2024-12-14T19:41:13.418+0000] {docker.py:413} INFO - 24/12/14 19:41:13 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
[2024-12-14T19:41:13.528+0000] {docker.py:413} INFO - 24/12/14 19:41:13 INFO ResolveWriteToStream: Checkpoint root /opt/spark/checkpoints resolved to file:/opt/spark/checkpoints.
[2024-12-14T19:41:13.529+0000] {docker.py:413} INFO - 24/12/14 19:41:13 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
[2024-12-14T19:41:13.672+0000] {docker.py:413} INFO - 24/12/14 19:41:13 INFO CheckpointFileManager: Writing atomically to file:/opt/spark/checkpoints/metadata using temp file file:/opt/spark/checkpoints/.metadata.b0de6fc8-84d8-40b8-bcfd-98c646046917.tmp
[2024-12-14T19:41:13.821+0000] {docker.py:413} INFO - 24/12/14 19:41:13 INFO CheckpointFileManager: Renamed temp file file:/opt/spark/checkpoints/.metadata.b0de6fc8-84d8-40b8-bcfd-98c646046917.tmp to file:/opt/spark/checkpoints/metadata
[2024-12-14T19:41:13.881+0000] {docker.py:413} INFO - 24/12/14 19:41:13 INFO MicroBatchExecution: Starting [id = 380f0ba5-0895-4b92-9659-cdf82c87bac4, runId = 119abbaf-fc84-434b-a8d5-63f33c113a14]. Use file:/opt/spark/checkpoints to store the query checkpoint.
[2024-12-14T19:41:13.893+0000] {docker.py:413} INFO - 2024-12-14 19:41:13,890 [INFO] Waiting for streaming query to complete...
[2024-12-14T19:41:13.905+0000] {docker.py:413} INFO - 24/12/14 19:41:13 INFO MicroBatchExecution: Reading table [org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@ffaa753] from DataSourceV2 named 'kafka' [org.apache.spark.sql.kafka010.KafkaSourceProvider@1c93d655]
[2024-12-14T19:41:13.909+0000] {docker.py:413} INFO - 24/12/14 19:41:13 WARN KafkaSourceProvider: Kafka option 'kafka.group.id' has been set on this query, it is
 not recommended to set this option. This option is unsafe to use since multiple concurrent
 queries or sources using the same group id will interfere with each other as they are part
 of the same consumer group. Restarted queries may also suffer interference from the
 previous run having the same group id. The user should have only one query per group id,
 and/or set the option 'kafka.session.timeout.ms' to be very small so that the Kafka
 consumers from the previous query are marked dead by the Kafka group coordinator before the
 restarted query starts running.
[2024-12-14T19:41:13.967+0000] {docker.py:413} INFO - 24/12/14 19:41:13 INFO OffsetSeqLog: BatchIds found from listing:
[2024-12-14T19:41:13.969+0000] {docker.py:413} INFO - 24/12/14 19:41:13 INFO OffsetSeqLog: BatchIds found from listing:
[2024-12-14T19:41:13.971+0000] {docker.py:413} INFO - 24/12/14 19:41:13 INFO MicroBatchExecution: Starting new streaming query.
[2024-12-14T19:41:13.978+0000] {docker.py:413} INFO - 24/12/14 19:41:13 INFO MicroBatchExecution: Stream started from {}
[2024-12-14T19:41:14.704+0000] {docker.py:413} INFO - 24/12/14 19:41:14 INFO AdminClientConfig: AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [kafka:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
[2024-12-14T19:41:14.913+0000] {docker.py:413} INFO - 24/12/14 19:41:14 INFO AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, group.id, auto.offset.reset]' were supplied but are not used yet.
[2024-12-14T19:41:14.916+0000] {docker.py:413} INFO - 24/12/14 19:41:14 INFO AppInfoParser: Kafka version: 3.5.0
24/12/14 19:41:14 INFO AppInfoParser: Kafka commitId: c97b88d5db4de28d
24/12/14 19:41:14 INFO AppInfoParser: Kafka startTimeMs: 1734205274910
[2024-12-14T19:41:15.615+0000] {docker.py:413} INFO - 24/12/14 19:41:15 INFO CheckpointFileManager: Writing atomically to file:/opt/spark/checkpoints/sources/0/0 using temp file file:/opt/spark/checkpoints/sources/0/.0.3a0ebbc5-3341-41ae-a873-04212cf61494.tmp
[2024-12-14T19:41:15.669+0000] {docker.py:413} INFO - 24/12/14 19:41:15 INFO CheckpointFileManager: Renamed temp file file:/opt/spark/checkpoints/sources/0/.0.3a0ebbc5-3341-41ae-a873-04212cf61494.tmp to file:/opt/spark/checkpoints/sources/0/0
[2024-12-14T19:41:15.671+0000] {docker.py:413} INFO - 24/12/14 19:41:15 INFO KafkaMicroBatchStream: Initial offsets: {"reddit_data":{"0":0}}
[2024-12-14T19:41:15.720+0000] {docker.py:413} INFO - 24/12/14 19:41:15 INFO CheckpointFileManager: Writing atomically to file:/opt/spark/checkpoints/offsets/0 using temp file file:/opt/spark/checkpoints/offsets/.0.425f9215-6459-4a2b-9290-8d1968ed9d26.tmp
[2024-12-14T19:41:15.781+0000] {docker.py:413} INFO - 24/12/14 19:41:15 INFO CheckpointFileManager: Renamed temp file file:/opt/spark/checkpoints/offsets/.0.425f9215-6459-4a2b-9290-8d1968ed9d26.tmp to file:/opt/spark/checkpoints/offsets/0
[2024-12-14T19:41:15.782+0000] {docker.py:413} INFO - 24/12/14 19:41:15 INFO MicroBatchExecution: Committed offsets for batch 0. Metadata OffsetSeqMetadata(0,1734205275701,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2024-12-14T19:41:16.483+0000] {docker.py:413} INFO - 24/12/14 19:41:16 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-12-14T19:41:16.624+0000] {docker.py:413} INFO - 24/12/14 19:41:16 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-12-14T19:41:16.803+0000] {docker.py:413} INFO - 24/12/14 19:41:16 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-12-14T19:41:16.809+0000] {docker.py:413} INFO - 24/12/14 19:41:16 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-12-14T19:41:17.474+0000] {docker.py:413} INFO - 24/12/14 19:41:17 INFO CodeGenerator: Code generated in 350.278744 ms
[2024-12-14T19:41:17.735+0000] {docker.py:413} INFO - 2024-12-14 19:41:17,731 [INFO] Python Server ready to receive messages
[2024-12-14T19:41:17.737+0000] {docker.py:413} INFO - 2024-12-14 19:41:17,732 [INFO] Received command c on object id p0
[2024-12-14T19:41:18.073+0000] {docker.py:413} INFO - 24/12/14 19:41:18 INFO CodeGenerator: Code generated in 41.780841 ms
[2024-12-14T19:41:18.155+0000] {docker.py:413} INFO - 24/12/14 19:41:18 INFO CodeGenerator: Code generated in 48.985196 ms
[2024-12-14T19:41:18.379+0000] {docker.py:413} INFO - 24/12/14 19:41:18 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
[2024-12-14T19:41:18.437+0000] {docker.py:413} INFO - 24/12/14 19:41:18 INFO DAGScheduler: Registering RDD 6 (start at NativeMethodAccessorImpl.java:0) as input to shuffle 0
[2024-12-14T19:41:18.463+0000] {docker.py:413} INFO - 24/12/14 19:41:18 INFO DAGScheduler: Got job 0 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2024-12-14T19:41:18.465+0000] {docker.py:413} INFO - 24/12/14 19:41:18 INFO DAGScheduler: Final stage: ResultStage 1 (start at NativeMethodAccessorImpl.java:0)
[2024-12-14T19:41:18.467+0000] {docker.py:413} INFO - 24/12/14 19:41:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
[2024-12-14T19:41:18.475+0000] {docker.py:413} INFO - 24/12/14 19:41:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
[2024-12-14T19:41:18.491+0000] {docker.py:413} INFO - 24/12/14 19:41:18 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[6] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-12-14T19:41:18.883+0000] {docker.py:413} INFO - 24/12/14 19:41:18 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 39.5 KiB, free 434.4 MiB)
[2024-12-14T19:41:18.965+0000] {docker.py:413} INFO - 24/12/14 19:41:18 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 15.9 KiB, free 434.3 MiB)
[2024-12-14T19:41:18.974+0000] {docker.py:413} INFO - 24/12/14 19:41:18 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:32963 (size: 15.9 KiB, free: 434.4 MiB)
[2024-12-14T19:41:18.988+0000] {docker.py:413} INFO - 24/12/14 19:41:18 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1580
[2024-12-14T19:41:19.112+0000] {docker.py:413} INFO - 24/12/14 19:41:19 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[6] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2024-12-14T19:41:19.120+0000] {docker.py:413} INFO - 24/12/14 19:41:19 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2024-12-14T19:41:19.269+0000] {docker.py:413} INFO - 24/12/14 19:41:19 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (localhost, executor driver, partition 0, PROCESS_LOCAL, 10838 bytes)
[2024-12-14T19:41:19.309+0000] {docker.py:413} INFO - 24/12/14 19:41:19 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
[2024-12-14T19:41:19.843+0000] {docker.py:413} INFO - 24/12/14 19:41:19 INFO CodeGenerator: Code generated in 110.190702 ms
[2024-12-14T19:41:19.948+0000] {docker.py:413} INFO - 24/12/14 19:41:19 INFO CodeGenerator: Code generated in 98.356531 ms
[2024-12-14T19:41:19.985+0000] {docker.py:413} INFO - 24/12/14 19:41:19 INFO CodeGenerator: Code generated in 28.157126 ms
[2024-12-14T19:41:20.005+0000] {docker.py:413} INFO - 24/12/14 19:41:20 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=reddit_data-0 fromOffset=0 untilOffset=650, for query queryId=380f0ba5-0895-4b92-9659-cdf82c87bac4 batchId=0 taskId=0 partitionId=0
[2024-12-14T19:41:20.086+0000] {docker.py:413} INFO - 24/12/14 19:41:20 INFO CodeGenerator: Code generated in 21.628746 ms
[2024-12-14T19:41:20.153+0000] {docker.py:413} INFO - 24/12/14 19:41:20 INFO CodeGenerator: Code generated in 45.759414 ms
[2024-12-14T19:41:20.217+0000] {docker.py:413} INFO - 24/12/14 19:41:20 INFO ConsumerConfig: ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = none
	bootstrap.servers = [kafka:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-reddit_processor_group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = reddit_processor_group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2024-12-14T19:41:20.479+0000] {docker.py:413} INFO - 24/12/14 19:41:20 INFO AppInfoParser: Kafka version: 3.5.0
24/12/14 19:41:20 INFO AppInfoParser: Kafka commitId: c97b88d5db4de28d
[2024-12-14T19:41:20.482+0000] {docker.py:413} INFO - 24/12/14 19:41:20 INFO AppInfoParser: Kafka startTimeMs: 1734205280473
[2024-12-14T19:41:20.488+0000] {docker.py:413} INFO - 24/12/14 19:41:20 INFO KafkaConsumer: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Assigned to partition(s): reddit_data-0
[2024-12-14T19:41:20.530+0000] {docker.py:413} INFO - 24/12/14 19:41:20 INFO KafkaConsumer: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to offset 0 for partition reddit_data-0
[2024-12-14T19:41:20.568+0000] {docker.py:413} INFO - 24/12/14 19:41:20 INFO Metadata: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Cluster ID: y_jx5SImQsqTV8y5Et3GdQ
[2024-12-14T19:41:20.803+0000] {docker.py:413} INFO - 24/12/14 19:41:20 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to earliest offset of partition reddit_data-0
[2024-12-14T19:41:20.842+0000] {docker.py:413} INFO - 24/12/14 19:41:20 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Resetting offset for partition reddit_data-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 0 rack: null)], epoch=32}}.
[2024-12-14T19:41:20.845+0000] {docker.py:413} INFO - 24/12/14 19:41:20 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to latest offset of partition reddit_data-0
[2024-12-14T19:41:20.849+0000] {docker.py:413} INFO - 24/12/14 19:41:20 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Resetting offset for partition reddit_data-0 to position FetchPosition{offset=650, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 0 rack: null)], epoch=32}}.
[2024-12-14T19:41:22.150+0000] {docker.py:413} INFO - 24/12/14 19:41:22 INFO KafkaConsumer: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to offset 500 for partition reddit_data-0
[2024-12-14T19:41:22.165+0000] {docker.py:413} INFO - 24/12/14 19:41:22 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to earliest offset of partition reddit_data-0
[2024-12-14T19:41:22.673+0000] {docker.py:413} INFO - 24/12/14 19:41:22 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Resetting offset for partition reddit_data-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 0 rack: null)], epoch=32}}.
[2024-12-14T19:41:22.676+0000] {docker.py:413} INFO - 24/12/14 19:41:22 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to latest offset of partition reddit_data-0
[2024-12-14T19:41:22.681+0000] {docker.py:413} INFO - 24/12/14 19:41:22 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Resetting offset for partition reddit_data-0 to position FetchPosition{offset=650, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 0 rack: null)], epoch=32}}.
[2024-12-14T19:41:22.856+0000] {docker.py:413} INFO - 24/12/14 19:41:22 INFO KafkaDataConsumer: From Kafka topicPartition=reddit_data-0 groupId=reddit_processor_group read 650 records through 2 polls (polled  out 650 records), taking 857760704 nanos, during time span of 2346514756 nanos.
[2024-12-14T19:41:22.980+0000] {docker.py:413} INFO - 24/12/14 19:41:22 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2340 bytes result sent to driver
[2024-12-14T19:41:23.033+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 3794 ms on localhost (executor driver) (1/1)
[2024-12-14T19:41:23.042+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2024-12-14T19:41:23.081+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO DAGScheduler: ShuffleMapStage 0 (start at NativeMethodAccessorImpl.java:0) finished in 4.550 s
[2024-12-14T19:41:23.084+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO DAGScheduler: looking for newly runnable stages
[2024-12-14T19:41:23.087+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO DAGScheduler: running: Set()
[2024-12-14T19:41:23.091+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO DAGScheduler: waiting: Set(ResultStage 1)
[2024-12-14T19:41:23.094+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO DAGScheduler: failed: Set()
[2024-12-14T19:41:23.103+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-12-14T19:41:23.151+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.5 KiB, free 434.3 MiB)
[2024-12-14T19:41:23.159+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.3 MiB)
[2024-12-14T19:41:23.163+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:32963 (size: 5.9 KiB, free: 434.4 MiB)
[2024-12-14T19:41:23.169+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1580
[2024-12-14T19:41:23.179+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2024-12-14T19:41:23.181+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
[2024-12-14T19:41:23.212+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (localhost, executor driver, partition 0, NODE_LOCAL, 9963 bytes)
[2024-12-14T19:41:23.216+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
[2024-12-14T19:41:23.350+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:23.356+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 25 ms
[2024-12-14T19:41:23.389+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO CodeGenerator: Code generated in 25.054751 ms
[2024-12-14T19:41:23.422+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 4038 bytes result sent to driver
[2024-12-14T19:41:23.428+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 230 ms on localhost (executor driver) (1/1)
[2024-12-14T19:41:23.431+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
[2024-12-14T19:41:23.439+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO DAGScheduler: ResultStage 1 (start at NativeMethodAccessorImpl.java:0) finished in 0.299 s
[2024-12-14T19:41:23.456+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-12-14T19:41:23.460+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
[2024-12-14T19:41:23.472+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO DAGScheduler: Job 0 finished: start at NativeMethodAccessorImpl.java:0, took 5.091799 s
[2024-12-14T19:41:23.499+0000] {docker.py:413} INFO - 2024-12-14 19:41:23,493 [INFO] Starting to process batch 0 with 650 records
2024-12-14 19:41:23,494 [INFO] Sample data from batch 0:
[2024-12-14T19:41:23.871+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO CodeGenerator: Code generated in 36.514231 ms
[2024-12-14T19:41:23.890+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
[2024-12-14T19:41:23.895+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO DAGScheduler: Got job 1 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/12/14 19:41:23 INFO DAGScheduler: Final stage: ResultStage 2 (start at NativeMethodAccessorImpl.java:0)
[2024-12-14T19:41:23.896+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO DAGScheduler: Parents of final stage: List()
[2024-12-14T19:41:23.899+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO DAGScheduler: Missing parents: List()
[2024-12-14T19:41:23.901+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[11] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-12-14T19:41:23.912+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 41.2 KiB, free 434.3 MiB)
[2024-12-14T19:41:23.917+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 15.6 KiB, free 434.3 MiB)
[2024-12-14T19:41:23.920+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:32963 (size: 15.6 KiB, free: 434.4 MiB)
[2024-12-14T19:41:23.922+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1580
[2024-12-14T19:41:23.925+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2024-12-14T19:41:23.930+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
[2024-12-14T19:41:23.932+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (localhost, executor driver, partition 0, PROCESS_LOCAL, 10849 bytes)
[2024-12-14T19:41:23.933+0000] {docker.py:413} INFO - 24/12/14 19:41:23 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
[2024-12-14T19:41:24.055+0000] {docker.py:413} INFO - 24/12/14 19:41:24 INFO CodeGenerator: Code generated in 69.964144 ms
[2024-12-14T19:41:24.059+0000] {docker.py:413} INFO - 24/12/14 19:41:24 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=reddit_data-0 fromOffset=0 untilOffset=650, for query queryId=380f0ba5-0895-4b92-9659-cdf82c87bac4 batchId=0 taskId=2 partitionId=0
[2024-12-14T19:41:24.097+0000] {docker.py:413} INFO - 24/12/14 19:41:24 INFO KafkaConsumer: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to offset 0 for partition reddit_data-0
[2024-12-14T19:41:24.113+0000] {docker.py:413} INFO - 24/12/14 19:41:24 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to earliest offset of partition reddit_data-0
[2024-12-14T19:41:24.119+0000] {docker.py:413} INFO - 24/12/14 19:41:24 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Resetting offset for partition reddit_data-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 0 rack: null)], epoch=32}}.
[2024-12-14T19:41:24.121+0000] {docker.py:413} INFO - 24/12/14 19:41:24 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to latest offset of partition reddit_data-0
[2024-12-14T19:41:24.123+0000] {docker.py:413} INFO - 24/12/14 19:41:24 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Resetting offset for partition reddit_data-0 to position FetchPosition{offset=650, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 0 rack: null)], epoch=32}}.
[2024-12-14T19:41:24.133+0000] {docker.py:413} INFO - 24/12/14 19:41:24 INFO KafkaDataConsumer: From Kafka topicPartition=reddit_data-0 groupId=reddit_processor_group read 3 records through 1 polls (polled  out 500 records), taking 27035824 nanos, during time span of 36436360 nanos.
[2024-12-14T19:41:24.137+0000] {docker.py:413} INFO - 24/12/14 19:41:24 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 3680 bytes result sent to driver
[2024-12-14T19:41:24.144+0000] {docker.py:413} INFO - 24/12/14 19:41:24 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 214 ms on localhost (executor driver) (1/1)
[2024-12-14T19:41:24.148+0000] {docker.py:413} INFO - 24/12/14 19:41:24 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2024-12-14T19:41:24.151+0000] {docker.py:413} INFO - 24/12/14 19:41:24 INFO DAGScheduler: ResultStage 2 (start at NativeMethodAccessorImpl.java:0) finished in 0.244 s
24/12/14 19:41:24 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-12-14T19:41:24.153+0000] {docker.py:413} INFO - 24/12/14 19:41:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
[2024-12-14T19:41:24.155+0000] {docker.py:413} INFO - 24/12/14 19:41:24 INFO DAGScheduler: Job 1 finished: start at NativeMethodAccessorImpl.java:0, took 0.258771 s
[2024-12-14T19:41:26.286+0000] {docker.py:413} INFO - 24/12/14 19:41:26 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:32963 in memory (size: 15.9 KiB, free: 434.4 MiB)
[2024-12-14T19:41:26.300+0000] {docker.py:413} INFO - 24/12/14 19:41:26 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:32963 in memory (size: 5.9 KiB, free: 434.4 MiB)
[2024-12-14T19:41:26.332+0000] {docker.py:413} INFO - 24/12/14 19:41:26 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:32963 in memory (size: 15.6 KiB, free: 434.4 MiB)
[2024-12-14T19:41:27.311+0000] {docker.py:413} INFO - 24/12/14 19:41:27 INFO CodeGenerator: Code generated in 53.906219 ms
[2024-12-14T19:41:27.411+0000] {docker.py:413} INFO - +-------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+------------+-------+---------+------------+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------+---------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+--------------------------+
|id     |title                                                                                                                                                                                                                                                                                 |author    |post_time   |upvotes|downvotes|num_comments|score|selftext                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |first_level_comments_count|second_level_comments_count|text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |subreddit|processing_timestamp      |
+-------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+------------+-------+---------+------------+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------+---------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+--------------------------+
|1he0jj3|After Milan's 2-1 win against Crvena Zvezda, coach Fonseca had said: "I don't give a f... about the player's name, I work hard to give my best, some in the team don't. If I need to play players from the youth team I will do it." Today 6 youth players trained with the first team|Blodgharm |1.7341737E9 |20     |0        |2           |20   |NULL                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |1                         |1                          |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |soccer   |2024-12-14T11:08:32.604441|
|1he0j1x|UK TV Games & What to Watch: Sunday 15th December                                                                                                                                                                                                                                     |JammyMoore|1.73417357E9|2      |0        |1           |2    |Looking at the games on **Sunday 15th December** that are available to watch in the UK. Where to watch them and what I would watch!\n\nEarly risers can watch a tasty match from the Australian **A-League**. Newly founded **Auckland FC** are 6 wins from 6 games this season, and they travel to the seasoned **Melbourne City**.\n\nNext up is a double header of **Serie A** matches. A relegation scrap as **Lecce**, sitting 1 point outside the drop zone face **Monza** sitting in 19th. Followed up by Derby dell' Appennino, as Vincenzo Italiano's **Bologna** host his former club **Fiorentina**.\n\nThe match of the day is the Manchester Derby in the **Premier League**. Out of form **Manchester City** take on a new form **Manchester United** under Ruben Amorim.\n\nTo round of the day, a big showdown in **Ligue 1**. League leaders **PSG** take on a revived **Lyon** in what surely will be a tasty match.\n\n|Time|Fixture|Competition|Provider / Channel|\n|:-|:-|:-|:-|\n|06:00|Melbourne City v Auckland FC|A-League Men|TNT Sports 1|\n|11:30|Lecce v Monza|Serie A|OneFootball|\n|14:00|Bologna v Fiorentina|Serie A|OneFootball|\n|16:30|Manchester City v Manchester United|Premier League|Sky Sports Main Event / Sky Sports Premier League / Sky Sports Ultra HDR|\n|19:45|PSG v Lyon|Ligue 1|Ligue 1 Pass|\n\n|1                         |0                          |Looking at the games on **Sunday 15th December** that are available to watch in the UK. Where to watch them and what I would watch!\n\nEarly risers can watch a tasty match from the Australian **A-League**. Newly founded **Auckland FC** are 6 wins from 6 games this season, and they travel to the seasoned **Melbourne City**.\n\nNext up is a double header of **Serie A** matches. A relegation scrap as **Lecce**, sitting 1 point outside the drop zone face **Monza** sitting in 19th. Followed up by Derby dell' Appennino, as Vincenzo Italiano's **Bologna** host his former club **Fiorentina**.\n\nThe match of the day is the Manchester Derby in the **Premier League**. Out of form **Manchester City** take on a new form **Manchester United** under Ruben Amorim.\n\nTo round of the day, a big showdown in **Ligue 1**. League leaders **PSG** take on a revived **Lyon** in what surely will be a tasty match.\n\n|Time|Fixture|Competition|Provider / Channel|\n|:-|:-|:-|:-|\n|06:00|Melbourne City v Auckland FC|A-League Men|TNT Sports 1|\n|11:30|Lecce v Monza|Serie A|OneFootball|\n|14:00|Bologna v Fiorentina|Serie A|OneFootball|\n|16:30|Manchester City v Manchester United|Premier League|Sky Sports Main Event / Sky Sports Premier League / Sky Sports Ultra HDR|\n|19:45|PSG v Lyon|Ligue 1|Ligue 1 Pass|\n\n|soccer   |2024-12-14T11:08:33.922040|
+-------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+------------+-------+---------+------------+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------+---------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+--------------------------+
only showing top 2 rows
[2024-12-14T19:41:27.415+0000] {docker.py:413} INFO - 2024-12-14 19:41:27,405 [INFO] Removing duplicates from batch 0...
[2024-12-14T19:41:27.708+0000] {docker.py:413} INFO - 24/12/14 19:41:27 INFO CodeGenerator: Code generated in 36.477279 ms
[2024-12-14T19:41:27.848+0000] {docker.py:413} INFO - 24/12/14 19:41:27 INFO CodeGenerator: Code generated in 97.588423 ms
[2024-12-14T19:41:27.919+0000] {docker.py:413} INFO - 24/12/14 19:41:27 INFO CodeGenerator: Code generated in 53.872795 ms
[2024-12-14T19:41:28.021+0000] {docker.py:413} INFO - 24/12/14 19:41:28 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
[2024-12-14T19:41:28.027+0000] {docker.py:413} INFO - 24/12/14 19:41:28 INFO DAGScheduler: Registering RDD 13 (start at NativeMethodAccessorImpl.java:0) as input to shuffle 1
[2024-12-14T19:41:28.028+0000] {docker.py:413} INFO - 24/12/14 19:41:28 INFO DAGScheduler: Registering RDD 16 (start at NativeMethodAccessorImpl.java:0) as input to shuffle 2
[2024-12-14T19:41:28.029+0000] {docker.py:413} INFO - 24/12/14 19:41:28 INFO DAGScheduler: Got job 2 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/12/14 19:41:28 INFO DAGScheduler: Final stage: ResultStage 5 (start at NativeMethodAccessorImpl.java:0)
[2024-12-14T19:41:28.030+0000] {docker.py:413} INFO - 24/12/14 19:41:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
[2024-12-14T19:41:28.031+0000] {docker.py:413} INFO - 24/12/14 19:41:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
[2024-12-14T19:41:28.033+0000] {docker.py:413} INFO - 24/12/14 19:41:28 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[13] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-12-14T19:41:28.044+0000] {docker.py:413} INFO - 24/12/14 19:41:28 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 51.8 KiB, free 434.3 MiB)
[2024-12-14T19:41:28.049+0000] {docker.py:413} INFO - 24/12/14 19:41:28 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 434.3 MiB)
[2024-12-14T19:41:28.051+0000] {docker.py:413} INFO - 24/12/14 19:41:28 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:32963 (size: 20.7 KiB, free: 434.4 MiB)
[2024-12-14T19:41:28.054+0000] {docker.py:413} INFO - 24/12/14 19:41:28 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1580
[2024-12-14T19:41:28.056+0000] {docker.py:413} INFO - 24/12/14 19:41:28 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[13] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/12/14 19:41:28 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
[2024-12-14T19:41:28.061+0000] {docker.py:413} INFO - 24/12/14 19:41:28 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (localhost, executor driver, partition 0, PROCESS_LOCAL, 10838 bytes)
[2024-12-14T19:41:28.064+0000] {docker.py:413} INFO - 24/12/14 19:41:28 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
[2024-12-14T19:41:28.130+0000] {docker.py:413} INFO - 24/12/14 19:41:28 INFO CodeGenerator: Code generated in 43.100809 ms
[2024-12-14T19:41:28.158+0000] {docker.py:413} INFO - 24/12/14 19:41:28 INFO CodeGenerator: Code generated in 15.634158 ms
[2024-12-14T19:41:28.173+0000] {docker.py:413} INFO - 24/12/14 19:41:28 INFO CodeGenerator: Code generated in 9.106185 ms
[2024-12-14T19:41:28.200+0000] {docker.py:413} INFO - 24/12/14 19:41:28 INFO CodeGenerator: Code generated in 9.957705 ms
[2024-12-14T19:41:28.211+0000] {docker.py:413} INFO - 24/12/14 19:41:28 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=reddit_data-0 fromOffset=0 untilOffset=650, for query queryId=380f0ba5-0895-4b92-9659-cdf82c87bac4 batchId=0 taskId=3 partitionId=0
[2024-12-14T19:41:28.226+0000] {docker.py:413} INFO - 24/12/14 19:41:28 INFO KafkaConsumer: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to offset 0 for partition reddit_data-0
[2024-12-14T19:41:28.245+0000] {docker.py:413} INFO - 24/12/14 19:41:28 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to earliest offset of partition reddit_data-0
[2024-12-14T19:41:28.248+0000] {docker.py:413} INFO - 24/12/14 19:41:28 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Resetting offset for partition reddit_data-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 0 rack: null)], epoch=32}}.
[2024-12-14T19:41:28.250+0000] {docker.py:413} INFO - 24/12/14 19:41:28 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to latest offset of partition reddit_data-0
[2024-12-14T19:41:28.254+0000] {docker.py:413} INFO - 24/12/14 19:41:28 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Resetting offset for partition reddit_data-0 to position FetchPosition{offset=650, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 0 rack: null)], epoch=32}}.
[2024-12-14T19:41:28.333+0000] {docker.py:413} INFO - 24/12/14 19:41:28 INFO KafkaConsumer: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to offset 500 for partition reddit_data-0
[2024-12-14T19:41:28.338+0000] {docker.py:413} INFO - 24/12/14 19:41:28 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to earliest offset of partition reddit_data-0
[2024-12-14T19:41:28.846+0000] {docker.py:413} INFO - 24/12/14 19:41:28 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Resetting offset for partition reddit_data-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 0 rack: null)], epoch=32}}.
[2024-12-14T19:41:28.849+0000] {docker.py:413} INFO - 24/12/14 19:41:28 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to latest offset of partition reddit_data-0
[2024-12-14T19:41:28.855+0000] {docker.py:413} INFO - 24/12/14 19:41:28 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Resetting offset for partition reddit_data-0 to position FetchPosition{offset=650, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 0 rack: null)], epoch=32}}.
[2024-12-14T19:41:29.120+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO KafkaDataConsumer: From Kafka topicPartition=reddit_data-0 groupId=reddit_processor_group read 650 records through 2 polls (polled  out 650 records), taking 550667134 nanos, during time span of 892895455 nanos.
[2024-12-14T19:41:29.130+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2903 bytes result sent to driver
[2024-12-14T19:41:29.140+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 1079 ms on localhost (executor driver) (1/1)
24/12/14 19:41:29 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2024-12-14T19:41:29.146+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO DAGScheduler: ShuffleMapStage 3 (start at NativeMethodAccessorImpl.java:0) finished in 1.108 s
[2024-12-14T19:41:29.150+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO DAGScheduler: looking for newly runnable stages
24/12/14 19:41:29 INFO DAGScheduler: running: Set()
[2024-12-14T19:41:29.152+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO DAGScheduler: waiting: Set(ResultStage 5, ShuffleMapStage 4)
[2024-12-14T19:41:29.155+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO DAGScheduler: failed: Set()
[2024-12-14T19:41:29.158+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[16] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-12-14T19:41:29.296+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 63.8 KiB, free 434.3 MiB)
[2024-12-14T19:41:29.305+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 25.7 KiB, free 434.2 MiB)
[2024-12-14T19:41:29.309+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:32963 (size: 25.7 KiB, free: 434.4 MiB)
[2024-12-14T19:41:29.317+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1580
[2024-12-14T19:41:29.327+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO DAGScheduler: Submitting 200 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[16] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2024-12-14T19:41:29.331+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSchedulerImpl: Adding task set 4.0 with 200 tasks resource profile 0
[2024-12-14T19:41:29.341+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (localhost, executor driver, partition 0, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:29.346+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 5) (localhost, executor driver, partition 3, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:29.350+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 6) (localhost, executor driver, partition 4, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:29.355+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Starting task 5.0 in stage 4.0 (TID 7) (localhost, executor driver, partition 5, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:29.359+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Starting task 6.0 in stage 4.0 (TID 8) (localhost, executor driver, partition 6, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:29.365+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Starting task 7.0 in stage 4.0 (TID 9) (localhost, executor driver, partition 7, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:29.368+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Starting task 8.0 in stage 4.0 (TID 10) (localhost, executor driver, partition 8, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:29.371+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Starting task 9.0 in stage 4.0 (TID 11) (localhost, executor driver, partition 9, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:29.375+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Starting task 12.0 in stage 4.0 (TID 12) (localhost, executor driver, partition 12, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:29.377+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Starting task 14.0 in stage 4.0 (TID 13) (localhost, executor driver, partition 14, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:29.380+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Starting task 16.0 in stage 4.0 (TID 14) (localhost, executor driver, partition 16, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:29.384+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Starting task 19.0 in stage 4.0 (TID 15) (localhost, executor driver, partition 19, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:29.392+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Starting task 22.0 in stage 4.0 (TID 16) (localhost, executor driver, partition 22, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:29.396+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Starting task 25.0 in stage 4.0 (TID 17) (localhost, executor driver, partition 25, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:29.401+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Starting task 26.0 in stage 4.0 (TID 18) (localhost, executor driver, partition 26, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:29.403+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Starting task 29.0 in stage 4.0 (TID 19) (localhost, executor driver, partition 29, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:29.413+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
[2024-12-14T19:41:29.415+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Running task 3.0 in stage 4.0 (TID 5)
[2024-12-14T19:41:29.418+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Running task 4.0 in stage 4.0 (TID 6)
[2024-12-14T19:41:29.422+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Running task 5.0 in stage 4.0 (TID 7)
[2024-12-14T19:41:29.429+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Running task 6.0 in stage 4.0 (TID 8)
24/12/14 19:41:29 INFO Executor: Running task 7.0 in stage 4.0 (TID 9)
[2024-12-14T19:41:29.431+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Running task 8.0 in stage 4.0 (TID 10)
24/12/14 19:41:29 INFO Executor: Running task 9.0 in stage 4.0 (TID 11)
[2024-12-14T19:41:29.439+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Running task 14.0 in stage 4.0 (TID 13)
24/12/14 19:41:29 INFO Executor: Running task 12.0 in stage 4.0 (TID 12)
24/12/14 19:41:29 INFO Executor: Running task 16.0 in stage 4.0 (TID 14)
24/12/14 19:41:29 INFO Executor: Running task 19.0 in stage 4.0 (TID 15)
[2024-12-14T19:41:29.444+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Running task 22.0 in stage 4.0 (TID 16)
[2024-12-14T19:41:29.452+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Running task 26.0 in stage 4.0 (TID 18)
24/12/14 19:41:29 INFO Executor: Running task 29.0 in stage 4.0 (TID 19)
[2024-12-14T19:41:29.464+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Running task 25.0 in stage 4.0 (TID 17)
[2024-12-14T19:41:29.509+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:29.514+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2024-12-14T19:41:29.516+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:29.517+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2024-12-14T19:41:29.520+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:29.523+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
[2024-12-14T19:41:29.526+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:29.531+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:29.535+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:29.540+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2024-12-14T19:41:29.542+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:29.545+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2024-12-14T19:41:29.547+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:29.549+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:29.550+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:29.551+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2024-12-14T19:41:29.552+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:29.553+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2024-12-14T19:41:29.555+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2024-12-14T19:41:29.556+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:29.558+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:29.594+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO CodeGenerator: Code generated in 88.793193 ms
[2024-12-14T19:41:29.637+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:32963 in memory (size: 20.7 KiB, free: 434.4 MiB)
[2024-12-14T19:41:29.669+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Finished task 16.0 in stage 4.0 (TID 14). 5819 bytes result sent to driver
[2024-12-14T19:41:29.678+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Starting task 31.0 in stage 4.0 (TID 20) (localhost, executor driver, partition 31, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:29.686+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Finished task 8.0 in stage 4.0 (TID 10). 5819 bytes result sent to driver
[2024-12-14T19:41:29.689+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Finished task 16.0 in stage 4.0 (TID 14) in 312 ms on localhost (executor driver) (1/200)
[2024-12-14T19:41:29.703+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Starting task 32.0 in stage 4.0 (TID 21) (localhost, executor driver, partition 32, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:29.709+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Running task 31.0 in stage 4.0 (TID 20)
24/12/14 19:41:29 INFO Executor: Finished task 29.0 in stage 4.0 (TID 19). 5819 bytes result sent to driver
[2024-12-14T19:41:29.711+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Running task 32.0 in stage 4.0 (TID 21)
[2024-12-14T19:41:29.713+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Finished task 14.0 in stage 4.0 (TID 13). 5819 bytes result sent to driver
24/12/14 19:41:29 INFO Executor: Finished task 22.0 in stage 4.0 (TID 16). 5819 bytes result sent to driver
[2024-12-14T19:41:29.735+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Finished task 26.0 in stage 4.0 (TID 18). 5862 bytes result sent to driver
[2024-12-14T19:41:29.745+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 5819 bytes result sent to driver
[2024-12-14T19:41:29.749+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Finished task 4.0 in stage 4.0 (TID 6). 5819 bytes result sent to driver
[2024-12-14T19:41:29.750+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Finished task 25.0 in stage 4.0 (TID 17). 5862 bytes result sent to driver
[2024-12-14T19:41:29.751+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Finished task 5.0 in stage 4.0 (TID 7). 5819 bytes result sent to driver
[2024-12-14T19:41:29.752+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Finished task 12.0 in stage 4.0 (TID 12). 5819 bytes result sent to driver
24/12/14 19:41:29 INFO Executor: Finished task 6.0 in stage 4.0 (TID 8). 5819 bytes result sent to driver
[2024-12-14T19:41:29.754+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Finished task 3.0 in stage 4.0 (TID 5). 5819 bytes result sent to driver
[2024-12-14T19:41:29.755+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Starting task 34.0 in stage 4.0 (TID 22) (localhost, executor driver, partition 34, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:29.756+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Finished task 8.0 in stage 4.0 (TID 10) in 386 ms on localhost (executor driver) (2/200)
[2024-12-14T19:41:29.758+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Finished task 29.0 in stage 4.0 (TID 19) in 350 ms on localhost (executor driver) (3/200)
[2024-12-14T19:41:29.759+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Finished task 19.0 in stage 4.0 (TID 15). 5819 bytes result sent to driver
[2024-12-14T19:41:29.761+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Finished task 9.0 in stage 4.0 (TID 11). 5819 bytes result sent to driver
[2024-12-14T19:41:29.762+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Finished task 7.0 in stage 4.0 (TID 9). 5862 bytes result sent to driver
[2024-12-14T19:41:29.768+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Starting task 35.0 in stage 4.0 (TID 23) (localhost, executor driver, partition 35, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:29.770+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Starting task 39.0 in stage 4.0 (TID 24) (localhost, executor driver, partition 39, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:29 INFO Executor: Running task 34.0 in stage 4.0 (TID 22)
[2024-12-14T19:41:29.771+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Starting task 40.0 in stage 4.0 (TID 25) (localhost, executor driver, partition 40, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:29.772+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Running task 35.0 in stage 4.0 (TID 23)
[2024-12-14T19:41:29.777+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Running task 40.0 in stage 4.0 (TID 25)
24/12/14 19:41:29 INFO TaskSetManager: Finished task 14.0 in stage 4.0 (TID 13) in 399 ms on localhost (executor driver) (4/200)
[2024-12-14T19:41:29.780+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Running task 39.0 in stage 4.0 (TID 24)
[2024-12-14T19:41:29.781+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Starting task 42.0 in stage 4.0 (TID 26) (localhost, executor driver, partition 42, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:29.795+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Running task 42.0 in stage 4.0 (TID 26)
[2024-12-14T19:41:29.797+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:29.811+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2024-12-14T19:41:29.819+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Starting task 43.0 in stage 4.0 (TID 27) (localhost, executor driver, partition 43, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:29.822+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Starting task 46.0 in stage 4.0 (TID 28) (localhost, executor driver, partition 46, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:29.827+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 462 ms on localhost (executor driver) (5/200)
[2024-12-14T19:41:29.829+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Running task 46.0 in stage 4.0 (TID 28)
24/12/14 19:41:29 INFO Executor: Running task 43.0 in stage 4.0 (TID 27)
[2024-12-14T19:41:29.834+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Finished task 22.0 in stage 4.0 (TID 16) in 418 ms on localhost (executor driver) (6/200)
[2024-12-14T19:41:29.837+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Starting task 47.0 in stage 4.0 (TID 29) (localhost, executor driver, partition 47, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:29.839+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Finished task 26.0 in stage 4.0 (TID 18) in 430 ms on localhost (executor driver) (7/200)
24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:29.840+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:29.842+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Finished task 25.0 in stage 4.0 (TID 17) in 435 ms on localhost (executor driver) (8/200)
[2024-12-14T19:41:29.844+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 6) in 479 ms on localhost (executor driver) (9/200)
24/12/14 19:41:29 INFO TaskSetManager: Finished task 5.0 in stage 4.0 (TID 7) in 475 ms on localhost (executor driver) (10/200)
24/12/14 19:41:29 INFO Executor: Finished task 32.0 in stage 4.0 (TID 21). 5776 bytes result sent to driver
[2024-12-14T19:41:29.846+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Running task 47.0 in stage 4.0 (TID 29)
24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:29.849+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2024-12-14T19:41:29.851+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Starting task 48.0 in stage 4.0 (TID 30) (localhost, executor driver, partition 48, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:29.854+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:29.856+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Finished task 31.0 in stage 4.0 (TID 20). 5776 bytes result sent to driver
[2024-12-14T19:41:29.858+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2024-12-14T19:41:29.860+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:29.862+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Running task 48.0 in stage 4.0 (TID 30)
24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:29.865+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:29.868+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Finished task 35.0 in stage 4.0 (TID 23). 5776 bytes result sent to driver
[2024-12-14T19:41:29.870+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Starting task 49.0 in stage 4.0 (TID 31) (localhost, executor driver, partition 49, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:29.872+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Starting task 50.0 in stage 4.0 (TID 32) (localhost, executor driver, partition 50, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:29.874+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Finished task 40.0 in stage 4.0 (TID 25). 5776 bytes result sent to driver
[2024-12-14T19:41:29.875+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Running task 49.0 in stage 4.0 (TID 31)
[2024-12-14T19:41:29.877+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Finished task 12.0 in stage 4.0 (TID 12) in 499 ms on localhost (executor driver) (11/200)
[2024-12-14T19:41:29.879+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Running task 50.0 in stage 4.0 (TID 32)
[2024-12-14T19:41:29.881+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Starting task 51.0 in stage 4.0 (TID 33) (localhost, executor driver, partition 51, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:29.883+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Finished task 46.0 in stage 4.0 (TID 28). 5776 bytes result sent to driver
[2024-12-14T19:41:29.886+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Finished task 6.0 in stage 4.0 (TID 8) in 525 ms on localhost (executor driver) (12/200)
24/12/14 19:41:29 INFO Executor: Running task 51.0 in stage 4.0 (TID 33)
[2024-12-14T19:41:29.890+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Starting task 52.0 in stage 4.0 (TID 34) (localhost, executor driver, partition 52, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:29.894+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Finished task 42.0 in stage 4.0 (TID 26). 5776 bytes result sent to driver
[2024-12-14T19:41:29.901+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Finished task 19.0 in stage 4.0 (TID 15) in 508 ms on localhost (executor driver) (13/200)
[2024-12-14T19:41:29.903+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Running task 52.0 in stage 4.0 (TID 34)
[2024-12-14T19:41:29.904+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Finished task 34.0 in stage 4.0 (TID 22). 5776 bytes result sent to driver
[2024-12-14T19:41:29.906+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Finished task 39.0 in stage 4.0 (TID 24). 5776 bytes result sent to driver
[2024-12-14T19:41:29.909+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Starting task 53.0 in stage 4.0 (TID 35) (localhost, executor driver, partition 53, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:29.911+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:29.913+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
24/12/14 19:41:29 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 5) in 555 ms on localhost (executor driver) (14/200)
[2024-12-14T19:41:29.916+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:29.918+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
[2024-12-14T19:41:29.925+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Finished task 9.0 in stage 4.0 (TID 11) in 537 ms on localhost (executor driver) (15/200)
24/12/14 19:41:29 INFO Executor: Running task 53.0 in stage 4.0 (TID 35)
[2024-12-14T19:41:29.928+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Starting task 54.0 in stage 4.0 (TID 36) (localhost, executor driver, partition 54, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:29.932+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Finished task 7.0 in stage 4.0 (TID 9) in 549 ms on localhost (executor driver) (16/200)
24/12/14 19:41:29 INFO Executor: Running task 54.0 in stage 4.0 (TID 36)
[2024-12-14T19:41:29.934+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Starting task 57.0 in stage 4.0 (TID 37) (localhost, executor driver, partition 57, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:29.940+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:29.942+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Running task 57.0 in stage 4.0 (TID 37)
24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:29 INFO TaskSetManager: Starting task 59.0 in stage 4.0 (TID 38) (localhost, executor driver, partition 59, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:29.945+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Running task 59.0 in stage 4.0 (TID 38)
[2024-12-14T19:41:29.947+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
24/12/14 19:41:29 INFO TaskSetManager: Starting task 60.0 in stage 4.0 (TID 39) (localhost, executor driver, partition 60, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:29.948+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Finished task 32.0 in stage 4.0 (TID 21) in 234 ms on localhost (executor driver) (17/200)
[2024-12-14T19:41:29.959+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Finished task 35.0 in stage 4.0 (TID 23) in 176 ms on localhost (executor driver) (18/200)
24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:29 INFO Executor: Running task 60.0 in stage 4.0 (TID 39)
[2024-12-14T19:41:29.962+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Finished task 40.0 in stage 4.0 (TID 25) in 169 ms on localhost (executor driver) (19/200)
[2024-12-14T19:41:29.965+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Finished task 31.0 in stage 4.0 (TID 20) in 267 ms on localhost (executor driver) (20/200)
24/12/14 19:41:29 INFO Executor: Finished task 48.0 in stage 4.0 (TID 30). 5819 bytes result sent to driver
[2024-12-14T19:41:29.967+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
[2024-12-14T19:41:29.995+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Starting task 61.0 in stage 4.0 (TID 40) (localhost, executor driver, partition 61, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.000+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Finished task 43.0 in stage 4.0 (TID 27). 5862 bytes result sent to driver
[2024-12-14T19:41:30.012+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO TaskSetManager: Starting task 62.0 in stage 4.0 (TID 41) (localhost, executor driver, partition 62, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.014+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Running task 61.0 in stage 4.0 (TID 40)
[2024-12-14T19:41:30.016+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Finished task 47.0 in stage 4.0 (TID 29). 5862 bytes result sent to driver
[2024-12-14T19:41:30.022+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Running task 62.0 in stage 4.0 (TID 41)
24/12/14 19:41:29 INFO TaskSetManager: Finished task 46.0 in stage 4.0 (TID 28) in 198 ms on localhost (executor driver) (21/200)
[2024-12-14T19:41:30.031+0000] {docker.py:413} INFO - 24/12/14 19:41:29 INFO Executor: Finished task 51.0 in stage 4.0 (TID 33). 5862 bytes result sent to driver
[2024-12-14T19:41:30.039+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 63.0 in stage 4.0 (TID 42) (localhost, executor driver, partition 63, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.044+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 49.0 in stage 4.0 (TID 31). 5819 bytes result sent to driver
[2024-12-14T19:41:30.048+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 63.0 in stage 4.0 (TID 42)
[2024-12-14T19:41:30.052+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:30 INFO Executor: Finished task 52.0 in stage 4.0 (TID 34). 5819 bytes result sent to driver
[2024-12-14T19:41:30.056+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2024-12-14T19:41:30.058+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 64.0 in stage 4.0 (TID 43) (localhost, executor driver, partition 64, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.060+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 64.0 in stage 4.0 (TID 43)
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
[2024-12-14T19:41:30.066+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 39.0 in stage 4.0 (TID 24) in 269 ms on localhost (executor driver) (22/200)
[2024-12-14T19:41:30.069+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 50.0 in stage 4.0 (TID 32). 5819 bytes result sent to driver
[2024-12-14T19:41:30.073+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 34.0 in stage 4.0 (TID 22) in 288 ms on localhost (executor driver) (23/200)
[2024-12-14T19:41:30.076+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.079+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:30.102+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 68.0 in stage 4.0 (TID 44) (localhost, executor driver, partition 68, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.106+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:30 INFO TaskSetManager: Finished task 42.0 in stage 4.0 (TID 26) in 323 ms on localhost (executor driver) (24/200)
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2024-12-14T19:41:30.109+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.115+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2024-12-14T19:41:30.118+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 69.0 in stage 4.0 (TID 45) (localhost, executor driver, partition 69, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.127+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 68.0 in stage 4.0 (TID 44)
[2024-12-14T19:41:30.131+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 54.0 in stage 4.0 (TID 36). 5819 bytes result sent to driver
24/12/14 19:41:30 INFO Executor: Finished task 53.0 in stage 4.0 (TID 35). 5819 bytes result sent to driver
[2024-12-14T19:41:30.137+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 48.0 in stage 4.0 (TID 30) in 284 ms on localhost (executor driver) (25/200)
[2024-12-14T19:41:30.143+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 69.0 in stage 4.0 (TID 45)
[2024-12-14T19:41:30.149+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.156+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 70.0 in stage 4.0 (TID 46) (localhost, executor driver, partition 70, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.159+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
24/12/14 19:41:30 INFO Executor: Finished task 57.0 in stage 4.0 (TID 37). 5862 bytes result sent to driver
[2024-12-14T19:41:30.163+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 43.0 in stage 4.0 (TID 27) in 347 ms on localhost (executor driver) (26/200)
[2024-12-14T19:41:30.168+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 70.0 in stage 4.0 (TID 46)
[2024-12-14T19:41:30.171+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 59.0 in stage 4.0 (TID 38). 5862 bytes result sent to driver
24/12/14 19:41:30 INFO Executor: Finished task 61.0 in stage 4.0 (TID 40). 5862 bytes result sent to driver
24/12/14 19:41:30 INFO TaskSetManager: Starting task 71.0 in stage 4.0 (TID 47) (localhost, executor driver, partition 71, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.173+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 60.0 in stage 4.0 (TID 39). 5819 bytes result sent to driver
[2024-12-14T19:41:30.180+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.184+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2024-12-14T19:41:30.192+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 71.0 in stage 4.0 (TID 47)
[2024-12-14T19:41:30.194+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.199+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2024-12-14T19:41:30.201+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.204+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2024-12-14T19:41:30.209+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 72.0 in stage 4.0 (TID 48) (localhost, executor driver, partition 72, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.213+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 63.0 in stage 4.0 (TID 42). 5819 bytes result sent to driver
[2024-12-14T19:41:30.220+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.223+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2024-12-14T19:41:30.225+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 72.0 in stage 4.0 (TID 48)
[2024-12-14T19:41:30.227+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 68.0 in stage 4.0 (TID 44). 5776 bytes result sent to driver
[2024-12-14T19:41:30.230+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 62.0 in stage 4.0 (TID 41). 5819 bytes result sent to driver
[2024-12-14T19:41:30.233+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.235+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
24/12/14 19:41:30 INFO TaskSetManager: Starting task 73.0 in stage 4.0 (TID 49) (localhost, executor driver, partition 73, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.241+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 73.0 in stage 4.0 (TID 49)
[2024-12-14T19:41:30.245+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 74.0 in stage 4.0 (TID 50) (localhost, executor driver, partition 74, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.259+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 74.0 in stage 4.0 (TID 50)
[2024-12-14T19:41:30.262+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 51.0 in stage 4.0 (TID 33) in 365 ms on localhost (executor driver) (27/200)
[2024-12-14T19:41:30.266+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 47.0 in stage 4.0 (TID 29) in 420 ms on localhost (executor driver) (28/200)
[2024-12-14T19:41:30.268+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 50.0 in stage 4.0 (TID 32) in 384 ms on localhost (executor driver) (29/200)
24/12/14 19:41:30 INFO TaskSetManager: Finished task 52.0 in stage 4.0 (TID 34) in 361 ms on localhost (executor driver) (30/200)
[2024-12-14T19:41:30.270+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 64.0 in stage 4.0 (TID 43). 5819 bytes result sent to driver
[2024-12-14T19:41:30.273+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 69.0 in stage 4.0 (TID 45). 5819 bytes result sent to driver
[2024-12-14T19:41:30.276+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 75.0 in stage 4.0 (TID 51) (localhost, executor driver, partition 75, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.278+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2024-12-14T19:41:30.280+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 75.0 in stage 4.0 (TID 51)
[2024-12-14T19:41:30.283+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 76.0 in stage 4.0 (TID 52) (localhost, executor driver, partition 76, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.285+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 49.0 in stage 4.0 (TID 31) in 424 ms on localhost (executor driver) (31/200)
[2024-12-14T19:41:30.286+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 76.0 in stage 4.0 (TID 52)
[2024-12-14T19:41:30.287+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.290+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:30.291+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 71.0 in stage 4.0 (TID 47). 5776 bytes result sent to driver
[2024-12-14T19:41:30.296+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 70.0 in stage 4.0 (TID 46). 5819 bytes result sent to driver
[2024-12-14T19:41:30.297+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 77.0 in stage 4.0 (TID 53) (localhost, executor driver, partition 77, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.299+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 54.0 in stage 4.0 (TID 36) in 383 ms on localhost (executor driver) (32/200)
[2024-12-14T19:41:30.302+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 53.0 in stage 4.0 (TID 35) in 399 ms on localhost (executor driver) (33/200)
[2024-12-14T19:41:30.306+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 57.0 in stage 4.0 (TID 37) in 382 ms on localhost (executor driver) (34/200)
[2024-12-14T19:41:30.308+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 77.0 in stage 4.0 (TID 53)
[2024-12-14T19:41:30.311+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:30.315+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 73.0 in stage 4.0 (TID 49). 5776 bytes result sent to driver
[2024-12-14T19:41:30.318+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 78.0 in stage 4.0 (TID 54) (localhost, executor driver, partition 78, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.321+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 78.0 in stage 4.0 (TID 54)
[2024-12-14T19:41:30.323+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 79.0 in stage 4.0 (TID 55) (localhost, executor driver, partition 79, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:30 INFO Executor: Running task 79.0 in stage 4.0 (TID 55)
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:30.325+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 74.0 in stage 4.0 (TID 50). 5819 bytes result sent to driver
[2024-12-14T19:41:30.326+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:30 INFO TaskSetManager: Starting task 80.0 in stage 4.0 (TID 56) (localhost, executor driver, partition 80, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.329+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:30.333+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 59.0 in stage 4.0 (TID 38) in 402 ms on localhost (executor driver) (35/200)
[2024-12-14T19:41:30.338+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 80.0 in stage 4.0 (TID 56)
[2024-12-14T19:41:30.344+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 81.0 in stage 4.0 (TID 57) (localhost, executor driver, partition 81, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.348+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 72.0 in stage 4.0 (TID 48). 5776 bytes result sent to driver
[2024-12-14T19:41:30.351+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 81.0 in stage 4.0 (TID 57)
[2024-12-14T19:41:30.354+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 82.0 in stage 4.0 (TID 58) (localhost, executor driver, partition 82, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.356+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 83.0 in stage 4.0 (TID 59) (localhost, executor driver, partition 83, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.358+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 82.0 in stage 4.0 (TID 58)
[2024-12-14T19:41:30.361+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 84.0 in stage 4.0 (TID 60) (localhost, executor driver, partition 84, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.362+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 83.0 in stage 4.0 (TID 59)
[2024-12-14T19:41:30.365+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 76.0 in stage 4.0 (TID 52). 5776 bytes result sent to driver
[2024-12-14T19:41:30.368+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 60.0 in stage 4.0 (TID 39) in 416 ms on localhost (executor driver) (36/200)
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
24/12/14 19:41:30 INFO TaskSetManager: Finished task 63.0 in stage 4.0 (TID 42) in 335 ms on localhost (executor driver) (37/200)
[2024-12-14T19:41:30.375+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 84.0 in stage 4.0 (TID 60)
[2024-12-14T19:41:30.378+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.381+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:30.384+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 61.0 in stage 4.0 (TID 40) in 391 ms on localhost (executor driver) (38/200)
[2024-12-14T19:41:30.387+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 68.0 in stage 4.0 (TID 44) in 264 ms on localhost (executor driver) (39/200)
24/12/14 19:41:30 INFO TaskSetManager: Finished task 62.0 in stage 4.0 (TID 41) in 359 ms on localhost (executor driver) (40/200)
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:30.392+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 85.0 in stage 4.0 (TID 61) (localhost, executor driver, partition 85, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.398+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 85.0 in stage 4.0 (TID 61)
24/12/14 19:41:30 INFO Executor: Finished task 75.0 in stage 4.0 (TID 51). 5819 bytes result sent to driver
[2024-12-14T19:41:30.401+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:30.406+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 79.0 in stage 4.0 (TID 55). 5776 bytes result sent to driver
[2024-12-14T19:41:30.411+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:30.416+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 86.0 in stage 4.0 (TID 62) (localhost, executor driver, partition 86, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.418+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 86.0 in stage 4.0 (TID 62)
24/12/14 19:41:30 INFO TaskSetManager: Starting task 88.0 in stage 4.0 (TID 63) (localhost, executor driver, partition 88, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.424+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 88.0 in stage 4.0 (TID 63)
[2024-12-14T19:41:30.430+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 89.0 in stage 4.0 (TID 64) (localhost, executor driver, partition 89, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.433+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 89.0 in stage 4.0 (TID 64)
[2024-12-14T19:41:30.438+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 90.0 in stage 4.0 (TID 65) (localhost, executor driver, partition 90, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.439+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 90.0 in stage 4.0 (TID 65)
[2024-12-14T19:41:30.441+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 77.0 in stage 4.0 (TID 53). 5776 bytes result sent to driver
[2024-12-14T19:41:30.443+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.443+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 64.0 in stage 4.0 (TID 43) in 372 ms on localhost (executor driver) (41/200)
[2024-12-14T19:41:30.445+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
[2024-12-14T19:41:30.447+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 82.0 in stage 4.0 (TID 58). 5819 bytes result sent to driver
[2024-12-14T19:41:30.452+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.453+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 78.0 in stage 4.0 (TID 54). 5819 bytes result sent to driver
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:30.457+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 69.0 in stage 4.0 (TID 45) in 284 ms on localhost (executor driver) (42/200)
[2024-12-14T19:41:30.458+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 71.0 in stage 4.0 (TID 47) in 247 ms on localhost (executor driver) (43/200)
[2024-12-14T19:41:30.460+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 92.0 in stage 4.0 (TID 66) (localhost, executor driver, partition 92, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.462+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 70.0 in stage 4.0 (TID 46) in 276 ms on localhost (executor driver) (44/200)
[2024-12-14T19:41:30.465+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.468+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.472+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:30 INFO Executor: Running task 92.0 in stage 4.0 (TID 66)
[2024-12-14T19:41:30.476+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.480+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 15 ms
24/12/14 19:41:30 INFO TaskSetManager: Starting task 95.0 in stage 4.0 (TID 67) (localhost, executor driver, partition 95, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:30 INFO TaskSetManager: Finished task 74.0 in stage 4.0 (TID 50) in 186 ms on localhost (executor driver) (45/200)
[2024-12-14T19:41:30.484+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 95.0 in stage 4.0 (TID 67)
[2024-12-14T19:41:30.488+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 96.0 in stage 4.0 (TID 68) (localhost, executor driver, partition 96, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:30 INFO TaskSetManager: Starting task 97.0 in stage 4.0 (TID 69) (localhost, executor driver, partition 97, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.493+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 97.0 in stage 4.0 (TID 69)
[2024-12-14T19:41:30.495+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 72.0 in stage 4.0 (TID 48) in 264 ms on localhost (executor driver) (46/200)
[2024-12-14T19:41:30.497+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 96.0 in stage 4.0 (TID 68)
[2024-12-14T19:41:30.498+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.500+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 81.0 in stage 4.0 (TID 57). 5819 bytes result sent to driver
[2024-12-14T19:41:30.502+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:30.507+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 73.0 in stage 4.0 (TID 49) in 237 ms on localhost (executor driver) (47/200)
[2024-12-14T19:41:30.509+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 75.0 in stage 4.0 (TID 51) in 182 ms on localhost (executor driver) (48/200)
[2024-12-14T19:41:30.510+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 85.0 in stage 4.0 (TID 61). 5819 bytes result sent to driver
[2024-12-14T19:41:30.511+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 80.0 in stage 4.0 (TID 56). 5862 bytes result sent to driver
24/12/14 19:41:30 INFO Executor: Finished task 86.0 in stage 4.0 (TID 62). 5819 bytes result sent to driver
[2024-12-14T19:41:30.511+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 98.0 in stage 4.0 (TID 70) (localhost, executor driver, partition 98, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.512+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 84.0 in stage 4.0 (TID 60). 5819 bytes result sent to driver
[2024-12-14T19:41:30.513+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 89.0 in stage 4.0 (TID 64). 5819 bytes result sent to driver
[2024-12-14T19:41:30.514+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 98.0 in stage 4.0 (TID 70)
[2024-12-14T19:41:30.516+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 99.0 in stage 4.0 (TID 71) (localhost, executor driver, partition 99, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.519+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 76.0 in stage 4.0 (TID 52) in 200 ms on localhost (executor driver) (49/200)
[2024-12-14T19:41:30.521+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 99.0 in stage 4.0 (TID 71)
[2024-12-14T19:41:30.523+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 88.0 in stage 4.0 (TID 63). 5819 bytes result sent to driver
[2024-12-14T19:41:30.524+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 100.0 in stage 4.0 (TID 72) (localhost, executor driver, partition 100, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.526+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:30 INFO Executor: Finished task 83.0 in stage 4.0 (TID 59). 5819 bytes result sent to driver
[2024-12-14T19:41:30.528+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 79.0 in stage 4.0 (TID 55) in 169 ms on localhost (executor driver) (50/200)
[2024-12-14T19:41:30.529+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 100.0 in stage 4.0 (TID 72)
[2024-12-14T19:41:30.531+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 82.0 in stage 4.0 (TID 58) in 149 ms on localhost (executor driver) (51/200)
[2024-12-14T19:41:30.532+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 77.0 in stage 4.0 (TID 53) in 198 ms on localhost (executor driver) (52/200)
[2024-12-14T19:41:30.533+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:30 INFO Executor: Finished task 90.0 in stage 4.0 (TID 65). 5819 bytes result sent to driver
24/12/14 19:41:30 INFO TaskSetManager: Starting task 101.0 in stage 4.0 (TID 73) (localhost, executor driver, partition 101, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.535+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:30.537+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 78.0 in stage 4.0 (TID 54) in 187 ms on localhost (executor driver) (53/200)
[2024-12-14T19:41:30.538+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2024-12-14T19:41:30.543+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 101.0 in stage 4.0 (TID 73)
[2024-12-14T19:41:30.545+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.546+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:30.549+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 102.0 in stage 4.0 (TID 74) (localhost, executor driver, partition 102, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.550+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 85.0 in stage 4.0 (TID 61) in 143 ms on localhost (executor driver) (54/200)
[2024-12-14T19:41:30.552+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.554+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 81.0 in stage 4.0 (TID 57) in 175 ms on localhost (executor driver) (55/200)
[2024-12-14T19:41:30.559+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:30.565+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 102.0 in stage 4.0 (TID 74)
[2024-12-14T19:41:30.568+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 103.0 in stage 4.0 (TID 75) (localhost, executor driver, partition 103, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.570+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 103.0 in stage 4.0 (TID 75)
[2024-12-14T19:41:30.572+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 80.0 in stage 4.0 (TID 56) in 198 ms on localhost (executor driver) (56/200)
[2024-12-14T19:41:30.575+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 92.0 in stage 4.0 (TID 66). 5819 bytes result sent to driver
[2024-12-14T19:41:30.584+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.587+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 35 ms
[2024-12-14T19:41:30.590+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.592+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
[2024-12-14T19:41:30.597+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 104.0 in stage 4.0 (TID 76) (localhost, executor driver, partition 104, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.599+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 104.0 in stage 4.0 (TID 76)
24/12/14 19:41:30 INFO TaskSetManager: Starting task 105.0 in stage 4.0 (TID 77) (localhost, executor driver, partition 105, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.601+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 105.0 in stage 4.0 (TID 77)
[2024-12-14T19:41:30.605+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 106.0 in stage 4.0 (TID 78) (localhost, executor driver, partition 106, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.611+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:30 INFO Executor: Finished task 98.0 in stage 4.0 (TID 70). 5862 bytes result sent to driver
[2024-12-14T19:41:30.615+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 19 ms
[2024-12-14T19:41:30.621+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 106.0 in stage 4.0 (TID 78)
[2024-12-14T19:41:30.625+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 108.0 in stage 4.0 (TID 79) (localhost, executor driver, partition 108, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.628+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 96.0 in stage 4.0 (TID 68). 5819 bytes result sent to driver
[2024-12-14T19:41:30.631+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 86.0 in stage 4.0 (TID 62) in 207 ms on localhost (executor driver) (57/200)
[2024-12-14T19:41:30.635+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 108.0 in stage 4.0 (TID 79)
[2024-12-14T19:41:30.638+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 95.0 in stage 4.0 (TID 67). 5819 bytes result sent to driver
[2024-12-14T19:41:30.640+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 109.0 in stage 4.0 (TID 80) (localhost, executor driver, partition 109, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.642+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 100.0 in stage 4.0 (TID 72). 5862 bytes result sent to driver
[2024-12-14T19:41:30.647+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 89.0 in stage 4.0 (TID 64) in 210 ms on localhost (executor driver) (58/200)
[2024-12-14T19:41:30.651+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 97.0 in stage 4.0 (TID 69). 5819 bytes result sent to driver
[2024-12-14T19:41:30.655+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.657+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
24/12/14 19:41:30 INFO Executor: Running task 109.0 in stage 4.0 (TID 80)
[2024-12-14T19:41:30.659+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 15 ms
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:30 INFO TaskSetManager: Starting task 111.0 in stage 4.0 (TID 81) (localhost, executor driver, partition 111, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.661+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 111.0 in stage 4.0 (TID 81)
[2024-12-14T19:41:30.663+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.666+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.668+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2024-12-14T19:41:30.670+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.675+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
24/12/14 19:41:30 INFO TaskSetManager: Starting task 113.0 in stage 4.0 (TID 82) (localhost, executor driver, partition 113, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.677+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 113.0 in stage 4.0 (TID 82)
[2024-12-14T19:41:30.679+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 120.0 in stage 4.0 (TID 83) (localhost, executor driver, partition 120, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.682+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 83.0 in stage 4.0 (TID 59) in 298 ms on localhost (executor driver) (59/200)
[2024-12-14T19:41:30.685+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 92.0 in stage 4.0 (TID 66) in 224 ms on localhost (executor driver) (60/200)
[2024-12-14T19:41:30.688+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 103.0 in stage 4.0 (TID 75). 5819 bytes result sent to driver
[2024-12-14T19:41:30.690+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 101.0 in stage 4.0 (TID 73). 5819 bytes result sent to driver
[2024-12-14T19:41:30.691+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 88.0 in stage 4.0 (TID 63) in 257 ms on localhost (executor driver) (61/200)
[2024-12-14T19:41:30.693+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 90.0 in stage 4.0 (TID 65) in 257 ms on localhost (executor driver) (62/200)
[2024-12-14T19:41:30.694+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 120.0 in stage 4.0 (TID 83)
24/12/14 19:41:30 INFO TaskSetManager: Finished task 84.0 in stage 4.0 (TID 60) in 308 ms on localhost (executor driver) (63/200)
[2024-12-14T19:41:30.696+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 123.0 in stage 4.0 (TID 84) (localhost, executor driver, partition 123, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.698+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 99.0 in stage 4.0 (TID 71). 5862 bytes result sent to driver
24/12/14 19:41:30 INFO TaskSetManager: Finished task 98.0 in stage 4.0 (TID 70) in 192 ms on localhost (executor driver) (64/200)
[2024-12-14T19:41:30.700+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 124.0 in stage 4.0 (TID 85) (localhost, executor driver, partition 124, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.703+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 104.0 in stage 4.0 (TID 76). 5776 bytes result sent to driver
[2024-12-14T19:41:30.706+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 123.0 in stage 4.0 (TID 84)
[2024-12-14T19:41:30.709+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 102.0 in stage 4.0 (TID 74). 5862 bytes result sent to driver
[2024-12-14T19:41:30.712+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 124.0 in stage 4.0 (TID 85)
24/12/14 19:41:30 INFO Executor: Finished task 106.0 in stage 4.0 (TID 78). 5776 bytes result sent to driver
[2024-12-14T19:41:30.715+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 125.0 in stage 4.0 (TID 86) (localhost, executor driver, partition 125, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.723+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.726+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
24/12/14 19:41:30 INFO Executor: Finished task 108.0 in stage 4.0 (TID 79). 5776 bytes result sent to driver
24/12/14 19:41:30 INFO Executor: Running task 125.0 in stage 4.0 (TID 86)
24/12/14 19:41:30 INFO Executor: Finished task 105.0 in stage 4.0 (TID 77). 5819 bytes result sent to driver
24/12/14 19:41:30 INFO TaskSetManager: Starting task 127.0 in stage 4.0 (TID 87) (localhost, executor driver, partition 127, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.728+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
24/12/14 19:41:30 INFO TaskSetManager: Finished task 96.0 in stage 4.0 (TID 68) in 281 ms on localhost (executor driver) (65/200)
[2024-12-14T19:41:30.731+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.732+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 127.0 in stage 4.0 (TID 87)
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:30 INFO TaskSetManager: Finished task 95.0 in stage 4.0 (TID 67) in 292 ms on localhost (executor driver) (66/200)
[2024-12-14T19:41:30.733+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.735+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:30.737+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 129.0 in stage 4.0 (TID 88) (localhost, executor driver, partition 129, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.738+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 100.0 in stage 4.0 (TID 72) in 248 ms on localhost (executor driver) (67/200)
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.740+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:30.742+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 97.0 in stage 4.0 (TID 69) in 293 ms on localhost (executor driver) (68/200)
[2024-12-14T19:41:30.743+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 129.0 in stage 4.0 (TID 88)
[2024-12-14T19:41:30.744+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 101.0 in stage 4.0 (TID 73) in 240 ms on localhost (executor driver) (69/200)
[2024-12-14T19:41:30.746+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.747+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:30.752+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 103.0 in stage 4.0 (TID 75) in 222 ms on localhost (executor driver) (70/200)
24/12/14 19:41:30 INFO Executor: Finished task 111.0 in stage 4.0 (TID 81). 5776 bytes result sent to driver
[2024-12-14T19:41:30.754+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 130.0 in stage 4.0 (TID 89) (localhost, executor driver, partition 130, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.755+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 109.0 in stage 4.0 (TID 80). 5776 bytes result sent to driver
[2024-12-14T19:41:30.757+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 130.0 in stage 4.0 (TID 89)
24/12/14 19:41:30 INFO Executor: Finished task 123.0 in stage 4.0 (TID 84). 5776 bytes result sent to driver
[2024-12-14T19:41:30.758+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 113.0 in stage 4.0 (TID 82). 5776 bytes result sent to driver
[2024-12-14T19:41:30.760+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.762+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2024-12-14T19:41:30.764+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 132.0 in stage 4.0 (TID 90) (localhost, executor driver, partition 132, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.766+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 120.0 in stage 4.0 (TID 83). 5776 bytes result sent to driver
[2024-12-14T19:41:30.768+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 132.0 in stage 4.0 (TID 90)
[2024-12-14T19:41:30.769+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 124.0 in stage 4.0 (TID 85). 5819 bytes result sent to driver
[2024-12-14T19:41:30.773+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 135.0 in stage 4.0 (TID 91) (localhost, executor driver, partition 135, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.777+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 135.0 in stage 4.0 (TID 91)
[2024-12-14T19:41:30.779+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 136.0 in stage 4.0 (TID 92) (localhost, executor driver, partition 136, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.781+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 99.0 in stage 4.0 (TID 71) in 306 ms on localhost (executor driver) (71/200)
[2024-12-14T19:41:30.782+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 104.0 in stage 4.0 (TID 76) in 209 ms on localhost (executor driver) (72/200)
24/12/14 19:41:30 INFO TaskSetManager: Finished task 102.0 in stage 4.0 (TID 74) in 274 ms on localhost (executor driver) (73/200)
[2024-12-14T19:41:30.784+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.786+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:30.791+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2024-12-14T19:41:30.793+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.795+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:30.798+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 136.0 in stage 4.0 (TID 92)
[2024-12-14T19:41:30.800+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 137.0 in stage 4.0 (TID 93) (localhost, executor driver, partition 137, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.802+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 137.0 in stage 4.0 (TID 93)
[2024-12-14T19:41:30.804+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 142.0 in stage 4.0 (TID 94) (localhost, executor driver, partition 142, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.806+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 106.0 in stage 4.0 (TID 78) in 218 ms on localhost (executor driver) (74/200)
[2024-12-14T19:41:30.808+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 142.0 in stage 4.0 (TID 94)
[2024-12-14T19:41:30.810+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 125.0 in stage 4.0 (TID 86). 5776 bytes result sent to driver
[2024-12-14T19:41:30.812+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 145.0 in stage 4.0 (TID 95) (localhost, executor driver, partition 145, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.814+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:30.815+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 145.0 in stage 4.0 (TID 95)
[2024-12-14T19:41:30.817+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 146.0 in stage 4.0 (TID 96) (localhost, executor driver, partition 146, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.820+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 108.0 in stage 4.0 (TID 79) in 221 ms on localhost (executor driver) (75/200)
[2024-12-14T19:41:30.821+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 146.0 in stage 4.0 (TID 96)
[2024-12-14T19:41:30.822+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.824+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:30.826+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 105.0 in stage 4.0 (TID 77) in 235 ms on localhost (executor driver) (76/200)
[2024-12-14T19:41:30.828+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 148.0 in stage 4.0 (TID 97) (localhost, executor driver, partition 148, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.830+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 111.0 in stage 4.0 (TID 81) in 212 ms on localhost (executor driver) (77/200)
[2024-12-14T19:41:30.832+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 129.0 in stage 4.0 (TID 88). 5776 bytes result sent to driver
[2024-12-14T19:41:30.833+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 135.0 in stage 4.0 (TID 91). 5776 bytes result sent to driver
24/12/14 19:41:30 INFO Executor: Finished task 127.0 in stage 4.0 (TID 87). 5776 bytes result sent to driver
[2024-12-14T19:41:30.834+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 148.0 in stage 4.0 (TID 97)
24/12/14 19:41:30 INFO Executor: Finished task 130.0 in stage 4.0 (TID 89). 5819 bytes result sent to driver
[2024-12-14T19:41:30.836+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 149.0 in stage 4.0 (TID 98) (localhost, executor driver, partition 149, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.837+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 149.0 in stage 4.0 (TID 98)
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.839+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 150.0 in stage 4.0 (TID 99) (localhost, executor driver, partition 150, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.841+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
24/12/14 19:41:30 INFO Executor: Running task 150.0 in stage 4.0 (TID 99)
[2024-12-14T19:41:30.844+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 151.0 in stage 4.0 (TID 100) (localhost, executor driver, partition 151, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.846+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 109.0 in stage 4.0 (TID 80) in 238 ms on localhost (executor driver) (78/200)
[2024-12-14T19:41:30.849+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.851+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 123.0 in stage 4.0 (TID 84) in 180 ms on localhost (executor driver) (79/200)
[2024-12-14T19:41:30.853+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:30.855+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 151.0 in stage 4.0 (TID 100)
[2024-12-14T19:41:30.856+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
24/12/14 19:41:30 INFO Executor: Finished task 132.0 in stage 4.0 (TID 90). 5819 bytes result sent to driver
24/12/14 19:41:30 INFO TaskSetManager: Finished task 113.0 in stage 4.0 (TID 82) in 215 ms on localhost (executor driver) (80/200)
[2024-12-14T19:41:30.858+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.862+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:30.865+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 152.0 in stage 4.0 (TID 101) (localhost, executor driver, partition 152, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.866+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 120.0 in stage 4.0 (TID 83) in 215 ms on localhost (executor driver) (81/200)
[2024-12-14T19:41:30.868+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 152.0 in stage 4.0 (TID 101)
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.871+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2024-12-14T19:41:30.872+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 142.0 in stage 4.0 (TID 94). 5776 bytes result sent to driver
24/12/14 19:41:30 INFO TaskSetManager: Starting task 154.0 in stage 4.0 (TID 102) (localhost, executor driver, partition 154, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:30 INFO Executor: Running task 154.0 in stage 4.0 (TID 102)
24/12/14 19:41:30 INFO TaskSetManager: Starting task 158.0 in stage 4.0 (TID 103) (localhost, executor driver, partition 158, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:30 INFO Executor: Running task 158.0 in stage 4.0 (TID 103)
24/12/14 19:41:30 INFO TaskSetManager: Starting task 159.0 in stage 4.0 (TID 104) (localhost, executor driver, partition 159, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.875+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:30 INFO Executor: Finished task 145.0 in stage 4.0 (TID 95). 5819 bytes result sent to driver
[2024-12-14T19:41:30.877+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 161.0 in stage 4.0 (TID 105) (localhost, executor driver, partition 161, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.880+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 124.0 in stage 4.0 (TID 85) in 211 ms on localhost (executor driver) (82/200)
24/12/14 19:41:30 INFO Executor: Running task 161.0 in stage 4.0 (TID 105)
[2024-12-14T19:41:30.882+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 159.0 in stage 4.0 (TID 104)
[2024-12-14T19:41:30.884+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 162.0 in stage 4.0 (TID 106) (localhost, executor driver, partition 162, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:30 INFO Executor: Finished task 137.0 in stage 4.0 (TID 93). 5776 bytes result sent to driver
[2024-12-14T19:41:30.886+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 146.0 in stage 4.0 (TID 96). 5776 bytes result sent to driver
[2024-12-14T19:41:30.887+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 135.0 in stage 4.0 (TID 91) in 113 ms on localhost (executor driver) (83/200)
24/12/14 19:41:30 INFO Executor: Running task 162.0 in stage 4.0 (TID 106)
[2024-12-14T19:41:30.889+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 125.0 in stage 4.0 (TID 86) in 194 ms on localhost (executor driver) (84/200)
[2024-12-14T19:41:30.890+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 129.0 in stage 4.0 (TID 88) in 160 ms on localhost (executor driver) (85/200)
[2024-12-14T19:41:30.891+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 127.0 in stage 4.0 (TID 87) in 183 ms on localhost (executor driver) (86/200)
[2024-12-14T19:41:30.893+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 164.0 in stage 4.0 (TID 107) (localhost, executor driver, partition 164, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.896+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.898+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:30.899+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.901+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:30.903+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 164.0 in stage 4.0 (TID 107)
[2024-12-14T19:41:30.906+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 136.0 in stage 4.0 (TID 92). 5776 bytes result sent to driver
[2024-12-14T19:41:30.910+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.912+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
24/12/14 19:41:30 INFO TaskSetManager: Starting task 165.0 in stage 4.0 (TID 108) (localhost, executor driver, partition 165, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:30 INFO TaskSetManager: Finished task 132.0 in stage 4.0 (TID 90) in 150 ms on localhost (executor driver) (87/200)
[2024-12-14T19:41:30.914+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 150.0 in stage 4.0 (TID 99). 5776 bytes result sent to driver
[2024-12-14T19:41:30.917+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.918+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:30.921+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 149.0 in stage 4.0 (TID 98). 5776 bytes result sent to driver
[2024-12-14T19:41:30.923+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 165.0 in stage 4.0 (TID 108)
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.929+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:30 INFO TaskSetManager: Starting task 167.0 in stage 4.0 (TID 109) (localhost, executor driver, partition 167, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:30.933+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 167.0 in stage 4.0 (TID 109)
[2024-12-14T19:41:30.938+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 148.0 in stage 4.0 (TID 97). 5776 bytes result sent to driver
[2024-12-14T19:41:30.942+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 154.0 in stage 4.0 (TID 102). 5776 bytes result sent to driver
[2024-12-14T19:41:30.946+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 168.0 in stage 4.0 (TID 110) (localhost, executor driver, partition 168, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:30 INFO Executor: Running task 168.0 in stage 4.0 (TID 110)
[2024-12-14T19:41:30.948+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 170.0 in stage 4.0 (TID 111) (localhost, executor driver, partition 170, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:30 INFO Executor: Running task 170.0 in stage 4.0 (TID 111)
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:30.951+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 171.0 in stage 4.0 (TID 112) (localhost, executor driver, partition 171, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.953+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 171.0 in stage 4.0 (TID 112)
[2024-12-14T19:41:30.955+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 172.0 in stage 4.0 (TID 113) (localhost, executor driver, partition 172, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.958+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 152.0 in stage 4.0 (TID 101). 5776 bytes result sent to driver
[2024-12-14T19:41:30.961+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 130.0 in stage 4.0 (TID 89) in 197 ms on localhost (executor driver) (88/200)
[2024-12-14T19:41:30.963+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 145.0 in stage 4.0 (TID 95) in 148 ms on localhost (executor driver) (89/200)
[2024-12-14T19:41:30.966+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 158.0 in stage 4.0 (TID 103). 5776 bytes result sent to driver
[2024-12-14T19:41:30.969+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 172.0 in stage 4.0 (TID 113)
[2024-12-14T19:41:30.972+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.974+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 161.0 in stage 4.0 (TID 105). 5819 bytes result sent to driver
[2024-12-14T19:41:30.976+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2024-12-14T19:41:30.978+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 137.0 in stage 4.0 (TID 93) in 164 ms on localhost (executor driver) (90/200)
[2024-12-14T19:41:30.979+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 142.0 in stage 4.0 (TID 94) in 161 ms on localhost (executor driver) (91/200)
[2024-12-14T19:41:30.981+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 159.0 in stage 4.0 (TID 104). 5819 bytes result sent to driver
24/12/14 19:41:30 INFO Executor: Finished task 164.0 in stage 4.0 (TID 107). 5776 bytes result sent to driver
[2024-12-14T19:41:30.983+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 146.0 in stage 4.0 (TID 96) in 161 ms on localhost (executor driver) (92/200)
[2024-12-14T19:41:30.984+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 173.0 in stage 4.0 (TID 114) (localhost, executor driver, partition 173, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:30.986+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 151.0 in stage 4.0 (TID 100). 5819 bytes result sent to driver
[2024-12-14T19:41:30.988+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 150.0 in stage 4.0 (TID 99) in 140 ms on localhost (executor driver) (93/200)
[2024-12-14T19:41:30.990+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:30.992+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:30.994+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 162.0 in stage 4.0 (TID 106). 5819 bytes result sent to driver
[2024-12-14T19:41:30.997+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 149.0 in stage 4.0 (TID 98) in 155 ms on localhost (executor driver) (94/200)
[2024-12-14T19:41:30.999+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 173.0 in stage 4.0 (TID 114)
[2024-12-14T19:41:31.002+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.004+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:30 INFO TaskSetManager: Starting task 174.0 in stage 4.0 (TID 115) (localhost, executor driver, partition 174, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.006+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 136.0 in stage 4.0 (TID 92) in 202 ms on localhost (executor driver) (95/200)
[2024-12-14T19:41:31.009+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 174.0 in stage 4.0 (TID 115)
[2024-12-14T19:41:31.012+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 168.0 in stage 4.0 (TID 110). 5819 bytes result sent to driver
[2024-12-14T19:41:31.020+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.023+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:31.024+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 175.0 in stage 4.0 (TID 116) (localhost, executor driver, partition 175, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.032+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 148.0 in stage 4.0 (TID 97) in 188 ms on localhost (executor driver) (96/200)
24/12/14 19:41:30 INFO Executor: Finished task 165.0 in stage 4.0 (TID 108). 5819 bytes result sent to driver
[2024-12-14T19:41:31.034+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 154.0 in stage 4.0 (TID 102) in 146 ms on localhost (executor driver) (97/200)
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2024-12-14T19:41:31.035+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 175.0 in stage 4.0 (TID 116)
[2024-12-14T19:41:31.037+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Finished task 167.0 in stage 4.0 (TID 109). 5819 bytes result sent to driver
[2024-12-14T19:41:31.038+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 179.0 in stage 4.0 (TID 117) (localhost, executor driver, partition 179, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.044+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 179.0 in stage 4.0 (TID 117)
[2024-12-14T19:41:31.046+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Starting task 181.0 in stage 4.0 (TID 118) (localhost, executor driver, partition 181, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.049+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO Executor: Running task 181.0 in stage 4.0 (TID 118)
[2024-12-14T19:41:31.052+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 152.0 in stage 4.0 (TID 101) in 173 ms on localhost (executor driver) (98/200)
[2024-12-14T19:41:31.054+0000] {docker.py:413} INFO - 24/12/14 19:41:30 INFO TaskSetManager: Finished task 161.0 in stage 4.0 (TID 105) in 146 ms on localhost (executor driver) (99/200)
[2024-12-14T19:41:31.055+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 184.0 in stage 4.0 (TID 119) (localhost, executor driver, partition 184, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.056+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 184.0 in stage 4.0 (TID 119)
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.057+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:31.059+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.063+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.067+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 186.0 in stage 4.0 (TID 120) (localhost, executor driver, partition 186, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.069+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 158.0 in stage 4.0 (TID 103) in 168 ms on localhost (executor driver) (100/200)
24/12/14 19:41:31 INFO Executor: Finished task 172.0 in stage 4.0 (TID 113). 5819 bytes result sent to driver
24/12/14 19:41:31 INFO Executor: Running task 186.0 in stage 4.0 (TID 120)
[2024-12-14T19:41:31.071+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:31 INFO Executor: Finished task 170.0 in stage 4.0 (TID 111). 5819 bytes result sent to driver
[2024-12-14T19:41:31.076+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.081+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 192.0 in stage 4.0 (TID 121) (localhost, executor driver, partition 192, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.083+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 194.0 in stage 4.0 (TID 122) (localhost, executor driver, partition 194, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.086+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 159.0 in stage 4.0 (TID 104) in 180 ms on localhost (executor driver) (101/200)
[2024-12-14T19:41:31.090+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 194.0 in stage 4.0 (TID 122)
[2024-12-14T19:41:31.092+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.094+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.098+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 171.0 in stage 4.0 (TID 112). 5819 bytes result sent to driver
[2024-12-14T19:41:31.102+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 192.0 in stage 4.0 (TID 121)
[2024-12-14T19:41:31.104+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 195.0 in stage 4.0 (TID 123) (localhost, executor driver, partition 195, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.106+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 173.0 in stage 4.0 (TID 114). 5819 bytes result sent to driver
[2024-12-14T19:41:31.108+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 174.0 in stage 4.0 (TID 115). 5819 bytes result sent to driver
[2024-12-14T19:41:31.112+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 195.0 in stage 4.0 (TID 123)
[2024-12-14T19:41:31.114+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.117+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 196.0 in stage 4.0 (TID 124) (localhost, executor driver, partition 196, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.120+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.123+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 164.0 in stage 4.0 (TID 107) in 165 ms on localhost (executor driver) (102/200)
[2024-12-14T19:41:31.125+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 196.0 in stage 4.0 (TID 124)
[2024-12-14T19:41:31.127+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 125) (localhost, executor driver, partition 1, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.129+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 1.0 in stage 4.0 (TID 125)
[2024-12-14T19:41:31.132+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.134+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.138+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 126) (localhost, executor driver, partition 2, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.140+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 179.0 in stage 4.0 (TID 117). 5862 bytes result sent to driver
[2024-12-14T19:41:31.142+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 168.0 in stage 4.0 (TID 110) in 163 ms on localhost (executor driver) (103/200)
[2024-12-14T19:41:31.146+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 175.0 in stage 4.0 (TID 116). 5819 bytes result sent to driver
[2024-12-14T19:41:31.148+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 181.0 in stage 4.0 (TID 118). 5819 bytes result sent to driver
[2024-12-14T19:41:31.149+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 2.0 in stage 4.0 (TID 126)
[2024-12-14T19:41:31.150+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.152+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 184.0 in stage 4.0 (TID 119). 5819 bytes result sent to driver
24/12/14 19:41:31 INFO TaskSetManager: Starting task 10.0 in stage 4.0 (TID 127) (localhost, executor driver, partition 10, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2024-12-14T19:41:31.153+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:31 INFO TaskSetManager: Finished task 151.0 in stage 4.0 (TID 100) in 266 ms on localhost (executor driver) (104/200)
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.155+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.157+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 10.0 in stage 4.0 (TID 127)
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.162+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.164+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 11.0 in stage 4.0 (TID 128) (localhost, executor driver, partition 11, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.168+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 165.0 in stage 4.0 (TID 108) in 201 ms on localhost (executor driver) (105/200)
[2024-12-14T19:41:31.170+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 11.0 in stage 4.0 (TID 128)
[2024-12-14T19:41:31.172+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 167.0 in stage 4.0 (TID 109) in 194 ms on localhost (executor driver) (106/200)
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:31.178+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 170.0 in stage 4.0 (TID 111) in 180 ms on localhost (executor driver) (107/200)
[2024-12-14T19:41:31.181+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.183+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 171.0 in stage 4.0 (TID 112) in 183 ms on localhost (executor driver) (108/200)
[2024-12-14T19:41:31.184+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2024-12-14T19:41:31.186+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 1.0 in stage 4.0 (TID 125). 5819 bytes result sent to driver
24/12/14 19:41:31 INFO TaskSetManager: Starting task 13.0 in stage 4.0 (TID 129) (localhost, executor driver, partition 13, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.188+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 13.0 in stage 4.0 (TID 129)
[2024-12-14T19:41:31.189+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 192.0 in stage 4.0 (TID 121). 5819 bytes result sent to driver
[2024-12-14T19:41:31.191+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.193+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:31 INFO TaskSetManager: Starting task 15.0 in stage 4.0 (TID 130) (localhost, executor driver, partition 15, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.196+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 162.0 in stage 4.0 (TID 106) in 247 ms on localhost (executor driver) (109/200)
[2024-12-14T19:41:31.198+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 196.0 in stage 4.0 (TID 124). 5819 bytes result sent to driver
[2024-12-14T19:41:31.200+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 17.0 in stage 4.0 (TID 131) (localhost, executor driver, partition 17, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.204+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 15.0 in stage 4.0 (TID 130)
[2024-12-14T19:41:31.207+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 174.0 in stage 4.0 (TID 115) in 158 ms on localhost (executor driver) (110/200)
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.212+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 172.0 in stage 4.0 (TID 113) in 194 ms on localhost (executor driver) (111/200)
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.215+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 195.0 in stage 4.0 (TID 123). 5819 bytes result sent to driver
[2024-12-14T19:41:31.223+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 194.0 in stage 4.0 (TID 122). 5819 bytes result sent to driver
[2024-12-14T19:41:31.224+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 17.0 in stage 4.0 (TID 131)
[2024-12-14T19:41:31.226+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 18.0 in stage 4.0 (TID 132) (localhost, executor driver, partition 18, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.227+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 186.0 in stage 4.0 (TID 120). 5819 bytes result sent to driver
[2024-12-14T19:41:31.229+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 18.0 in stage 4.0 (TID 132)
24/12/14 19:41:31 INFO TaskSetManager: Finished task 173.0 in stage 4.0 (TID 114) in 179 ms on localhost (executor driver) (112/200)
[2024-12-14T19:41:31.232+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 179.0 in stage 4.0 (TID 117) in 138 ms on localhost (executor driver) (113/200)
[2024-12-14T19:41:31.234+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 20.0 in stage 4.0 (TID 133) (localhost, executor driver, partition 20, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.236+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 20.0 in stage 4.0 (TID 133)
[2024-12-14T19:41:31.238+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 21.0 in stage 4.0 (TID 134) (localhost, executor driver, partition 21, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.239+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 21.0 in stage 4.0 (TID 134)
[2024-12-14T19:41:31.244+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 23.0 in stage 4.0 (TID 135) (localhost, executor driver, partition 23, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.246+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 10.0 in stage 4.0 (TID 127). 5776 bytes result sent to driver
24/12/14 19:41:31 INFO Executor: Running task 23.0 in stage 4.0 (TID 135)
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.249+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:31 INFO TaskSetManager: Starting task 24.0 in stage 4.0 (TID 136) (localhost, executor driver, partition 24, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.251+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.257+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.260+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.262+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 24.0 in stage 4.0 (TID 136)
24/12/14 19:41:31 INFO TaskSetManager: Finished task 184.0 in stage 4.0 (TID 119) in 156 ms on localhost (executor driver) (114/200)
[2024-12-14T19:41:31.263+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 175.0 in stage 4.0 (TID 116) in 190 ms on localhost (executor driver) (115/200)
[2024-12-14T19:41:31.266+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 27.0 in stage 4.0 (TID 137) (localhost, executor driver, partition 27, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.269+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 181.0 in stage 4.0 (TID 118) in 169 ms on localhost (executor driver) (116/200)
[2024-12-14T19:41:31.276+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 192.0 in stage 4.0 (TID 121) in 148 ms on localhost (executor driver) (117/200)
[2024-12-14T19:41:31.281+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 27.0 in stage 4.0 (TID 137)
[2024-12-14T19:41:31.284+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 125) in 120 ms on localhost (executor driver) (118/200)
24/12/14 19:41:31 INFO Executor: Finished task 2.0 in stage 4.0 (TID 126). 5776 bytes result sent to driver
[2024-12-14T19:41:31.291+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 28.0 in stage 4.0 (TID 138) (localhost, executor driver, partition 28, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:31 INFO TaskSetManager: Starting task 30.0 in stage 4.0 (TID 139) (localhost, executor driver, partition 30, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:31 INFO Executor: Running task 28.0 in stage 4.0 (TID 138)
[2024-12-14T19:41:31.293+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 30.0 in stage 4.0 (TID 139)
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.295+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2024-12-14T19:41:31.302+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 33.0 in stage 4.0 (TID 140) (localhost, executor driver, partition 33, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.307+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 13.0 in stage 4.0 (TID 129). 5819 bytes result sent to driver
[2024-12-14T19:41:31.310+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 196.0 in stage 4.0 (TID 124) in 143 ms on localhost (executor driver) (119/200)
[2024-12-14T19:41:31.318+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.320+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.321+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:31 INFO Executor: Finished task 15.0 in stage 4.0 (TID 130). 5819 bytes result sent to driver
24/12/14 19:41:31 INFO Executor: Finished task 11.0 in stage 4.0 (TID 128). 5819 bytes result sent to driver
[2024-12-14T19:41:31.325+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 33.0 in stage 4.0 (TID 140)
[2024-12-14T19:41:31.327+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 194.0 in stage 4.0 (TID 122) in 155 ms on localhost (executor driver) (120/200)
[2024-12-14T19:41:31.328+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.329+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.331+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 36.0 in stage 4.0 (TID 141) (localhost, executor driver, partition 36, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.334+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 36.0 in stage 4.0 (TID 141)
24/12/14 19:41:31 INFO TaskSetManager: Starting task 37.0 in stage 4.0 (TID 142) (localhost, executor driver, partition 37, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.337+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 37.0 in stage 4.0 (TID 142)
[2024-12-14T19:41:31.340+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 17.0 in stage 4.0 (TID 131). 5819 bytes result sent to driver
[2024-12-14T19:41:31.345+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 38.0 in stage 4.0 (TID 143) (localhost, executor driver, partition 38, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:31 INFO Executor: Finished task 21.0 in stage 4.0 (TID 134). 5819 bytes result sent to driver
[2024-12-14T19:41:31.349+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.353+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.366+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 38.0 in stage 4.0 (TID 143)
[2024-12-14T19:41:31.367+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 41.0 in stage 4.0 (TID 144) (localhost, executor driver, partition 41, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.369+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 186.0 in stage 4.0 (TID 120) in 200 ms on localhost (executor driver) (121/200)
[2024-12-14T19:41:31.371+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 13.0 in stage 4.0 (TID 129) in 103 ms on localhost (executor driver) (122/200)
[2024-12-14T19:41:31.374+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 41.0 in stage 4.0 (TID 144)
[2024-12-14T19:41:31.375+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 20.0 in stage 4.0 (TID 133). 5862 bytes result sent to driver
[2024-12-14T19:41:31.377+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.379+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2024-12-14T19:41:31.380+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.381+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.385+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 28.0 in stage 4.0 (TID 138). 5776 bytes result sent to driver
[2024-12-14T19:41:31.387+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 18.0 in stage 4.0 (TID 132). 5819 bytes result sent to driver
[2024-12-14T19:41:31.389+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.392+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 195.0 in stage 4.0 (TID 123) in 178 ms on localhost (executor driver) (123/200)
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:31.394+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.396+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.398+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2024-12-14T19:41:31.401+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.402+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.405+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 44.0 in stage 4.0 (TID 145) (localhost, executor driver, partition 44, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.407+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 45.0 in stage 4.0 (TID 146) (localhost, executor driver, partition 45, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:31 INFO Executor: Running task 45.0 in stage 4.0 (TID 146)
24/12/14 19:41:31 INFO Executor: Running task 44.0 in stage 4.0 (TID 145)
[2024-12-14T19:41:31.409+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 55.0 in stage 4.0 (TID 147) (localhost, executor driver, partition 55, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.411+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 30.0 in stage 4.0 (TID 139). 5819 bytes result sent to driver
[2024-12-14T19:41:31.412+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 10.0 in stage 4.0 (TID 127) in 181 ms on localhost (executor driver) (124/200)
24/12/14 19:41:31 INFO Executor: Running task 55.0 in stage 4.0 (TID 147)
[2024-12-14T19:41:31.414+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.417+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 17.0 in stage 4.0 (TID 131) in 150 ms on localhost (executor driver) (125/200)
24/12/14 19:41:31 INFO Executor: Finished task 23.0 in stage 4.0 (TID 135). 5819 bytes result sent to driver
[2024-12-14T19:41:31.421+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 56.0 in stage 4.0 (TID 148) (localhost, executor driver, partition 56, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.423+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 24.0 in stage 4.0 (TID 136). 5819 bytes result sent to driver
24/12/14 19:41:31 INFO Executor: Finished task 41.0 in stage 4.0 (TID 144). 5819 bytes result sent to driver
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
[2024-12-14T19:41:31.425+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 56.0 in stage 4.0 (TID 148)
[2024-12-14T19:41:31.430+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 33.0 in stage 4.0 (TID 140). 5819 bytes result sent to driver
24/12/14 19:41:31 INFO Executor: Finished task 38.0 in stage 4.0 (TID 143). 5819 bytes result sent to driver
[2024-12-14T19:41:31.431+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 58.0 in stage 4.0 (TID 149) (localhost, executor driver, partition 58, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.433+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 36.0 in stage 4.0 (TID 141). 5819 bytes result sent to driver
[2024-12-14T19:41:31.435+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 58.0 in stage 4.0 (TID 149)
[2024-12-14T19:41:31.436+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 65.0 in stage 4.0 (TID 150) (localhost, executor driver, partition 65, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.440+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 126) in 228 ms on localhost (executor driver) (126/200)
24/12/14 19:41:31 INFO Executor: Running task 65.0 in stage 4.0 (TID 150)
[2024-12-14T19:41:31.443+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 15.0 in stage 4.0 (TID 130) in 172 ms on localhost (executor driver) (127/200)
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.445+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:31.446+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 11.0 in stage 4.0 (TID 128) in 196 ms on localhost (executor driver) (128/200)
24/12/14 19:41:31 INFO Executor: Finished task 27.0 in stage 4.0 (TID 137). 5819 bytes result sent to driver
[2024-12-14T19:41:31.448+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.449+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2024-12-14T19:41:31.451+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 66.0 in stage 4.0 (TID 151) (localhost, executor driver, partition 66, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.454+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 20.0 in stage 4.0 (TID 133) in 161 ms on localhost (executor driver) (129/200)
[2024-12-14T19:41:31.456+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 66.0 in stage 4.0 (TID 151)
[2024-12-14T19:41:31.460+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 18.0 in stage 4.0 (TID 132) in 168 ms on localhost (executor driver) (130/200)
24/12/14 19:41:31 INFO TaskSetManager: Finished task 21.0 in stage 4.0 (TID 134) in 161 ms on localhost (executor driver) (131/200)
[2024-12-14T19:41:31.468+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 37.0 in stage 4.0 (TID 142). 5819 bytes result sent to driver
[2024-12-14T19:41:31.472+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 67.0 in stage 4.0 (TID 152) (localhost, executor driver, partition 67, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.474+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 67.0 in stage 4.0 (TID 152)
[2024-12-14T19:41:31.476+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:31.479+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:31 INFO TaskSetManager: Starting task 87.0 in stage 4.0 (TID 153) (localhost, executor driver, partition 87, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.481+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.483+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 87.0 in stage 4.0 (TID 153)
[2024-12-14T19:41:31.485+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 91.0 in stage 4.0 (TID 154) (localhost, executor driver, partition 91, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.490+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 28.0 in stage 4.0 (TID 138) in 141 ms on localhost (executor driver) (132/200)
[2024-12-14T19:41:31.493+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.495+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.498+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 91.0 in stage 4.0 (TID 154)
[2024-12-14T19:41:31.500+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 93.0 in stage 4.0 (TID 155) (localhost, executor driver, partition 93, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.504+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 55.0 in stage 4.0 (TID 147). 5776 bytes result sent to driver
[2024-12-14T19:41:31.507+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 45.0 in stage 4.0 (TID 146). 5776 bytes result sent to driver
[2024-12-14T19:41:31.510+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:31 INFO Executor: Running task 93.0 in stage 4.0 (TID 155)
24/12/14 19:41:31 INFO TaskSetManager: Starting task 94.0 in stage 4.0 (TID 156) (localhost, executor driver, partition 94, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.512+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 107.0 in stage 4.0 (TID 157) (localhost, executor driver, partition 107, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.518+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 94.0 in stage 4.0 (TID 156)
24/12/14 19:41:31 INFO TaskSetManager: Finished task 24.0 in stage 4.0 (TID 136) in 188 ms on localhost (executor driver) (133/200)
[2024-12-14T19:41:31.520+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 23.0 in stage 4.0 (TID 135) in 196 ms on localhost (executor driver) (134/200)
[2024-12-14T19:41:31.523+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 107.0 in stage 4.0 (TID 157)
[2024-12-14T19:41:31.524+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 38.0 in stage 4.0 (TID 143) in 141 ms on localhost (executor driver) (135/200)
[2024-12-14T19:41:31.526+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 58.0 in stage 4.0 (TID 149). 5776 bytes result sent to driver
24/12/14 19:41:31 INFO TaskSetManager: Finished task 33.0 in stage 4.0 (TID 140) in 171 ms on localhost (executor driver) (136/200)
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.532+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 44.0 in stage 4.0 (TID 145). 5776 bytes result sent to driver
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:31.534+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 66.0 in stage 4.0 (TID 151). 5776 bytes result sent to driver
[2024-12-14T19:41:31.538+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.541+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 110.0 in stage 4.0 (TID 158) (localhost, executor driver, partition 110, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.543+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:31 INFO TaskSetManager: Finished task 30.0 in stage 4.0 (TID 139) in 180 ms on localhost (executor driver) (137/200)
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:31 INFO TaskSetManager: Finished task 41.0 in stage 4.0 (TID 144) in 149 ms on localhost (executor driver) (138/200)
[2024-12-14T19:41:31.545+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 36.0 in stage 4.0 (TID 141) in 167 ms on localhost (executor driver) (139/200)
24/12/14 19:41:31 INFO Executor: Running task 110.0 in stage 4.0 (TID 158)
24/12/14 19:41:31 INFO Executor: Finished task 56.0 in stage 4.0 (TID 148). 5819 bytes result sent to driver
[2024-12-14T19:41:31.549+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 112.0 in stage 4.0 (TID 159) (localhost, executor driver, partition 112, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.551+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 67.0 in stage 4.0 (TID 152). 5776 bytes result sent to driver
[2024-12-14T19:41:31.557+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.559+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 91.0 in stage 4.0 (TID 154). 5776 bytes result sent to driver
[2024-12-14T19:41:31.562+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:31 INFO Executor: Running task 112.0 in stage 4.0 (TID 159)
[2024-12-14T19:41:31.565+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:31.567+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 114.0 in stage 4.0 (TID 160) (localhost, executor driver, partition 114, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:31 INFO Executor: Finished task 87.0 in stage 4.0 (TID 153). 5776 bytes result sent to driver
[2024-12-14T19:41:31.569+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.572+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.576+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 114.0 in stage 4.0 (TID 160)
[2024-12-14T19:41:31.578+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.579+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.580+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 115.0 in stage 4.0 (TID 161) (localhost, executor driver, partition 115, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.582+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.584+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:31 INFO Executor: Running task 115.0 in stage 4.0 (TID 161)
[2024-12-14T19:41:31.591+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 116.0 in stage 4.0 (TID 162) (localhost, executor driver, partition 116, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:31 INFO TaskSetManager: Finished task 27.0 in stage 4.0 (TID 137) in 226 ms on localhost (executor driver) (140/200)
24/12/14 19:41:31 INFO Executor: Running task 116.0 in stage 4.0 (TID 162)
24/12/14 19:41:31 INFO TaskSetManager: Finished task 55.0 in stage 4.0 (TID 147) in 137 ms on localhost (executor driver) (141/200)
[2024-12-14T19:41:31.594+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 65.0 in stage 4.0 (TID 150). 5776 bytes result sent to driver
24/12/14 19:41:31 INFO Executor: Finished task 94.0 in stage 4.0 (TID 156). 5776 bytes result sent to driver
[2024-12-14T19:41:31.597+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 107.0 in stage 4.0 (TID 157). 5776 bytes result sent to driver
[2024-12-14T19:41:31.599+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 93.0 in stage 4.0 (TID 155). 5776 bytes result sent to driver
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.601+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.602+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 117.0 in stage 4.0 (TID 163) (localhost, executor driver, partition 117, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.607+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 37.0 in stage 4.0 (TID 142) in 211 ms on localhost (executor driver) (142/200)
[2024-12-14T19:41:31.609+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 117.0 in stage 4.0 (TID 163)
24/12/14 19:41:31 INFO Executor: Finished task 110.0 in stage 4.0 (TID 158). 5776 bytes result sent to driver
[2024-12-14T19:41:31.612+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 118.0 in stage 4.0 (TID 164) (localhost, executor driver, partition 118, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.617+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 45.0 in stage 4.0 (TID 146) in 159 ms on localhost (executor driver) (143/200)
24/12/14 19:41:31 INFO Executor: Running task 118.0 in stage 4.0 (TID 164)
[2024-12-14T19:41:31.620+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.622+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 66.0 in stage 4.0 (TID 151) in 122 ms on localhost (executor driver) (144/200)
[2024-12-14T19:41:31.624+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.627+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:31 INFO TaskSetManager: Finished task 58.0 in stage 4.0 (TID 149) in 144 ms on localhost (executor driver) (145/200)
[2024-12-14T19:41:31.629+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.631+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.634+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 119.0 in stage 4.0 (TID 165) (localhost, executor driver, partition 119, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:31 INFO Executor: Running task 119.0 in stage 4.0 (TID 165)
24/12/14 19:41:31 INFO TaskSetManager: Starting task 121.0 in stage 4.0 (TID 166) (localhost, executor driver, partition 121, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:31 INFO Executor: Finished task 114.0 in stage 4.0 (TID 160). 5776 bytes result sent to driver
24/12/14 19:41:31 INFO Executor: Running task 121.0 in stage 4.0 (TID 166)
24/12/14 19:41:31 INFO TaskSetManager: Starting task 122.0 in stage 4.0 (TID 167) (localhost, executor driver, partition 122, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.637+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 44.0 in stage 4.0 (TID 145) in 198 ms on localhost (executor driver) (146/200)
24/12/14 19:41:31 INFO Executor: Running task 122.0 in stage 4.0 (TID 167)
[2024-12-14T19:41:31.639+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 126.0 in stage 4.0 (TID 168) (localhost, executor driver, partition 126, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.643+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 56.0 in stage 4.0 (TID 148) in 163 ms on localhost (executor driver) (147/200)
[2024-12-14T19:41:31.648+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 67.0 in stage 4.0 (TID 152) in 133 ms on localhost (executor driver) (148/200)
[2024-12-14T19:41:31.650+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 112.0 in stage 4.0 (TID 159). 5776 bytes result sent to driver
[2024-12-14T19:41:31.654+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 126.0 in stage 4.0 (TID 168)
[2024-12-14T19:41:31.657+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.658+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:31 INFO TaskSetManager: Finished task 91.0 in stage 4.0 (TID 154) in 126 ms on localhost (executor driver) (149/200)
[2024-12-14T19:41:31.660+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 87.0 in stage 4.0 (TID 153) in 136 ms on localhost (executor driver) (150/200)
24/12/14 19:41:31 INFO Executor: Finished task 115.0 in stage 4.0 (TID 161). 5819 bytes result sent to driver
24/12/14 19:41:31 INFO TaskSetManager: Starting task 128.0 in stage 4.0 (TID 169) (localhost, executor driver, partition 128, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.663+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 128.0 in stage 4.0 (TID 169)
24/12/14 19:41:31 INFO Executor: Finished task 116.0 in stage 4.0 (TID 162). 5776 bytes result sent to driver
[2024-12-14T19:41:31.665+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 131.0 in stage 4.0 (TID 170) (localhost, executor driver, partition 131, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.676+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 133.0 in stage 4.0 (TID 171) (localhost, executor driver, partition 133, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.686+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 133.0 in stage 4.0 (TID 171)
[2024-12-14T19:41:31.687+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 131.0 in stage 4.0 (TID 170)
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.692+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.696+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 134.0 in stage 4.0 (TID 172) (localhost, executor driver, partition 134, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.697+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 134.0 in stage 4.0 (TID 172)
[2024-12-14T19:41:31.707+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.710+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.714+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.721+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.726+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.740+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
[2024-12-14T19:41:31.742+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 138.0 in stage 4.0 (TID 173) (localhost, executor driver, partition 138, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.744+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 138.0 in stage 4.0 (TID 173)
[2024-12-14T19:41:31.745+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 117.0 in stage 4.0 (TID 163). 5776 bytes result sent to driver
[2024-12-14T19:41:31.747+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 65.0 in stage 4.0 (TID 150) in 186 ms on localhost (executor driver) (151/200)
[2024-12-14T19:41:31.749+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 94.0 in stage 4.0 (TID 156) in 149 ms on localhost (executor driver) (152/200)
[2024-12-14T19:41:31.752+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 93.0 in stage 4.0 (TID 155) in 152 ms on localhost (executor driver) (153/200)
[2024-12-14T19:41:31.753+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 107.0 in stage 4.0 (TID 157) in 148 ms on localhost (executor driver) (154/200)
[2024-12-14T19:41:31.755+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.757+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:31.759+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 119.0 in stage 4.0 (TID 165). 5776 bytes result sent to driver
[2024-12-14T19:41:31.761+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 139.0 in stage 4.0 (TID 174) (localhost, executor driver, partition 139, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.762+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.763+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 121.0 in stage 4.0 (TID 166). 5819 bytes result sent to driver
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:31 INFO Executor: Running task 139.0 in stage 4.0 (TID 174)
[2024-12-14T19:41:31.764+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 140.0 in stage 4.0 (TID 175) (localhost, executor driver, partition 140, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.766+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 140.0 in stage 4.0 (TID 175)
[2024-12-14T19:41:31.767+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.768+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.775+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 118.0 in stage 4.0 (TID 164). 5776 bytes result sent to driver
[2024-12-14T19:41:31.779+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 122.0 in stage 4.0 (TID 167). 5776 bytes result sent to driver
[2024-12-14T19:41:31.782+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 141.0 in stage 4.0 (TID 176) (localhost, executor driver, partition 141, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.787+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 141.0 in stage 4.0 (TID 176)
[2024-12-14T19:41:31.789+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 143.0 in stage 4.0 (TID 177) (localhost, executor driver, partition 143, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.790+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 110.0 in stage 4.0 (TID 158) in 157 ms on localhost (executor driver) (155/200)
[2024-12-14T19:41:31.792+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 144.0 in stage 4.0 (TID 178) (localhost, executor driver, partition 144, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.793+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 143.0 in stage 4.0 (TID 177)
[2024-12-14T19:41:31.797+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 114.0 in stage 4.0 (TID 160) in 141 ms on localhost (executor driver) (156/200)
[2024-12-14T19:41:31.799+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 144.0 in stage 4.0 (TID 178)
[2024-12-14T19:41:31.801+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 133.0 in stage 4.0 (TID 171). 5776 bytes result sent to driver
[2024-12-14T19:41:31.803+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 126.0 in stage 4.0 (TID 168). 5819 bytes result sent to driver
[2024-12-14T19:41:31.804+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 115.0 in stage 4.0 (TID 161) in 133 ms on localhost (executor driver) (157/200)
[2024-12-14T19:41:31.806+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.807+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 131.0 in stage 4.0 (TID 170). 5776 bytes result sent to driver
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2024-12-14T19:41:31.809+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.811+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.812+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.814+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 147.0 in stage 4.0 (TID 179) (localhost, executor driver, partition 147, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.816+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2024-12-14T19:41:31.820+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 147.0 in stage 4.0 (TID 179)
[2024-12-14T19:41:31.821+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 112.0 in stage 4.0 (TID 159) in 163 ms on localhost (executor driver) (158/200)
[2024-12-14T19:41:31.823+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 128.0 in stage 4.0 (TID 169). 5776 bytes result sent to driver
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.825+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 153.0 in stage 4.0 (TID 180) (localhost, executor driver, partition 153, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:31.827+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.828+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.830+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 153.0 in stage 4.0 (TID 180)
[2024-12-14T19:41:31.832+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.833+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:31 INFO Executor: Finished task 140.0 in stage 4.0 (TID 175). 5776 bytes result sent to driver
24/12/14 19:41:31 INFO TaskSetManager: Starting task 155.0 in stage 4.0 (TID 181) (localhost, executor driver, partition 155, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.835+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 134.0 in stage 4.0 (TID 172). 5776 bytes result sent to driver
24/12/14 19:41:31 INFO Executor: Running task 155.0 in stage 4.0 (TID 181)
[2024-12-14T19:41:31.837+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 156.0 in stage 4.0 (TID 182) (localhost, executor driver, partition 156, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.838+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 116.0 in stage 4.0 (TID 162) in 159 ms on localhost (executor driver) (159/200)
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.842+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.845+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 156.0 in stage 4.0 (TID 182)
[2024-12-14T19:41:31.846+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 143.0 in stage 4.0 (TID 177). 5819 bytes result sent to driver
24/12/14 19:41:31 INFO TaskSetManager: Finished task 117.0 in stage 4.0 (TID 163) in 151 ms on localhost (executor driver) (160/200)
[2024-12-14T19:41:31.847+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 118.0 in stage 4.0 (TID 164) in 151 ms on localhost (executor driver) (161/200)
[2024-12-14T19:41:31.848+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 121.0 in stage 4.0 (TID 166) in 138 ms on localhost (executor driver) (162/200)
24/12/14 19:41:31 INFO Executor: Finished task 139.0 in stage 4.0 (TID 174). 5819 bytes result sent to driver
24/12/14 19:41:31 INFO Executor: Finished task 144.0 in stage 4.0 (TID 178). 5819 bytes result sent to driver
[2024-12-14T19:41:31.849+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 138.0 in stage 4.0 (TID 173). 5819 bytes result sent to driver
[2024-12-14T19:41:31.850+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 119.0 in stage 4.0 (TID 165) in 146 ms on localhost (executor driver) (163/200)
[2024-12-14T19:41:31.851+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
24/12/14 19:41:31 INFO TaskSetManager: Starting task 157.0 in stage 4.0 (TID 183) (localhost, executor driver, partition 157, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.854+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 157.0 in stage 4.0 (TID 183)
[2024-12-14T19:41:31.858+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 160.0 in stage 4.0 (TID 184) (localhost, executor driver, partition 160, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:31 INFO TaskSetManager: Finished task 122.0 in stage 4.0 (TID 167) in 149 ms on localhost (executor driver) (164/200)
24/12/14 19:41:31 INFO Executor: Running task 160.0 in stage 4.0 (TID 184)
[2024-12-14T19:41:31.860+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 141.0 in stage 4.0 (TID 176). 5819 bytes result sent to driver
[2024-12-14T19:41:31.862+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 163.0 in stage 4.0 (TID 185) (localhost, executor driver, partition 163, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.867+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 163.0 in stage 4.0 (TID 185)
[2024-12-14T19:41:31.871+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 147.0 in stage 4.0 (TID 179). 5819 bytes result sent to driver
[2024-12-14T19:41:31.876+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 166.0 in stage 4.0 (TID 186) (localhost, executor driver, partition 166, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.879+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 166.0 in stage 4.0 (TID 186)
[2024-12-14T19:41:31.880+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 169.0 in stage 4.0 (TID 187) (localhost, executor driver, partition 169, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.882+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 176.0 in stage 4.0 (TID 188) (localhost, executor driver, partition 176, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.885+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 169.0 in stage 4.0 (TID 187)
[2024-12-14T19:41:31.886+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 177.0 in stage 4.0 (TID 189) (localhost, executor driver, partition 177, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.889+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 176.0 in stage 4.0 (TID 188)
[2024-12-14T19:41:31.891+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 131.0 in stage 4.0 (TID 170) in 146 ms on localhost (executor driver) (165/200)
[2024-12-14T19:41:31.892+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 177.0 in stage 4.0 (TID 189)
[2024-12-14T19:41:31.893+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.894+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 153.0 in stage 4.0 (TID 180). 5819 bytes result sent to driver
[2024-12-14T19:41:31.895+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.896+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.897+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 140.0 in stage 4.0 (TID 175) in 107 ms on localhost (executor driver) (166/200)
[2024-12-14T19:41:31.897+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 133.0 in stage 4.0 (TID 171) in 151 ms on localhost (executor driver) (167/200)
[2024-12-14T19:41:31.898+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 178.0 in stage 4.0 (TID 190) (localhost, executor driver, partition 178, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.898+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 178.0 in stage 4.0 (TID 190)
[2024-12-14T19:41:31.899+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.903+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.905+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 180.0 in stage 4.0 (TID 191) (localhost, executor driver, partition 180, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.906+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 128.0 in stage 4.0 (TID 169) in 168 ms on localhost (executor driver) (168/200)
[2024-12-14T19:41:31.908+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 126.0 in stage 4.0 (TID 168) in 179 ms on localhost (executor driver) (169/200)
[2024-12-14T19:41:31.909+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 134.0 in stage 4.0 (TID 172) in 156 ms on localhost (executor driver) (170/200)
[2024-12-14T19:41:31.911+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.912+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.914+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 182.0 in stage 4.0 (TID 192) (localhost, executor driver, partition 182, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.915+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 182.0 in stage 4.0 (TID 192)
24/12/14 19:41:31 INFO Executor: Running task 180.0 in stage 4.0 (TID 191)
24/12/14 19:41:31 INFO TaskSetManager: Starting task 183.0 in stage 4.0 (TID 193) (localhost, executor driver, partition 183, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.917+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:31 INFO TaskSetManager: Starting task 185.0 in stage 4.0 (TID 194) (localhost, executor driver, partition 185, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:31 INFO Executor: Running task 185.0 in stage 4.0 (TID 194)
[2024-12-14T19:41:31.919+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 187.0 in stage 4.0 (TID 195) (localhost, executor driver, partition 187, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.920+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 160.0 in stage 4.0 (TID 184). 5819 bytes result sent to driver
[2024-12-14T19:41:31.922+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 183.0 in stage 4.0 (TID 193)
[2024-12-14T19:41:31.923+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 187.0 in stage 4.0 (TID 195)
[2024-12-14T19:41:31.924+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 166.0 in stage 4.0 (TID 186). 5776 bytes result sent to driver
[2024-12-14T19:41:31.926+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.927+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:31.929+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 188.0 in stage 4.0 (TID 196) (localhost, executor driver, partition 188, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.930+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 143.0 in stage 4.0 (TID 177) in 131 ms on localhost (executor driver) (171/200)
24/12/14 19:41:31 INFO Executor: Running task 188.0 in stage 4.0 (TID 196)
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.931+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.933+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 189.0 in stage 4.0 (TID 197) (localhost, executor driver, partition 189, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.934+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.935+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2024-12-14T19:41:31.936+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 189.0 in stage 4.0 (TID 197)
[2024-12-14T19:41:31.937+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 138.0 in stage 4.0 (TID 173) in 186 ms on localhost (executor driver) (172/200)
[2024-12-14T19:41:31.938+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.940+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2024-12-14T19:41:31.942+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 156.0 in stage 4.0 (TID 182). 5776 bytes result sent to driver
[2024-12-14T19:41:31.943+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 155.0 in stage 4.0 (TID 181). 5819 bytes result sent to driver
[2024-12-14T19:41:31.944+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 190.0 in stage 4.0 (TID 198) (localhost, executor driver, partition 190, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:31 INFO Executor: Finished task 157.0 in stage 4.0 (TID 183). 5819 bytes result sent to driver
[2024-12-14T19:41:31.946+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.947+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.949+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 147.0 in stage 4.0 (TID 179) in 164 ms on localhost (executor driver) (173/200)
24/12/14 19:41:31 INFO TaskSetManager: Finished task 139.0 in stage 4.0 (TID 174) in 207 ms on localhost (executor driver) (174/200)
24/12/14 19:41:31 INFO TaskSetManager: Finished task 153.0 in stage 4.0 (TID 180) in 160 ms on localhost (executor driver) (175/200)
24/12/14 19:41:31 INFO Executor: Finished task 169.0 in stage 4.0 (TID 187). 5819 bytes result sent to driver
24/12/14 19:41:31 INFO TaskSetManager: Finished task 160.0 in stage 4.0 (TID 184) in 121 ms on localhost (executor driver) (176/200)
[2024-12-14T19:41:31.951+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 144.0 in stage 4.0 (TID 178) in 190 ms on localhost (executor driver) (177/200)
[2024-12-14T19:41:31.952+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 166.0 in stage 4.0 (TID 186) in 123 ms on localhost (executor driver) (178/200)
[2024-12-14T19:41:31.954+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 163.0 in stage 4.0 (TID 185). 5819 bytes result sent to driver
[2024-12-14T19:41:31.956+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 178.0 in stage 4.0 (TID 190). 5819 bytes result sent to driver
[2024-12-14T19:41:31.957+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.959+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2024-12-14T19:41:31.960+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 190.0 in stage 4.0 (TID 198)
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:31 INFO Executor: Finished task 176.0 in stage 4.0 (TID 188). 5862 bytes result sent to driver
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:31.961+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 180.0 in stage 4.0 (TID 191). 5819 bytes result sent to driver
24/12/14 19:41:31 INFO TaskSetManager: Starting task 191.0 in stage 4.0 (TID 199) (localhost, executor driver, partition 191, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.962+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 141.0 in stage 4.0 (TID 176) in 209 ms on localhost (executor driver) (179/200)
24/12/14 19:41:31 INFO Executor: Running task 191.0 in stage 4.0 (TID 199)
[2024-12-14T19:41:31.964+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:31 INFO TaskSetManager: Starting task 193.0 in stage 4.0 (TID 200) (localhost, executor driver, partition 193, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:31 INFO Executor: Running task 193.0 in stage 4.0 (TID 200)
[2024-12-14T19:41:31.965+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 197.0 in stage 4.0 (TID 201) (localhost, executor driver, partition 197, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:31.967+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.968+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.969+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 197.0 in stage 4.0 (TID 201)
[2024-12-14T19:41:31.971+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 198.0 in stage 4.0 (TID 202) (localhost, executor driver, partition 198, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:31 INFO Executor: Finished task 177.0 in stage 4.0 (TID 189). 5819 bytes result sent to driver
[2024-12-14T19:41:31.973+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 155.0 in stage 4.0 (TID 181) in 200 ms on localhost (executor driver) (180/200)
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:31 INFO Executor: Running task 198.0 in stage 4.0 (TID 202)
24/12/14 19:41:31 INFO Executor: Finished task 188.0 in stage 4.0 (TID 196). 5819 bytes result sent to driver
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.974+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.976+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.977+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 199.0 in stage 4.0 (TID 203) (localhost, executor driver, partition 199, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:31 INFO Executor: Finished task 183.0 in stage 4.0 (TID 193). 5819 bytes result sent to driver
24/12/14 19:41:31 INFO Executor: Finished task 185.0 in stage 4.0 (TID 194). 5819 bytes result sent to driver
[2024-12-14T19:41:31.978+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 199.0 in stage 4.0 (TID 203)
[2024-12-14T19:41:31.979+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 169.0 in stage 4.0 (TID 187) in 181 ms on localhost (executor driver) (181/200)
[2024-12-14T19:41:31.981+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:31 INFO TaskSetManager: Finished task 156.0 in stage 4.0 (TID 182) in 229 ms on localhost (executor driver) (182/200)
[2024-12-14T19:41:31.982+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
[2024-12-14T19:41:31.983+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 182.0 in stage 4.0 (TID 192). 5862 bytes result sent to driver
[2024-12-14T19:41:31.985+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 157.0 in stage 4.0 (TID 183) in 210 ms on localhost (executor driver) (183/200)
[2024-12-14T19:41:31.987+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 178.0 in stage 4.0 (TID 190) in 177 ms on localhost (executor driver) (184/200)
[2024-12-14T19:41:31.988+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 180.0 in stage 4.0 (TID 191) in 175 ms on localhost (executor driver) (185/200)
[2024-12-14T19:41:31.990+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 187.0 in stage 4.0 (TID 195). 5819 bytes result sent to driver
[2024-12-14T19:41:31.992+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 163.0 in stage 4.0 (TID 185) in 210 ms on localhost (executor driver) (186/200)
24/12/14 19:41:31 INFO TaskSetManager: Finished task 176.0 in stage 4.0 (TID 188) in 202 ms on localhost (executor driver) (187/200)
24/12/14 19:41:31 INFO TaskSetManager: Finished task 188.0 in stage 4.0 (TID 196) in 157 ms on localhost (executor driver) (188/200)
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:31.994+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:31.995+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 177.0 in stage 4.0 (TID 189) in 205 ms on localhost (executor driver) (189/200)
[2024-12-14T19:41:31.997+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 185.0 in stage 4.0 (TID 194) in 172 ms on localhost (executor driver) (190/200)
[2024-12-14T19:41:31.998+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 190.0 in stage 4.0 (TID 198). 5862 bytes result sent to driver
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:31 INFO Executor: Finished task 189.0 in stage 4.0 (TID 197). 5819 bytes result sent to driver
[2024-12-14T19:41:32.000+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 191.0 in stage 4.0 (TID 199). 5862 bytes result sent to driver
24/12/14 19:41:31 INFO TaskSetManager: Finished task 182.0 in stage 4.0 (TID 192) in 185 ms on localhost (executor driver) (191/200)
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:32.001+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 183.0 in stage 4.0 (TID 193) in 185 ms on localhost (executor driver) (192/200)
24/12/14 19:41:31 INFO TaskSetManager: Finished task 190.0 in stage 4.0 (TID 198) in 118 ms on localhost (executor driver) (193/200)
24/12/14 19:41:31 INFO TaskSetManager: Finished task 187.0 in stage 4.0 (TID 195) in 179 ms on localhost (executor driver) (194/200)
24/12/14 19:41:31 INFO TaskSetManager: Finished task 189.0 in stage 4.0 (TID 197) in 160 ms on localhost (executor driver) (195/200)
[2024-12-14T19:41:32.002+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2024-12-14T19:41:32.004+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 193.0 in stage 4.0 (TID 200). 5819 bytes result sent to driver
[2024-12-14T19:41:32.006+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 191.0 in stage 4.0 (TID 199) in 98 ms on localhost (executor driver) (196/200)
[2024-12-14T19:41:32.007+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 193.0 in stage 4.0 (TID 200) in 93 ms on localhost (executor driver) (197/200)
[2024-12-14T19:41:32.009+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 198.0 in stage 4.0 (TID 202). 5819 bytes result sent to driver
[2024-12-14T19:41:32.010+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 197.0 in stage 4.0 (TID 201). 5819 bytes result sent to driver
[2024-12-14T19:41:32.012+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 198.0 in stage 4.0 (TID 202) in 93 ms on localhost (executor driver) (198/200)
24/12/14 19:41:31 INFO TaskSetManager: Finished task 197.0 in stage 4.0 (TID 201) in 104 ms on localhost (executor driver) (199/200)
24/12/14 19:41:31 INFO Executor: Finished task 199.0 in stage 4.0 (TID 203). 5862 bytes result sent to driver
[2024-12-14T19:41:32.013+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 199.0 in stage 4.0 (TID 203) in 100 ms on localhost (executor driver) (200/200)
[2024-12-14T19:41:32.014+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool
[2024-12-14T19:41:32.016+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO DAGScheduler: ShuffleMapStage 4 (start at NativeMethodAccessorImpl.java:0) finished in 2.562 s
[2024-12-14T19:41:32.018+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO DAGScheduler: looking for newly runnable stages
[2024-12-14T19:41:32.020+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO DAGScheduler: running: Set()
24/12/14 19:41:31 INFO DAGScheduler: waiting: Set(ResultStage 5)
[2024-12-14T19:41:32.022+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO DAGScheduler: failed: Set()
[2024-12-14T19:41:32.024+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[19] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-12-14T19:41:32.025+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 12.5 KiB, free 434.3 MiB)
[2024-12-14T19:41:32.027+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.3 MiB)
[2024-12-14T19:41:32.028+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:32963 (size: 5.9 KiB, free: 434.4 MiB)
[2024-12-14T19:41:32.030+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1580
[2024-12-14T19:41:32.031+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[19] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/12/14 19:41:31 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
[2024-12-14T19:41:32.033+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 204) (localhost, executor driver, partition 0, NODE_LOCAL, 9963 bytes)
[2024-12-14T19:41:32.034+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Running task 0.0 in stage 5.0 (TID 204)
[2024-12-14T19:41:32.036+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Getting 200 (11.7 KiB) non-empty blocks including 200 (11.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2024-12-14T19:41:32.038+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO CodeGenerator: Code generated in 15.552307 ms
[2024-12-14T19:41:32.040+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO Executor: Finished task 0.0 in stage 5.0 (TID 204). 3995 bytes result sent to driver
[2024-12-14T19:41:32.042+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 204) in 109 ms on localhost (executor driver) (1/1)
[2024-12-14T19:41:32.044+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2024-12-14T19:41:32.045+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO DAGScheduler: ResultStage 5 (start at NativeMethodAccessorImpl.java:0) finished in 0.145 s
[2024-12-14T19:41:32.046+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
24/12/14 19:41:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
[2024-12-14T19:41:32.048+0000] {docker.py:413} INFO - 24/12/14 19:41:31 INFO DAGScheduler: Job 2 finished: start at NativeMethodAccessorImpl.java:0, took 3.975391 s
[2024-12-14T19:41:32.049+0000] {docker.py:413} INFO - 2024-12-14 19:41:31,997 [INFO] After deduplication: 180 records
[2024-12-14T19:41:32.051+0000] {docker.py:413} INFO - 2024-12-14 19:41:31,997 [INFO] Transforming posts for batch 0...
2024-12-14 19:41:31,997 [INFO] Starting posts transformation...
[2024-12-14T19:41:32.321+0000] {docker.py:413} INFO - 24/12/14 19:41:32 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
[2024-12-14T19:41:32.323+0000] {docker.py:413} INFO - 24/12/14 19:41:32 INFO DAGScheduler: Registering RDD 21 (start at NativeMethodAccessorImpl.java:0) as input to shuffle 3
[2024-12-14T19:41:32.325+0000] {docker.py:413} INFO - 24/12/14 19:41:32 INFO DAGScheduler: Registering RDD 24 (start at NativeMethodAccessorImpl.java:0) as input to shuffle 4
[2024-12-14T19:41:32.327+0000] {docker.py:413} INFO - 24/12/14 19:41:32 INFO DAGScheduler: Got job 3 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/12/14 19:41:32 INFO DAGScheduler: Final stage: ResultStage 8 (start at NativeMethodAccessorImpl.java:0)
24/12/14 19:41:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
[2024-12-14T19:41:32.329+0000] {docker.py:413} INFO - 24/12/14 19:41:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
[2024-12-14T19:41:32.330+0000] {docker.py:413} INFO - 24/12/14 19:41:32 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[21] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-12-14T19:41:32.332+0000] {docker.py:413} INFO - 24/12/14 19:41:32 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 51.8 KiB, free 434.2 MiB)
[2024-12-14T19:41:32.335+0000] {docker.py:413} INFO - 24/12/14 19:41:32 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 434.2 MiB)
[2024-12-14T19:41:32.336+0000] {docker.py:413} INFO - 24/12/14 19:41:32 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:32963 (size: 20.7 KiB, free: 434.3 MiB)
[2024-12-14T19:41:32.338+0000] {docker.py:413} INFO - 24/12/14 19:41:32 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1580
[2024-12-14T19:41:32.340+0000] {docker.py:413} INFO - 24/12/14 19:41:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[21] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/12/14 19:41:32 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
[2024-12-14T19:41:32.344+0000] {docker.py:413} INFO - 24/12/14 19:41:32 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 205) (localhost, executor driver, partition 0, PROCESS_LOCAL, 10838 bytes)
[2024-12-14T19:41:32.345+0000] {docker.py:413} INFO - 24/12/14 19:41:32 INFO Executor: Running task 0.0 in stage 6.0 (TID 205)
[2024-12-14T19:41:32.372+0000] {docker.py:413} INFO - 24/12/14 19:41:32 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=reddit_data-0 fromOffset=0 untilOffset=650, for query queryId=380f0ba5-0895-4b92-9659-cdf82c87bac4 batchId=0 taskId=205 partitionId=0
[2024-12-14T19:41:32.385+0000] {docker.py:413} INFO - 24/12/14 19:41:32 INFO KafkaConsumer: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to offset 0 for partition reddit_data-0
[2024-12-14T19:41:32.397+0000] {docker.py:413} INFO - 24/12/14 19:41:32 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to earliest offset of partition reddit_data-0
[2024-12-14T19:41:32.400+0000] {docker.py:413} INFO - 24/12/14 19:41:32 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Resetting offset for partition reddit_data-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 0 rack: null)], epoch=32}}.
24/12/14 19:41:32 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to latest offset of partition reddit_data-0
[2024-12-14T19:41:32.403+0000] {docker.py:413} INFO - 24/12/14 19:41:32 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Resetting offset for partition reddit_data-0 to position FetchPosition{offset=650, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 0 rack: null)], epoch=32}}.
[2024-12-14T19:41:32.434+0000] {docker.py:413} INFO - 24/12/14 19:41:32 INFO KafkaConsumer: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to offset 500 for partition reddit_data-0
[2024-12-14T19:41:32.436+0000] {docker.py:413} INFO - 24/12/14 19:41:32 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to earliest offset of partition reddit_data-0
[2024-12-14T19:41:32.944+0000] {docker.py:413} INFO - 24/12/14 19:41:32 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Resetting offset for partition reddit_data-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 0 rack: null)], epoch=32}}.
[2024-12-14T19:41:32.946+0000] {docker.py:413} INFO - 24/12/14 19:41:32 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to latest offset of partition reddit_data-0
[2024-12-14T19:41:32.949+0000] {docker.py:413} INFO - 24/12/14 19:41:32 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Resetting offset for partition reddit_data-0 to position FetchPosition{offset=650, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 0 rack: null)], epoch=32}}.
[2024-12-14T19:41:33.126+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO KafkaDataConsumer: From Kafka topicPartition=reddit_data-0 groupId=reddit_processor_group read 650 records through 2 polls (polled  out 650 records), taking 534507872 nanos, during time span of 741932027 nanos.
[2024-12-14T19:41:33.132+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Finished task 0.0 in stage 6.0 (TID 205). 2903 bytes result sent to driver
[2024-12-14T19:41:33.142+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 205) in 797 ms on localhost (executor driver) (1/1)
[2024-12-14T19:41:33.143+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool
[2024-12-14T19:41:33.148+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO DAGScheduler: ShuffleMapStage 6 (start at NativeMethodAccessorImpl.java:0) finished in 0.817 s
24/12/14 19:41:33 INFO DAGScheduler: looking for newly runnable stages
[2024-12-14T19:41:33.149+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO DAGScheduler: running: Set()
[2024-12-14T19:41:33.151+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO DAGScheduler: waiting: Set(ShuffleMapStage 7, ResultStage 8)
24/12/14 19:41:33 INFO DAGScheduler: failed: Set()
[2024-12-14T19:41:33.153+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[24] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-12-14T19:41:33.202+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 63.8 KiB, free 434.2 MiB)
[2024-12-14T19:41:33.205+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 25.8 KiB, free 434.1 MiB)
[2024-12-14T19:41:33.206+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:32963 (size: 25.8 KiB, free: 434.3 MiB)
[2024-12-14T19:41:33.209+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1580
[2024-12-14T19:41:33.215+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO DAGScheduler: Submitting 200 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[24] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
24/12/14 19:41:33 INFO TaskSchedulerImpl: Adding task set 7.0 with 200 tasks resource profile 0
[2024-12-14T19:41:33.224+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 206) (localhost, executor driver, partition 0, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.225+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 207) (localhost, executor driver, partition 3, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.227+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 208) (localhost, executor driver, partition 4, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.229+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 209) (localhost, executor driver, partition 5, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.232+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 210) (localhost, executor driver, partition 6, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.234+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 211) (localhost, executor driver, partition 7, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.236+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 212) (localhost, executor driver, partition 8, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.238+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 213) (localhost, executor driver, partition 9, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:33 INFO TaskSetManager: Starting task 12.0 in stage 7.0 (TID 214) (localhost, executor driver, partition 12, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.242+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 14.0 in stage 7.0 (TID 215) (localhost, executor driver, partition 14, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.244+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 16.0 in stage 7.0 (TID 216) (localhost, executor driver, partition 16, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.246+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 19.0 in stage 7.0 (TID 217) (localhost, executor driver, partition 19, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:33 INFO TaskSetManager: Starting task 22.0 in stage 7.0 (TID 218) (localhost, executor driver, partition 22, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.255+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 25.0 in stage 7.0 (TID 219) (localhost, executor driver, partition 25, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.259+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 26.0 in stage 7.0 (TID 220) (localhost, executor driver, partition 26, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.263+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 29.0 in stage 7.0 (TID 221) (localhost, executor driver, partition 29, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.270+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 4.0 in stage 7.0 (TID 208)
24/12/14 19:41:33 INFO Executor: Running task 5.0 in stage 7.0 (TID 209)
24/12/14 19:41:33 INFO Executor: Running task 3.0 in stage 7.0 (TID 207)
24/12/14 19:41:33 INFO Executor: Running task 7.0 in stage 7.0 (TID 211)
[2024-12-14T19:41:33.272+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 0.0 in stage 7.0 (TID 206)
24/12/14 19:41:33 INFO Executor: Running task 16.0 in stage 7.0 (TID 216)
24/12/14 19:41:33 INFO Executor: Running task 9.0 in stage 7.0 (TID 213)
24/12/14 19:41:33 INFO Executor: Running task 29.0 in stage 7.0 (TID 221)
24/12/14 19:41:33 INFO Executor: Running task 25.0 in stage 7.0 (TID 219)
24/12/14 19:41:33 INFO Executor: Running task 8.0 in stage 7.0 (TID 212)
[2024-12-14T19:41:33.275+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 12.0 in stage 7.0 (TID 214)
[2024-12-14T19:41:33.277+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 14.0 in stage 7.0 (TID 215)
24/12/14 19:41:33 INFO Executor: Running task 19.0 in stage 7.0 (TID 217)
24/12/14 19:41:33 INFO Executor: Running task 26.0 in stage 7.0 (TID 220)
[2024-12-14T19:41:33.278+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 22.0 in stage 7.0 (TID 218)
[2024-12-14T19:41:33.280+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 6.0 in stage 7.0 (TID 210)
[2024-12-14T19:41:33.281+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:33.287+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:33.289+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:33.290+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:33.294+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2024-12-14T19:41:33.296+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:33.299+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:33.304+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:33.307+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:33.313+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:33.319+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:33.324+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:33.327+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:33.334+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:33.336+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:33.339+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2024-12-14T19:41:33.349+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:33.358+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:33.363+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:33.367+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:33.375+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2024-12-14T19:41:33.382+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Finished task 16.0 in stage 7.0 (TID 216). 5776 bytes result sent to driver
[2024-12-14T19:41:33.386+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Finished task 12.0 in stage 7.0 (TID 214). 5776 bytes result sent to driver
24/12/14 19:41:33 INFO Executor: Finished task 25.0 in stage 7.0 (TID 219). 5776 bytes result sent to driver
[2024-12-14T19:41:33.388+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Finished task 3.0 in stage 7.0 (TID 207). 5819 bytes result sent to driver
24/12/14 19:41:33 INFO TaskSetManager: Starting task 31.0 in stage 7.0 (TID 222) (localhost, executor driver, partition 31, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.394+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 31.0 in stage 7.0 (TID 222)
[2024-12-14T19:41:33.400+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Finished task 26.0 in stage 7.0 (TID 220). 5776 bytes result sent to driver
[2024-12-14T19:41:33.403+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Finished task 8.0 in stage 7.0 (TID 212). 5776 bytes result sent to driver
[2024-12-14T19:41:33.409+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Finished task 19.0 in stage 7.0 (TID 217). 5776 bytes result sent to driver
[2024-12-14T19:41:33.413+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Finished task 6.0 in stage 7.0 (TID 210). 5776 bytes result sent to driver
[2024-12-14T19:41:33.423+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 32.0 in stage 7.0 (TID 223) (localhost, executor driver, partition 32, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.432+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Finished task 5.0 in stage 7.0 (TID 209). 5776 bytes result sent to driver
24/12/14 19:41:33 INFO Executor: Finished task 4.0 in stage 7.0 (TID 208). 5776 bytes result sent to driver
[2024-12-14T19:41:33.439+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Finished task 16.0 in stage 7.0 (TID 216) in 96 ms on localhost (executor driver) (1/200)
[2024-12-14T19:41:33.465+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Finished task 22.0 in stage 7.0 (TID 218). 5776 bytes result sent to driver
[2024-12-14T19:41:33.472+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:33.478+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:33.482+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Finished task 7.0 in stage 7.0 (TID 211). 5776 bytes result sent to driver
[2024-12-14T19:41:33.488+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Finished task 12.0 in stage 7.0 (TID 214) in 100 ms on localhost (executor driver) (2/200)
[2024-12-14T19:41:33.494+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Finished task 14.0 in stage 7.0 (TID 215). 5819 bytes result sent to driver
[2024-12-14T19:41:33.503+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Finished task 29.0 in stage 7.0 (TID 221). 5776 bytes result sent to driver
[2024-12-14T19:41:33.508+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 32.0 in stage 7.0 (TID 223)
24/12/14 19:41:33 INFO TaskSetManager: Starting task 34.0 in stage 7.0 (TID 224) (localhost, executor driver, partition 34, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.515+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 34.0 in stage 7.0 (TID 224)
24/12/14 19:41:33 INFO Executor: Finished task 0.0 in stage 7.0 (TID 206). 5776 bytes result sent to driver
[2024-12-14T19:41:33.522+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 35.0 in stage 7.0 (TID 225) (localhost, executor driver, partition 35, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:33 INFO Executor: Running task 35.0 in stage 7.0 (TID 225)
[2024-12-14T19:41:33.533+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 39.0 in stage 7.0 (TID 226) (localhost, executor driver, partition 39, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.537+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 39.0 in stage 7.0 (TID 226)
[2024-12-14T19:41:33.539+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 40.0 in stage 7.0 (TID 227) (localhost, executor driver, partition 40, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.540+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Finished task 25.0 in stage 7.0 (TID 219) in 125 ms on localhost (executor driver) (3/200)
[2024-12-14T19:41:33.543+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Finished task 31.0 in stage 7.0 (TID 222). 5776 bytes result sent to driver
[2024-12-14T19:41:33.546+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 207) in 138 ms on localhost (executor driver) (4/200)
[2024-12-14T19:41:33.552+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 40.0 in stage 7.0 (TID 227)
24/12/14 19:41:33 INFO Executor: Finished task 9.0 in stage 7.0 (TID 213). 5776 bytes result sent to driver
[2024-12-14T19:41:33.560+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Finished task 26.0 in stage 7.0 (TID 220) in 127 ms on localhost (executor driver) (5/200)
[2024-12-14T19:41:33.563+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 212) in 144 ms on localhost (executor driver) (6/200)
[2024-12-14T19:41:33.565+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 42.0 in stage 7.0 (TID 228) (localhost, executor driver, partition 42, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:33.568+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:33.570+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:33.576+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Finished task 19.0 in stage 7.0 (TID 217) in 146 ms on localhost (executor driver) (7/200)
[2024-12-14T19:41:33.581+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 43.0 in stage 7.0 (TID 229) (localhost, executor driver, partition 43, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO Executor: Running task 42.0 in stage 7.0 (TID 228)
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:33 INFO Executor: Running task 43.0 in stage 7.0 (TID 229)
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:33.584+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 46.0 in stage 7.0 (TID 230) (localhost, executor driver, partition 46, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.591+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 210) in 162 ms on localhost (executor driver) (8/200)
[2024-12-14T19:41:33.597+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 46.0 in stage 7.0 (TID 230)
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
24/12/14 19:41:33 INFO Executor: Finished task 39.0 in stage 7.0 (TID 226). 5776 bytes result sent to driver
24/12/14 19:41:33 INFO TaskSetManager: Starting task 47.0 in stage 7.0 (TID 231) (localhost, executor driver, partition 47, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.608+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 209) in 180 ms on localhost (executor driver) (9/200)
[2024-12-14T19:41:33.610+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 208) in 185 ms on localhost (executor driver) (10/200)
[2024-12-14T19:41:33.615+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 47.0 in stage 7.0 (TID 231)
[2024-12-14T19:41:33.616+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Finished task 34.0 in stage 7.0 (TID 224). 5819 bytes result sent to driver
24/12/14 19:41:33 INFO Executor: Finished task 35.0 in stage 7.0 (TID 225). 5776 bytes result sent to driver
[2024-12-14T19:41:33.618+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:33.620+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 48.0 in stage 7.0 (TID 232) (localhost, executor driver, partition 48, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.626+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
[2024-12-14T19:41:33.630+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:33.636+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
24/12/14 19:41:33 INFO Executor: Running task 48.0 in stage 7.0 (TID 232)
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:33.647+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
[2024-12-14T19:41:33.650+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Finished task 32.0 in stage 7.0 (TID 223). 5819 bytes result sent to driver
24/12/14 19:41:33 INFO Executor: Finished task 40.0 in stage 7.0 (TID 227). 5819 bytes result sent to driver
[2024-12-14T19:41:33.654+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 49.0 in stage 7.0 (TID 233) (localhost, executor driver, partition 49, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.658+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:33.660+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Finished task 22.0 in stage 7.0 (TID 218) in 220 ms on localhost (executor driver) (11/200)
24/12/14 19:41:33 INFO Executor: Running task 49.0 in stage 7.0 (TID 233)
24/12/14 19:41:33 INFO Executor: Finished task 46.0 in stage 7.0 (TID 230). 5776 bytes result sent to driver
[2024-12-14T19:41:33.664+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 50.0 in stage 7.0 (TID 234) (localhost, executor driver, partition 50, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.668+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 211) in 242 ms on localhost (executor driver) (12/200)
[2024-12-14T19:41:33.670+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Finished task 14.0 in stage 7.0 (TID 215) in 239 ms on localhost (executor driver) (13/200)
[2024-12-14T19:41:33.672+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Finished task 43.0 in stage 7.0 (TID 229). 5776 bytes result sent to driver
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:33 INFO TaskSetManager: Starting task 51.0 in stage 7.0 (TID 235) (localhost, executor driver, partition 51, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:33 INFO Executor: Finished task 47.0 in stage 7.0 (TID 231). 5776 bytes result sent to driver
24/12/14 19:41:33 INFO Executor: Running task 50.0 in stage 7.0 (TID 234)
[2024-12-14T19:41:33.674+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 51.0 in stage 7.0 (TID 235)
[2024-12-14T19:41:33.679+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Finished task 42.0 in stage 7.0 (TID 228). 5776 bytes result sent to driver
[2024-12-14T19:41:33.684+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 52.0 in stage 7.0 (TID 236) (localhost, executor driver, partition 52, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.689+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Finished task 29.0 in stage 7.0 (TID 221) in 244 ms on localhost (executor driver) (14/200)
[2024-12-14T19:41:33.691+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 52.0 in stage 7.0 (TID 236)
[2024-12-14T19:41:33.693+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 53.0 in stage 7.0 (TID 237) (localhost, executor driver, partition 53, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:33 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 206) in 264 ms on localhost (executor driver) (15/200)
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO Executor: Running task 53.0 in stage 7.0 (TID 237)
24/12/14 19:41:33 INFO TaskSetManager: Finished task 31.0 in stage 7.0 (TID 222) in 180 ms on localhost (executor driver) (16/200)
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:33.695+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 54.0 in stage 7.0 (TID 238) (localhost, executor driver, partition 54, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.699+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 57.0 in stage 7.0 (TID 239) (localhost, executor driver, partition 57, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:33 INFO Executor: Running task 54.0 in stage 7.0 (TID 238)
[2024-12-14T19:41:33.701+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 57.0 in stage 7.0 (TID 239)
[2024-12-14T19:41:33.708+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:33.717+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
24/12/14 19:41:33 INFO TaskSetManager: Starting task 59.0 in stage 7.0 (TID 240) (localhost, executor driver, partition 59, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:33 INFO Executor: Finished task 48.0 in stage 7.0 (TID 232). 5819 bytes result sent to driver
[2024-12-14T19:41:33.721+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 59.0 in stage 7.0 (TID 240)
[2024-12-14T19:41:33.725+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 60.0 in stage 7.0 (TID 241) (localhost, executor driver, partition 60, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.728+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 60.0 in stage 7.0 (TID 241)
24/12/14 19:41:33 INFO TaskSetManager: Starting task 61.0 in stage 7.0 (TID 242) (localhost, executor driver, partition 61, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.731+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 61.0 in stage 7.0 (TID 242)
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:33.733+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:33.736+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 62.0 in stage 7.0 (TID 243) (localhost, executor driver, partition 62, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:33 INFO Executor: Finished task 52.0 in stage 7.0 (TID 236). 5776 bytes result sent to driver
[2024-12-14T19:41:33.738+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Finished task 49.0 in stage 7.0 (TID 233). 5776 bytes result sent to driver
[2024-12-14T19:41:33.741+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 62.0 in stage 7.0 (TID 243)
24/12/14 19:41:33 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 213) in 314 ms on localhost (executor driver) (17/200)
[2024-12-14T19:41:33.745+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:33.747+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO TaskSetManager: Starting task 63.0 in stage 7.0 (TID 244) (localhost, executor driver, partition 63, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.749+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:33.751+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2024-12-14T19:41:33.753+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 63.0 in stage 7.0 (TID 244)
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:33.757+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 64.0 in stage 7.0 (TID 245) (localhost, executor driver, partition 64, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.760+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:33.762+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 64.0 in stage 7.0 (TID 245)
[2024-12-14T19:41:33.766+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 68.0 in stage 7.0 (TID 246) (localhost, executor driver, partition 68, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.768+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 68.0 in stage 7.0 (TID 246)
[2024-12-14T19:41:33.771+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 69.0 in stage 7.0 (TID 247) (localhost, executor driver, partition 69, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.778+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:33.780+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 69.0 in stage 7.0 (TID 247)
24/12/14 19:41:33 INFO TaskSetManager: Starting task 70.0 in stage 7.0 (TID 248) (localhost, executor driver, partition 70, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.787+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Finished task 57.0 in stage 7.0 (TID 239). 5776 bytes result sent to driver
[2024-12-14T19:41:33.789+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2024-12-14T19:41:33.794+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 70.0 in stage 7.0 (TID 248)
[2024-12-14T19:41:33.796+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 71.0 in stage 7.0 (TID 249) (localhost, executor driver, partition 71, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.804+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Finished task 53.0 in stage 7.0 (TID 237). 5776 bytes result sent to driver
24/12/14 19:41:33 INFO Executor: Finished task 54.0 in stage 7.0 (TID 238). 5776 bytes result sent to driver
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:33.811+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:33.815+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Finished task 39.0 in stage 7.0 (TID 226) in 228 ms on localhost (executor driver) (18/200)
24/12/14 19:41:33 INFO TaskSetManager: Finished task 40.0 in stage 7.0 (TID 227) in 226 ms on localhost (executor driver) (19/200)
24/12/14 19:41:33 INFO Executor: Finished task 51.0 in stage 7.0 (TID 235). 5776 bytes result sent to driver
[2024-12-14T19:41:33.819+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Finished task 35.0 in stage 7.0 (TID 225) in 236 ms on localhost (executor driver) (20/200)
[2024-12-14T19:41:33.822+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:33.826+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:33.834+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Finished task 32.0 in stage 7.0 (TID 223) in 279 ms on localhost (executor driver) (21/200)
24/12/14 19:41:33 INFO TaskSetManager: Finished task 47.0 in stage 7.0 (TID 231) in 199 ms on localhost (executor driver) (22/200)
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 17 ms
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO Executor: Running task 71.0 in stage 7.0 (TID 249)
24/12/14 19:41:33 INFO TaskSetManager: Finished task 34.0 in stage 7.0 (TID 224) in 264 ms on localhost (executor driver) (23/200)
[2024-12-14T19:41:33.840+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Finished task 61.0 in stage 7.0 (TID 242). 5776 bytes result sent to driver
24/12/14 19:41:33 INFO TaskSetManager: Finished task 42.0 in stage 7.0 (TID 228) in 232 ms on localhost (executor driver) (24/200)
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
[2024-12-14T19:41:33.847+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 34 ms
24/12/14 19:41:33 INFO TaskSetManager: Starting task 72.0 in stage 7.0 (TID 250) (localhost, executor driver, partition 72, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.860+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Finished task 63.0 in stage 7.0 (TID 244). 5819 bytes result sent to driver
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:33.867+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:33.869+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Finished task 64.0 in stage 7.0 (TID 245). 5776 bytes result sent to driver
24/12/14 19:41:33 INFO Executor: Running task 72.0 in stage 7.0 (TID 250)
[2024-12-14T19:41:33.875+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 73.0 in stage 7.0 (TID 251) (localhost, executor driver, partition 73, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.883+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 73.0 in stage 7.0 (TID 251)
[2024-12-14T19:41:33.892+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 74.0 in stage 7.0 (TID 252) (localhost, executor driver, partition 74, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:33 INFO Executor: Finished task 50.0 in stage 7.0 (TID 234). 5776 bytes result sent to driver
[2024-12-14T19:41:33.897+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Finished task 46.0 in stage 7.0 (TID 230) in 247 ms on localhost (executor driver) (25/200)
24/12/14 19:41:33 INFO Executor: Running task 74.0 in stage 7.0 (TID 252)
24/12/14 19:41:33 INFO TaskSetManager: Finished task 49.0 in stage 7.0 (TID 233) in 203 ms on localhost (executor driver) (26/200)
24/12/14 19:41:33 INFO TaskSetManager: Starting task 75.0 in stage 7.0 (TID 253) (localhost, executor driver, partition 75, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.903+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Finished task 43.0 in stage 7.0 (TID 229) in 262 ms on localhost (executor driver) (27/200)
[2024-12-14T19:41:33.911+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Finished task 48.0 in stage 7.0 (TID 232) in 221 ms on localhost (executor driver) (28/200)
24/12/14 19:41:33 INFO Executor: Finished task 69.0 in stage 7.0 (TID 247). 5776 bytes result sent to driver
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO TaskSetManager: Finished task 53.0 in stage 7.0 (TID 237) in 162 ms on localhost (executor driver) (29/200)
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:33.923+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 75.0 in stage 7.0 (TID 253)
[2024-12-14T19:41:33.926+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Finished task 54.0 in stage 7.0 (TID 238) in 160 ms on localhost (executor driver) (30/200)
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2024-12-14T19:41:33.932+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Finished task 51.0 in stage 7.0 (TID 235) in 178 ms on localhost (executor driver) (31/200)
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:33.937+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:33.942+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Finished task 52.0 in stage 7.0 (TID 236) in 181 ms on localhost (executor driver) (32/200)
[2024-12-14T19:41:33.948+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Finished task 62.0 in stage 7.0 (TID 243). 5862 bytes result sent to driver
[2024-12-14T19:41:33.955+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 76.0 in stage 7.0 (TID 254) (localhost, executor driver, partition 76, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:33 INFO Executor: Finished task 59.0 in stage 7.0 (TID 240). 5819 bytes result sent to driver
24/12/14 19:41:33 INFO Executor: Finished task 68.0 in stage 7.0 (TID 246). 5776 bytes result sent to driver
[2024-12-14T19:41:33.961+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 76.0 in stage 7.0 (TID 254)
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:33 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:32963 in memory (size: 5.9 KiB, free: 434.3 MiB)
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:33.966+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:33 INFO TaskSetManager: Starting task 77.0 in stage 7.0 (TID 255) (localhost, executor driver, partition 77, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:33 INFO Executor: Finished task 71.0 in stage 7.0 (TID 249). 5862 bytes result sent to driver
[2024-12-14T19:41:33.969+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 78.0 in stage 7.0 (TID 256) (localhost, executor driver, partition 78, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:33 INFO TaskSetManager: Starting task 79.0 in stage 7.0 (TID 257) (localhost, executor driver, partition 79, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:33 INFO Executor: Finished task 70.0 in stage 7.0 (TID 248). 5819 bytes result sent to driver
[2024-12-14T19:41:33.974+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 77.0 in stage 7.0 (TID 255)
[2024-12-14T19:41:33.979+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 78.0 in stage 7.0 (TID 256)
[2024-12-14T19:41:33.983+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Finished task 60.0 in stage 7.0 (TID 241). 5819 bytes result sent to driver
[2024-12-14T19:41:33.986+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Finished task 72.0 in stage 7.0 (TID 250). 5862 bytes result sent to driver
24/12/14 19:41:33 INFO TaskSetManager: Finished task 57.0 in stage 7.0 (TID 239) in 204 ms on localhost (executor driver) (33/200)
24/12/14 19:41:33 INFO Executor: Finished task 74.0 in stage 7.0 (TID 252). 5819 bytes result sent to driver
24/12/14 19:41:33 INFO Executor: Running task 79.0 in stage 7.0 (TID 257)
[2024-12-14T19:41:33.993+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 80.0 in stage 7.0 (TID 258) (localhost, executor driver, partition 80, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:33.998+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Finished task 64.0 in stage 7.0 (TID 245) in 168 ms on localhost (executor driver) (34/200)
[2024-12-14T19:41:34.001+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Finished task 63.0 in stage 7.0 (TID 244) in 174 ms on localhost (executor driver) (35/200)
[2024-12-14T19:41:34.008+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 81.0 in stage 7.0 (TID 259) (localhost, executor driver, partition 81, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.014+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Finished task 61.0 in stage 7.0 (TID 242) in 189 ms on localhost (executor driver) (36/200)
[2024-12-14T19:41:34.024+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Finished task 69.0 in stage 7.0 (TID 247) in 166 ms on localhost (executor driver) (37/200)
[2024-12-14T19:41:34.026+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO Executor: Finished task 73.0 in stage 7.0 (TID 251). 5819 bytes result sent to driver
[2024-12-14T19:41:34.040+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 80.0 in stage 7.0 (TID 258)
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
24/12/14 19:41:33 INFO Executor: Finished task 75.0 in stage 7.0 (TID 253). 5862 bytes result sent to driver
[2024-12-14T19:41:34.044+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Finished task 50.0 in stage 7.0 (TID 234) in 265 ms on localhost (executor driver) (38/200)
24/12/14 19:41:33 INFO Executor: Running task 81.0 in stage 7.0 (TID 259)
[2024-12-14T19:41:34.048+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:34.050+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:34.053+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:34.056+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:34.058+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 82.0 in stage 7.0 (TID 260) (localhost, executor driver, partition 82, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:33 INFO Executor: Running task 82.0 in stage 7.0 (TID 260)
[2024-12-14T19:41:34.060+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 83.0 in stage 7.0 (TID 261) (localhost, executor driver, partition 83, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.062+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 83.0 in stage 7.0 (TID 261)
[2024-12-14T19:41:34.066+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 84.0 in stage 7.0 (TID 262) (localhost, executor driver, partition 84, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.072+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Finished task 62.0 in stage 7.0 (TID 243) in 215 ms on localhost (executor driver) (39/200)
[2024-12-14T19:41:34.078+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Finished task 68.0 in stage 7.0 (TID 246) in 200 ms on localhost (executor driver) (40/200)
24/12/14 19:41:33 INFO Executor: Running task 84.0 in stage 7.0 (TID 262)
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:33 INFO TaskSetManager: Finished task 59.0 in stage 7.0 (TID 240) in 246 ms on localhost (executor driver) (41/200)
24/12/14 19:41:33 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:32963 in memory (size: 20.7 KiB, free: 434.3 MiB)
[2024-12-14T19:41:34.081+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 85.0 in stage 7.0 (TID 263) (localhost, executor driver, partition 85, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.086+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 85.0 in stage 7.0 (TID 263)
[2024-12-14T19:41:34.089+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Finished task 71.0 in stage 7.0 (TID 249) in 193 ms on localhost (executor driver) (42/200)
[2024-12-14T19:41:34.096+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 86.0 in stage 7.0 (TID 264) (localhost, executor driver, partition 86, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.099+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 86.0 in stage 7.0 (TID 264)
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:33 INFO TaskSetManager: Finished task 70.0 in stage 7.0 (TID 248) in 212 ms on localhost (executor driver) (43/200)
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:34.102+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:34.107+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms
[2024-12-14T19:41:34.114+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Finished task 76.0 in stage 7.0 (TID 254). 5776 bytes result sent to driver
24/12/14 19:41:33 INFO Executor: Finished task 78.0 in stage 7.0 (TID 256). 5776 bytes result sent to driver
[2024-12-14T19:41:34.121+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO TaskSetManager: Starting task 88.0 in stage 7.0 (TID 265) (localhost, executor driver, partition 88, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO Executor: Finished task 77.0 in stage 7.0 (TID 255). 5819 bytes result sent to driver
24/12/14 19:41:33 INFO Executor: Running task 88.0 in stage 7.0 (TID 265)
[2024-12-14T19:41:34.136+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 89.0 in stage 7.0 (TID 266) (localhost, executor driver, partition 89, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.138+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Finished task 60.0 in stage 7.0 (TID 241) in 267 ms on localhost (executor driver) (44/200)
[2024-12-14T19:41:34.140+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Finished task 84.0 in stage 7.0 (TID 262). 5776 bytes result sent to driver
24/12/14 19:41:33 INFO Executor: Finished task 79.0 in stage 7.0 (TID 257). 5776 bytes result sent to driver
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2024-12-14T19:41:34.145+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Finished task 72.0 in stage 7.0 (TID 250) in 180 ms on localhost (executor driver) (45/200)
[2024-12-14T19:41:34.151+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 89.0 in stage 7.0 (TID 266)
[2024-12-14T19:41:34.154+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:34.162+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:33 INFO TaskSetManager: Starting task 90.0 in stage 7.0 (TID 267) (localhost, executor driver, partition 90, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.169+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 90.0 in stage 7.0 (TID 267)
[2024-12-14T19:41:34.175+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 92.0 in stage 7.0 (TID 268) (localhost, executor driver, partition 92, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.179+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Finished task 83.0 in stage 7.0 (TID 261). 5819 bytes result sent to driver
[2024-12-14T19:41:34.181+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Finished task 74.0 in stage 7.0 (TID 252) in 223 ms on localhost (executor driver) (46/200)
24/12/14 19:41:33 INFO Executor: Running task 92.0 in stage 7.0 (TID 268)
[2024-12-14T19:41:34.187+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 95.0 in stage 7.0 (TID 269) (localhost, executor driver, partition 95, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:33 INFO Executor: Finished task 80.0 in stage 7.0 (TID 258). 5862 bytes result sent to driver
[2024-12-14T19:41:34.189+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Finished task 75.0 in stage 7.0 (TID 253) in 216 ms on localhost (executor driver) (47/200)
24/12/14 19:41:33 INFO Executor: Running task 95.0 in stage 7.0 (TID 269)
[2024-12-14T19:41:34.191+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 96.0 in stage 7.0 (TID 270) (localhost, executor driver, partition 96, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.195+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 96.0 in stage 7.0 (TID 270)
24/12/14 19:41:33 INFO Executor: Finished task 85.0 in stage 7.0 (TID 263). 5819 bytes result sent to driver
[2024-12-14T19:41:34.197+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Finished task 82.0 in stage 7.0 (TID 260). 5819 bytes result sent to driver
[2024-12-14T19:41:34.199+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 97.0 in stage 7.0 (TID 271) (localhost, executor driver, partition 97, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.201+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 24 ms
[2024-12-14T19:41:34.208+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 97.0 in stage 7.0 (TID 271)
[2024-12-14T19:41:34.210+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Finished task 81.0 in stage 7.0 (TID 259). 5819 bytes result sent to driver
[2024-12-14T19:41:34.214+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 98.0 in stage 7.0 (TID 272) (localhost, executor driver, partition 98, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.217+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:34.222+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 98.0 in stage 7.0 (TID 272)
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
[2024-12-14T19:41:34.225+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 99.0 in stage 7.0 (TID 273) (localhost, executor driver, partition 99, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.233+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms
24/12/14 19:41:33 INFO Executor: Running task 99.0 in stage 7.0 (TID 273)
[2024-12-14T19:41:34.236+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 100.0 in stage 7.0 (TID 274) (localhost, executor driver, partition 100, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.239+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 33 ms
[2024-12-14T19:41:34.244+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 101.0 in stage 7.0 (TID 275) (localhost, executor driver, partition 101, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.262+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 101.0 in stage 7.0 (TID 275)
[2024-12-14T19:41:34.266+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Running task 100.0 in stage 7.0 (TID 274)
[2024-12-14T19:41:34.275+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 102.0 in stage 7.0 (TID 276) (localhost, executor driver, partition 102, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.283+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Finished task 73.0 in stage 7.0 (TID 251) in 358 ms on localhost (executor driver) (48/200)
24/12/14 19:41:33 INFO Executor: Finished task 89.0 in stage 7.0 (TID 266). 5862 bytes result sent to driver
[2024-12-14T19:41:34.291+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:34.297+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO Executor: Finished task 86.0 in stage 7.0 (TID 264). 5862 bytes result sent to driver
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
24/12/14 19:41:33 INFO Executor: Running task 102.0 in stage 7.0 (TID 276)
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:34.304+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO TaskSetManager: Starting task 103.0 in stage 7.0 (TID 277) (localhost, executor driver, partition 103, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:33 INFO TaskSetManager: Finished task 77.0 in stage 7.0 (TID 255) in 305 ms on localhost (executor driver) (49/200)
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO Executor: Running task 103.0 in stage 7.0 (TID 277)
24/12/14 19:41:33 INFO Executor: Finished task 90.0 in stage 7.0 (TID 267). 5819 bytes result sent to driver
[2024-12-14T19:41:34.306+0000] {docker.py:413} INFO - 24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:34.308+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 96.0 in stage 7.0 (TID 270). 5776 bytes result sent to driver
[2024-12-14T19:41:34.312+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:34 INFO TaskSetManager: Finished task 78.0 in stage 7.0 (TID 256) in 317 ms on localhost (executor driver) (50/200)
[2024-12-14T19:41:34.317+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 76.0 in stage 7.0 (TID 254) in 332 ms on localhost (executor driver) (51/200)
24/12/14 19:41:34 INFO TaskSetManager: Starting task 104.0 in stage 7.0 (TID 278) (localhost, executor driver, partition 104, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:34 INFO TaskSetManager: Finished task 84.0 in stage 7.0 (TID 262) in 269 ms on localhost (executor driver) (52/200)
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:34.322+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 104.0 in stage 7.0 (TID 278)
[2024-12-14T19:41:34.326+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 105.0 in stage 7.0 (TID 279) (localhost, executor driver, partition 105, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.329+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 105.0 in stage 7.0 (TID 279)
[2024-12-14T19:41:34.331+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 83.0 in stage 7.0 (TID 261) in 291 ms on localhost (executor driver) (53/200)
[2024-12-14T19:41:34.337+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:34.344+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:34.348+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 23 ms
[2024-12-14T19:41:34.356+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 79.0 in stage 7.0 (TID 257) in 340 ms on localhost (executor driver) (54/200)
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
[2024-12-14T19:41:34.360+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 92.0 in stage 7.0 (TID 268). 5776 bytes result sent to driver
[2024-12-14T19:41:34.365+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 82.0 in stage 7.0 (TID 260) in 358 ms on localhost (executor driver) (55/200)
24/12/14 19:41:34 INFO TaskSetManager: Finished task 80.0 in stage 7.0 (TID 258) in 383 ms on localhost (executor driver) (56/200)
[2024-12-14T19:41:34.370+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 106.0 in stage 7.0 (TID 280) (localhost, executor driver, partition 106, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.372+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 88.0 in stage 7.0 (TID 265). 5819 bytes result sent to driver
24/12/14 19:41:34 INFO Executor: Finished task 101.0 in stage 7.0 (TID 275). 5819 bytes result sent to driver
24/12/14 19:41:34 INFO Executor: Finished task 97.0 in stage 7.0 (TID 271). 5819 bytes result sent to driver
[2024-12-14T19:41:34.375+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 106.0 in stage 7.0 (TID 280)
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:34 INFO TaskSetManager: Starting task 108.0 in stage 7.0 (TID 281) (localhost, executor driver, partition 108, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.381+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:34.383+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:34.386+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 102.0 in stage 7.0 (TID 276). 5819 bytes result sent to driver
[2024-12-14T19:41:34.392+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 95.0 in stage 7.0 (TID 269). 5819 bytes result sent to driver
[2024-12-14T19:41:34.401+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 108.0 in stage 7.0 (TID 281)
[2024-12-14T19:41:34.404+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 99.0 in stage 7.0 (TID 273). 5776 bytes result sent to driver
[2024-12-14T19:41:34.406+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 109.0 in stage 7.0 (TID 282) (localhost, executor driver, partition 109, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.412+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 109.0 in stage 7.0 (TID 282)
[2024-12-14T19:41:34.420+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 111.0 in stage 7.0 (TID 283) (localhost, executor driver, partition 111, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.425+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 111.0 in stage 7.0 (TID 283)
[2024-12-14T19:41:34.427+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 105.0 in stage 7.0 (TID 279). 5776 bytes result sent to driver
[2024-12-14T19:41:34.433+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:34.442+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 113.0 in stage 7.0 (TID 284) (localhost, executor driver, partition 113, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.445+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 104.0 in stage 7.0 (TID 278). 5776 bytes result sent to driver
[2024-12-14T19:41:34.448+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 113.0 in stage 7.0 (TID 284)
[2024-12-14T19:41:34.450+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:32963 in memory (size: 25.7 KiB, free: 434.4 MiB)
[2024-12-14T19:41:34.454+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 103.0 in stage 7.0 (TID 277). 5776 bytes result sent to driver
[2024-12-14T19:41:34.459+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 120.0 in stage 7.0 (TID 285) (localhost, executor driver, partition 120, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.462+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 123.0 in stage 7.0 (TID 286) (localhost, executor driver, partition 123, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.466+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 120.0 in stage 7.0 (TID 285)
[2024-12-14T19:41:34.471+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 86.0 in stage 7.0 (TID 264) in 390 ms on localhost (executor driver) (57/200)
[2024-12-14T19:41:34.477+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 100.0 in stage 7.0 (TID 274). 5819 bytes result sent to driver
[2024-12-14T19:41:34.482+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 89.0 in stage 7.0 (TID 266) in 382 ms on localhost (executor driver) (58/200)
[2024-12-14T19:41:34.485+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:34.488+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 98.0 in stage 7.0 (TID 272). 5776 bytes result sent to driver
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2024-12-14T19:41:34.492+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 96.0 in stage 7.0 (TID 270) in 308 ms on localhost (executor driver) (59/200)
[2024-12-14T19:41:34.495+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 123.0 in stage 7.0 (TID 286)
[2024-12-14T19:41:34.500+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 81.0 in stage 7.0 (TID 259) in 459 ms on localhost (executor driver) (60/200)
[2024-12-14T19:41:34.504+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 85.0 in stage 7.0 (TID 263) in 421 ms on localhost (executor driver) (61/200)
[2024-12-14T19:41:34.506+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:34.511+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:34.517+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:34.524+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:34.531+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 92.0 in stage 7.0 (TID 268) in 369 ms on localhost (executor driver) (62/200)
[2024-12-14T19:41:34.540+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 90.0 in stage 7.0 (TID 267) in 395 ms on localhost (executor driver) (63/200)
[2024-12-14T19:41:34.551+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 124.0 in stage 7.0 (TID 287) (localhost, executor driver, partition 124, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.558+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 88.0 in stage 7.0 (TID 265) in 427 ms on localhost (executor driver) (64/200)
24/12/14 19:41:34 INFO Executor: Finished task 106.0 in stage 7.0 (TID 280). 5776 bytes result sent to driver
[2024-12-14T19:41:34.565+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 101.0 in stage 7.0 (TID 275) in 266 ms on localhost (executor driver) (65/200)
24/12/14 19:41:34 INFO TaskSetManager: Finished task 97.0 in stage 7.0 (TID 271) in 327 ms on localhost (executor driver) (66/200)
[2024-12-14T19:41:34.568+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 109.0 in stage 7.0 (TID 282). 5776 bytes result sent to driver
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO Executor: Running task 124.0 in stage 7.0 (TID 287)
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2024-12-14T19:41:34.570+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 111.0 in stage 7.0 (TID 283). 5776 bytes result sent to driver
[2024-12-14T19:41:34.572+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 125.0 in stage 7.0 (TID 288) (localhost, executor driver, partition 125, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:34 INFO Executor: Running task 125.0 in stage 7.0 (TID 288)
[2024-12-14T19:41:34.577+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:34.579+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 127.0 in stage 7.0 (TID 289) (localhost, executor driver, partition 127, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.581+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 129.0 in stage 7.0 (TID 290) (localhost, executor driver, partition 129, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.586+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 19 ms
24/12/14 19:41:34 INFO Executor: Running task 127.0 in stage 7.0 (TID 289)
[2024-12-14T19:41:34.592+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 108.0 in stage 7.0 (TID 281). 5819 bytes result sent to driver
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:34.600+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 102.0 in stage 7.0 (TID 276) in 283 ms on localhost (executor driver) (67/200)
[2024-12-14T19:41:34.603+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:34.609+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 113.0 in stage 7.0 (TID 284). 5776 bytes result sent to driver
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO TaskSetManager: Starting task 130.0 in stage 7.0 (TID 291) (localhost, executor driver, partition 130, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:34.612+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 99.0 in stage 7.0 (TID 273) in 345 ms on localhost (executor driver) (68/200)
[2024-12-14T19:41:34.616+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 105.0 in stage 7.0 (TID 279) in 223 ms on localhost (executor driver) (69/200)
24/12/14 19:41:34 INFO Executor: Running task 130.0 in stage 7.0 (TID 291)
[2024-12-14T19:41:34.622+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 129.0 in stage 7.0 (TID 290)
[2024-12-14T19:41:34.625+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 95.0 in stage 7.0 (TID 269) in 400 ms on localhost (executor driver) (70/200)
[2024-12-14T19:41:34.632+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 132.0 in stage 7.0 (TID 292) (localhost, executor driver, partition 132, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.635+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 124.0 in stage 7.0 (TID 287). 5776 bytes result sent to driver
[2024-12-14T19:41:34.639+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 135.0 in stage 7.0 (TID 293) (localhost, executor driver, partition 135, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.642+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 104.0 in stage 7.0 (TID 278) in 249 ms on localhost (executor driver) (71/200)
[2024-12-14T19:41:34.648+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:34.652+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 132.0 in stage 7.0 (TID 292)
24/12/14 19:41:34 INFO TaskSetManager: Finished task 103.0 in stage 7.0 (TID 277) in 278 ms on localhost (executor driver) (72/200)
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:34.657+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 135.0 in stage 7.0 (TID 293)
[2024-12-14T19:41:34.661+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 136.0 in stage 7.0 (TID 294) (localhost, executor driver, partition 136, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.666+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 100.0 in stage 7.0 (TID 274) in 344 ms on localhost (executor driver) (73/200)
[2024-12-14T19:41:34.672+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 136.0 in stage 7.0 (TID 294)
[2024-12-14T19:41:34.678+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 123.0 in stage 7.0 (TID 286). 5776 bytes result sent to driver
[2024-12-14T19:41:34.681+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 137.0 in stage 7.0 (TID 295) (localhost, executor driver, partition 137, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.684+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 98.0 in stage 7.0 (TID 272) in 392 ms on localhost (executor driver) (74/200)
[2024-12-14T19:41:34.686+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 137.0 in stage 7.0 (TID 295)
24/12/14 19:41:34 INFO Executor: Finished task 120.0 in stage 7.0 (TID 285). 5776 bytes result sent to driver
24/12/14 19:41:34 INFO TaskSetManager: Starting task 142.0 in stage 7.0 (TID 296) (localhost, executor driver, partition 142, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.689+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 142.0 in stage 7.0 (TID 296)
[2024-12-14T19:41:34.691+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 145.0 in stage 7.0 (TID 297) (localhost, executor driver, partition 145, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:34 INFO Executor: Finished task 125.0 in stage 7.0 (TID 288). 5776 bytes result sent to driver
[2024-12-14T19:41:34.698+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 145.0 in stage 7.0 (TID 297)
[2024-12-14T19:41:34.703+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 146.0 in stage 7.0 (TID 298) (localhost, executor driver, partition 146, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.711+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 146.0 in stage 7.0 (TID 298)
[2024-12-14T19:41:34.713+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 148.0 in stage 7.0 (TID 299) (localhost, executor driver, partition 148, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO TaskSetManager: Finished task 106.0 in stage 7.0 (TID 280) in 221 ms on localhost (executor driver) (75/200)
[2024-12-14T19:41:34.716+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
24/12/14 19:41:34 INFO Executor: Running task 148.0 in stage 7.0 (TID 299)
[2024-12-14T19:41:34.720+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 108.0 in stage 7.0 (TID 281) in 211 ms on localhost (executor driver) (76/200)
[2024-12-14T19:41:34.726+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 129.0 in stage 7.0 (TID 290). 5776 bytes result sent to driver
[2024-12-14T19:41:34.734+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 109.0 in stage 7.0 (TID 282) in 208 ms on localhost (executor driver) (77/200)
[2024-12-14T19:41:34.736+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 149.0 in stage 7.0 (TID 300) (localhost, executor driver, partition 149, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:34 INFO Executor: Running task 149.0 in stage 7.0 (TID 300)
24/12/14 19:41:34 INFO TaskSetManager: Starting task 150.0 in stage 7.0 (TID 301) (localhost, executor driver, partition 150, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.740+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 113.0 in stage 7.0 (TID 284) in 196 ms on localhost (executor driver) (78/200)
24/12/14 19:41:34 INFO TaskSetManager: Finished task 111.0 in stage 7.0 (TID 283) in 205 ms on localhost (executor driver) (79/200)
[2024-12-14T19:41:34.746+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 124.0 in stage 7.0 (TID 287) in 130 ms on localhost (executor driver) (80/200)
[2024-12-14T19:41:34.749+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:34.752+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
24/12/14 19:41:34 INFO Executor: Running task 150.0 in stage 7.0 (TID 301)
24/12/14 19:41:34 INFO TaskSetManager: Starting task 151.0 in stage 7.0 (TID 302) (localhost, executor driver, partition 151, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.753+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:34.759+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:34.763+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
[2024-12-14T19:41:34.765+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:34.771+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
[2024-12-14T19:41:34.774+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 135.0 in stage 7.0 (TID 293). 5819 bytes result sent to driver
[2024-12-14T19:41:34.776+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 152.0 in stage 7.0 (TID 303) (localhost, executor driver, partition 152, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:34 INFO Executor: Running task 151.0 in stage 7.0 (TID 302)
[2024-12-14T19:41:34.779+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2024-12-14T19:41:34.781+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO Executor: Finished task 132.0 in stage 7.0 (TID 292). 5776 bytes result sent to driver
[2024-12-14T19:41:34.783+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 152.0 in stage 7.0 (TID 303)
[2024-12-14T19:41:34.789+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:34.791+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 154.0 in stage 7.0 (TID 304) (localhost, executor driver, partition 154, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.793+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
[2024-12-14T19:41:34.796+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO Executor: Running task 154.0 in stage 7.0 (TID 304)
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:34.799+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 127.0 in stage 7.0 (TID 289). 5776 bytes result sent to driver
[2024-12-14T19:41:34.804+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 15 ms
[2024-12-14T19:41:34.805+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
24/12/14 19:41:34 INFO Executor: Finished task 146.0 in stage 7.0 (TID 298). 5776 bytes result sent to driver
[2024-12-14T19:41:34.808+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 158.0 in stage 7.0 (TID 305) (localhost, executor driver, partition 158, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.818+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:34 INFO Executor: Running task 158.0 in stage 7.0 (TID 305)
24/12/14 19:41:34 INFO TaskSetManager: Starting task 159.0 in stage 7.0 (TID 306) (localhost, executor driver, partition 159, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.822+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 129.0 in stage 7.0 (TID 290) in 153 ms on localhost (executor driver) (81/200)
[2024-12-14T19:41:34.824+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 159.0 in stage 7.0 (TID 306)
[2024-12-14T19:41:34.828+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 120.0 in stage 7.0 (TID 285) in 247 ms on localhost (executor driver) (82/200)
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:34.835+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 130.0 in stage 7.0 (TID 291). 5819 bytes result sent to driver
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:34.840+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 145.0 in stage 7.0 (TID 297). 5776 bytes result sent to driver
[2024-12-14T19:41:34.848+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 161.0 in stage 7.0 (TID 307) (localhost, executor driver, partition 161, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.860+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 150.0 in stage 7.0 (TID 301). 5776 bytes result sent to driver
[2024-12-14T19:41:34.876+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 161.0 in stage 7.0 (TID 307)
[2024-12-14T19:41:34.882+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:34.889+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 136.0 in stage 7.0 (TID 294). 5819 bytes result sent to driver
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
24/12/14 19:41:34 INFO TaskSetManager: Starting task 162.0 in stage 7.0 (TID 308) (localhost, executor driver, partition 162, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.897+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:34.899+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 123.0 in stage 7.0 (TID 286) in 256 ms on localhost (executor driver) (83/200)
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2024-12-14T19:41:34.906+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO Executor: Finished task 142.0 in stage 7.0 (TID 296). 5776 bytes result sent to driver
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
24/12/14 19:41:34 INFO Executor: Running task 162.0 in stage 7.0 (TID 308)
24/12/14 19:41:34 INFO Executor: Finished task 137.0 in stage 7.0 (TID 295). 5776 bytes result sent to driver
[2024-12-14T19:41:34.912+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 164.0 in stage 7.0 (TID 309) (localhost, executor driver, partition 164, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.917+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 149.0 in stage 7.0 (TID 300). 5819 bytes result sent to driver
24/12/14 19:41:34 INFO Executor: Running task 164.0 in stage 7.0 (TID 309)
24/12/14 19:41:34 INFO TaskSetManager: Finished task 132.0 in stage 7.0 (TID 292) in 172 ms on localhost (executor driver) (84/200)
[2024-12-14T19:41:34.919+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 125.0 in stage 7.0 (TID 288) in 216 ms on localhost (executor driver) (85/200)
[2024-12-14T19:41:34.923+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 165.0 in stage 7.0 (TID 310) (localhost, executor driver, partition 165, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.926+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 146.0 in stage 7.0 (TID 298) in 145 ms on localhost (executor driver) (86/200)
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO Executor: Finished task 158.0 in stage 7.0 (TID 305). 5819 bytes result sent to driver
[2024-12-14T19:41:34.931+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2024-12-14T19:41:34.933+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 151.0 in stage 7.0 (TID 302). 5776 bytes result sent to driver
24/12/14 19:41:34 INFO TaskSetManager: Finished task 135.0 in stage 7.0 (TID 293) in 188 ms on localhost (executor driver) (87/200)
[2024-12-14T19:41:34.935+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 165.0 in stage 7.0 (TID 310)
[2024-12-14T19:41:34.938+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 145.0 in stage 7.0 (TID 297) in 158 ms on localhost (executor driver) (88/200)
[2024-12-14T19:41:34.940+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:34.943+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
24/12/14 19:41:34 INFO Executor: Finished task 152.0 in stage 7.0 (TID 303). 5819 bytes result sent to driver
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2024-12-14T19:41:34.946+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 167.0 in stage 7.0 (TID 311) (localhost, executor driver, partition 167, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.949+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 127.0 in stage 7.0 (TID 289) in 244 ms on localhost (executor driver) (89/200)
[2024-12-14T19:41:34.951+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 154.0 in stage 7.0 (TID 304). 5819 bytes result sent to driver
[2024-12-14T19:41:34.953+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 130.0 in stage 7.0 (TID 291) in 228 ms on localhost (executor driver) (90/200)
[2024-12-14T19:41:34.955+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 167.0 in stage 7.0 (TID 311)
[2024-12-14T19:41:34.962+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 148.0 in stage 7.0 (TID 299). 5819 bytes result sent to driver
[2024-12-14T19:41:34.965+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 168.0 in stage 7.0 (TID 312) (localhost, executor driver, partition 168, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.968+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:34 INFO TaskSetManager: Starting task 170.0 in stage 7.0 (TID 313) (localhost, executor driver, partition 170, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:34 INFO TaskSetManager: Finished task 136.0 in stage 7.0 (TID 294) in 223 ms on localhost (executor driver) (91/200)
24/12/14 19:41:34 INFO TaskSetManager: Finished task 150.0 in stage 7.0 (TID 301) in 168 ms on localhost (executor driver) (92/200)
24/12/14 19:41:34 INFO Executor: Running task 168.0 in stage 7.0 (TID 312)
[2024-12-14T19:41:34.972+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 162.0 in stage 7.0 (TID 308). 5776 bytes result sent to driver
24/12/14 19:41:34 INFO Executor: Running task 170.0 in stage 7.0 (TID 313)
24/12/14 19:41:34 INFO TaskSetManager: Starting task 171.0 in stage 7.0 (TID 314) (localhost, executor driver, partition 171, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
24/12/14 19:41:34 INFO Executor: Running task 171.0 in stage 7.0 (TID 314)
[2024-12-14T19:41:34.977+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 172.0 in stage 7.0 (TID 315) (localhost, executor driver, partition 172, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.980+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 173.0 in stage 7.0 (TID 316) (localhost, executor driver, partition 173, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:34 INFO Executor: Finished task 159.0 in stage 7.0 (TID 306). 5819 bytes result sent to driver
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO Executor: Running task 172.0 in stage 7.0 (TID 315)
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:34.982+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 173.0 in stage 7.0 (TID 316)
[2024-12-14T19:41:34.985+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 174.0 in stage 7.0 (TID 317) (localhost, executor driver, partition 174, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.988+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 165.0 in stage 7.0 (TID 310). 5819 bytes result sent to driver
[2024-12-14T19:41:34.994+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 161.0 in stage 7.0 (TID 307). 5776 bytes result sent to driver
24/12/14 19:41:34 INFO Executor: Running task 174.0 in stage 7.0 (TID 317)
24/12/14 19:41:34 INFO TaskSetManager: Starting task 175.0 in stage 7.0 (TID 318) (localhost, executor driver, partition 175, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:34 INFO Executor: Running task 175.0 in stage 7.0 (TID 318)
24/12/14 19:41:34 INFO TaskSetManager: Starting task 179.0 in stage 7.0 (TID 319) (localhost, executor driver, partition 179, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:34.998+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 137.0 in stage 7.0 (TID 295) in 250 ms on localhost (executor driver) (93/200)
[2024-12-14T19:41:35.006+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.014+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:34 INFO Executor: Running task 179.0 in stage 7.0 (TID 319)
24/12/14 19:41:34 INFO TaskSetManager: Finished task 142.0 in stage 7.0 (TID 296) in 243 ms on localhost (executor driver) (94/200)
24/12/14 19:41:34 INFO TaskSetManager: Finished task 151.0 in stage 7.0 (TID 302) in 203 ms on localhost (executor driver) (95/200)
[2024-12-14T19:41:35.018+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 149.0 in stage 7.0 (TID 300) in 218 ms on localhost (executor driver) (96/200)
[2024-12-14T19:41:35.020+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.022+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2024-12-14T19:41:35.025+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO TaskSetManager: Starting task 181.0 in stage 7.0 (TID 320) (localhost, executor driver, partition 181, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.027+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 181.0 in stage 7.0 (TID 320)
[2024-12-14T19:41:35.032+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:34 INFO Executor: Finished task 167.0 in stage 7.0 (TID 311). 5819 bytes result sent to driver
[2024-12-14T19:41:35.034+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 172.0 in stage 7.0 (TID 315). 5819 bytes result sent to driver
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 26 ms
24/12/14 19:41:34 INFO Executor: Finished task 164.0 in stage 7.0 (TID 309). 5819 bytes result sent to driver
24/12/14 19:41:34 INFO Executor: Finished task 170.0 in stage 7.0 (TID 313). 5776 bytes result sent to driver
[2024-12-14T19:41:35.037+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 184.0 in stage 7.0 (TID 321) (localhost, executor driver, partition 184, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.039+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 184.0 in stage 7.0 (TID 321)
[2024-12-14T19:41:35.042+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 186.0 in stage 7.0 (TID 322) (localhost, executor driver, partition 186, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.044+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.048+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
24/12/14 19:41:34 INFO TaskSetManager: Starting task 192.0 in stage 7.0 (TID 323) (localhost, executor driver, partition 192, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:34 INFO TaskSetManager: Finished task 158.0 in stage 7.0 (TID 305) in 215 ms on localhost (executor driver) (97/200)
[2024-12-14T19:41:35.053+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 186.0 in stage 7.0 (TID 322)
24/12/14 19:41:34 INFO Executor: Finished task 179.0 in stage 7.0 (TID 319). 5776 bytes result sent to driver
[2024-12-14T19:41:35.056+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 192.0 in stage 7.0 (TID 323)
24/12/14 19:41:34 INFO TaskSetManager: Starting task 194.0 in stage 7.0 (TID 324) (localhost, executor driver, partition 194, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.058+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 171.0 in stage 7.0 (TID 314). 5776 bytes result sent to driver
[2024-12-14T19:41:35.062+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2024-12-14T19:41:35.066+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 152.0 in stage 7.0 (TID 303) in 262 ms on localhost (executor driver) (98/200)
[2024-12-14T19:41:35.070+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 154.0 in stage 7.0 (TID 304) in 249 ms on localhost (executor driver) (99/200)
24/12/14 19:41:34 INFO TaskSetManager: Finished task 162.0 in stage 7.0 (TID 308) in 206 ms on localhost (executor driver) (100/200)
[2024-12-14T19:41:35.073+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 148.0 in stage 7.0 (TID 299) in 306 ms on localhost (executor driver) (101/200)
24/12/14 19:41:34 INFO Executor: Finished task 173.0 in stage 7.0 (TID 316). 5819 bytes result sent to driver
[2024-12-14T19:41:35.075+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:34 INFO TaskSetManager: Starting task 195.0 in stage 7.0 (TID 325) (localhost, executor driver, partition 195, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:34 INFO Executor: Running task 194.0 in stage 7.0 (TID 324)
[2024-12-14T19:41:35.077+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 196.0 in stage 7.0 (TID 326) (localhost, executor driver, partition 196, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.078+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:35.079+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 159.0 in stage 7.0 (TID 306) in 244 ms on localhost (executor driver) (102/200)
24/12/14 19:41:34 INFO Executor: Running task 195.0 in stage 7.0 (TID 325)
[2024-12-14T19:41:35.080+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 196.0 in stage 7.0 (TID 326)
24/12/14 19:41:34 INFO TaskSetManager: Finished task 161.0 in stage 7.0 (TID 307) in 229 ms on localhost (executor driver) (103/200)
[2024-12-14T19:41:35.082+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 327) (localhost, executor driver, partition 1, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:34 INFO Executor: Finished task 174.0 in stage 7.0 (TID 317). 5819 bytes result sent to driver
24/12/14 19:41:34 INFO Executor: Running task 1.0 in stage 7.0 (TID 327)
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2024-12-14T19:41:35.084+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 328) (localhost, executor driver, partition 2, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.086+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.088+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 192.0 in stage 7.0 (TID 323). 5776 bytes result sent to driver
[2024-12-14T19:41:35.091+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2024-12-14T19:41:35.093+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 165.0 in stage 7.0 (TID 310) in 217 ms on localhost (executor driver) (104/200)
[2024-12-14T19:41:35.095+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 2.0 in stage 7.0 (TID 328)
[2024-12-14T19:41:35.097+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 167.0 in stage 7.0 (TID 311) in 205 ms on localhost (executor driver) (105/200)
[2024-12-14T19:41:35.100+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 10.0 in stage 7.0 (TID 329) (localhost, executor driver, partition 10, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.101+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 168.0 in stage 7.0 (TID 312). 5819 bytes result sent to driver
[2024-12-14T19:41:35.103+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 10.0 in stage 7.0 (TID 329)
[2024-12-14T19:41:35.105+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 181.0 in stage 7.0 (TID 320). 5776 bytes result sent to driver
[2024-12-14T19:41:35.108+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 11.0 in stage 7.0 (TID 330) (localhost, executor driver, partition 11, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.110+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 186.0 in stage 7.0 (TID 322). 5819 bytes result sent to driver
[2024-12-14T19:41:35.111+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 172.0 in stage 7.0 (TID 315) in 176 ms on localhost (executor driver) (106/200)
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:34 INFO Executor: Running task 11.0 in stage 7.0 (TID 330)
[2024-12-14T19:41:35.113+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
24/12/14 19:41:34 INFO TaskSetManager: Starting task 13.0 in stage 7.0 (TID 331) (localhost, executor driver, partition 13, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:34 INFO TaskSetManager: Finished task 170.0 in stage 7.0 (TID 313) in 208 ms on localhost (executor driver) (107/200)
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO TaskSetManager: Finished task 164.0 in stage 7.0 (TID 309) in 282 ms on localhost (executor driver) (108/200)
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:34 INFO TaskSetManager: Finished task 179.0 in stage 7.0 (TID 319) in 171 ms on localhost (executor driver) (109/200)
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:34 INFO Executor: Running task 13.0 in stage 7.0 (TID 331)
24/12/14 19:41:34 INFO TaskSetManager: Finished task 171.0 in stage 7.0 (TID 314) in 207 ms on localhost (executor driver) (110/200)
24/12/14 19:41:34 INFO Executor: Finished task 184.0 in stage 7.0 (TID 321). 5819 bytes result sent to driver
24/12/14 19:41:34 INFO Executor: Finished task 175.0 in stage 7.0 (TID 318). 5819 bytes result sent to driver
24/12/14 19:41:34 INFO TaskSetManager: Starting task 15.0 in stage 7.0 (TID 332) (localhost, executor driver, partition 15, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.117+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 17.0 in stage 7.0 (TID 333) (localhost, executor driver, partition 17, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.119+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 15.0 in stage 7.0 (TID 332)
[2024-12-14T19:41:35.121+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 196.0 in stage 7.0 (TID 326). 5819 bytes result sent to driver
[2024-12-14T19:41:35.123+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 17.0 in stage 7.0 (TID 333)
[2024-12-14T19:41:35.125+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 174.0 in stage 7.0 (TID 317) in 204 ms on localhost (executor driver) (111/200)
[2024-12-14T19:41:35.127+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.128+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 173.0 in stage 7.0 (TID 316) in 211 ms on localhost (executor driver) (112/200)
24/12/14 19:41:34 INFO Executor: Finished task 195.0 in stage 7.0 (TID 325). 5819 bytes result sent to driver
[2024-12-14T19:41:35.130+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2024-12-14T19:41:35.132+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 18.0 in stage 7.0 (TID 334) (localhost, executor driver, partition 18, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.135+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 192.0 in stage 7.0 (TID 323) in 133 ms on localhost (executor driver) (113/200)
[2024-12-14T19:41:35.139+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.141+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2024-12-14T19:41:35.143+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 18.0 in stage 7.0 (TID 334)
[2024-12-14T19:41:35.146+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 194.0 in stage 7.0 (TID 324). 5819 bytes result sent to driver
[2024-12-14T19:41:35.148+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 20.0 in stage 7.0 (TID 335) (localhost, executor driver, partition 20, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:34 INFO Executor: Finished task 2.0 in stage 7.0 (TID 328). 5819 bytes result sent to driver
[2024-12-14T19:41:35.157+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 20.0 in stage 7.0 (TID 335)
[2024-12-14T19:41:35.164+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 21.0 in stage 7.0 (TID 336) (localhost, executor driver, partition 21, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.174+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.181+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 168.0 in stage 7.0 (TID 312) in 253 ms on localhost (executor driver) (114/200)
[2024-12-14T19:41:35.183+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:35.187+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 181.0 in stage 7.0 (TID 320) in 189 ms on localhost (executor driver) (115/200)
[2024-12-14T19:41:35.192+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 1.0 in stage 7.0 (TID 327). 5819 bytes result sent to driver
[2024-12-14T19:41:35.194+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 21.0 in stage 7.0 (TID 336)
[2024-12-14T19:41:35.198+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 23.0 in stage 7.0 (TID 337) (localhost, executor driver, partition 23, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.205+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 24.0 in stage 7.0 (TID 338) (localhost, executor driver, partition 24, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.208+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 23.0 in stage 7.0 (TID 337)
[2024-12-14T19:41:35.213+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 10.0 in stage 7.0 (TID 329). 5819 bytes result sent to driver
[2024-12-14T19:41:35.217+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 27.0 in stage 7.0 (TID 339) (localhost, executor driver, partition 27, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.223+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 15.0 in stage 7.0 (TID 332). 5776 bytes result sent to driver
24/12/14 19:41:34 INFO Executor: Running task 24.0 in stage 7.0 (TID 338)
[2024-12-14T19:41:35.227+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 186.0 in stage 7.0 (TID 322) in 166 ms on localhost (executor driver) (116/200)
[2024-12-14T19:41:35.229+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 13.0 in stage 7.0 (TID 331). 5776 bytes result sent to driver
[2024-12-14T19:41:35.233+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 184.0 in stage 7.0 (TID 321) in 172 ms on localhost (executor driver) (117/200)
24/12/14 19:41:34 INFO Executor: Running task 27.0 in stage 7.0 (TID 339)
24/12/14 19:41:34 INFO Executor: Finished task 11.0 in stage 7.0 (TID 330). 5819 bytes result sent to driver
24/12/14 19:41:34 INFO TaskSetManager: Finished task 175.0 in stage 7.0 (TID 318) in 231 ms on localhost (executor driver) (118/200)
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:34 INFO Executor: Finished task 17.0 in stage 7.0 (TID 333). 5776 bytes result sent to driver
[2024-12-14T19:41:35.239+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 28.0 in stage 7.0 (TID 340) (localhost, executor driver, partition 28, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.241+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:34 INFO TaskSetManager: Starting task 30.0 in stage 7.0 (TID 341) (localhost, executor driver, partition 30, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.246+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 30.0 in stage 7.0 (TID 341)
24/12/14 19:41:34 INFO Executor: Running task 28.0 in stage 7.0 (TID 340)
[2024-12-14T19:41:35.249+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 33.0 in stage 7.0 (TID 342) (localhost, executor driver, partition 33, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.253+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 36.0 in stage 7.0 (TID 343) (localhost, executor driver, partition 36, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.257+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 33.0 in stage 7.0 (TID 342)
24/12/14 19:41:34 INFO TaskSetManager: Starting task 37.0 in stage 7.0 (TID 344) (localhost, executor driver, partition 37, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.263+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 36.0 in stage 7.0 (TID 343)
24/12/14 19:41:34 INFO Executor: Running task 37.0 in stage 7.0 (TID 344)
[2024-12-14T19:41:35.267+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 38.0 in stage 7.0 (TID 345) (localhost, executor driver, partition 38, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.270+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 38.0 in stage 7.0 (TID 345)
24/12/14 19:41:34 INFO Executor: Finished task 18.0 in stage 7.0 (TID 334). 5776 bytes result sent to driver
[2024-12-14T19:41:35.276+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 41.0 in stage 7.0 (TID 346) (localhost, executor driver, partition 41, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.279+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 194.0 in stage 7.0 (TID 324) in 176 ms on localhost (executor driver) (119/200)
[2024-12-14T19:41:35.281+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO TaskSetManager: Finished task 195.0 in stage 7.0 (TID 325) in 158 ms on localhost (executor driver) (120/200)
24/12/14 19:41:34 INFO Executor: Finished task 20.0 in stage 7.0 (TID 335). 5776 bytes result sent to driver
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.284+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:35.286+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2024-12-14T19:41:35.292+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 41.0 in stage 7.0 (TID 346)
24/12/14 19:41:34 INFO TaskSetManager: Starting task 44.0 in stage 7.0 (TID 347) (localhost, executor driver, partition 44, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.299+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2024-12-14T19:41:35.307+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.312+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:35.319+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 44.0 in stage 7.0 (TID 347)
24/12/14 19:41:34 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 328) in 136 ms on localhost (executor driver) (121/200)
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.322+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 196.0 in stage 7.0 (TID 326) in 189 ms on localhost (executor driver) (122/200)
[2024-12-14T19:41:35.329+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 29 ms
[2024-12-14T19:41:35.334+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 13.0 in stage 7.0 (TID 331) in 119 ms on localhost (executor driver) (123/200)
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.345+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 19 ms
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 19 ms
[2024-12-14T19:41:35.349+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 45.0 in stage 7.0 (TID 348) (localhost, executor driver, partition 45, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.354+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 45.0 in stage 7.0 (TID 348)
[2024-12-14T19:41:35.358+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 55.0 in stage 7.0 (TID 349) (localhost, executor driver, partition 55, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:34 INFO Executor: Finished task 23.0 in stage 7.0 (TID 337). 5819 bytes result sent to driver
[2024-12-14T19:41:35.363+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.370+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2024-12-14T19:41:35.381+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 55.0 in stage 7.0 (TID 349)
[2024-12-14T19:41:35.384+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:34 INFO TaskSetManager: Starting task 56.0 in stage 7.0 (TID 350) (localhost, executor driver, partition 56, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.388+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 56.0 in stage 7.0 (TID 350)
[2024-12-14T19:41:35.391+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 58.0 in stage 7.0 (TID 351) (localhost, executor driver, partition 58, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.393+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 58.0 in stage 7.0 (TID 351)
[2024-12-14T19:41:35.395+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 65.0 in stage 7.0 (TID 352) (localhost, executor driver, partition 65, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.399+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 10.0 in stage 7.0 (TID 329) in 177 ms on localhost (executor driver) (124/200)
[2024-12-14T19:41:35.406+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.411+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2024-12-14T19:41:35.422+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.427+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 21.0 in stage 7.0 (TID 336). 5819 bytes result sent to driver
[2024-12-14T19:41:35.431+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 27.0 in stage 7.0 (TID 339). 5819 bytes result sent to driver
[2024-12-14T19:41:35.438+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 17.0 in stage 7.0 (TID 333) in 135 ms on localhost (executor driver) (125/200)
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:34 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 327) in 210 ms on localhost (executor driver) (126/200)
[2024-12-14T19:41:35.443+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 30.0 in stage 7.0 (TID 341). 5819 bytes result sent to driver
[2024-12-14T19:41:35.458+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 65.0 in stage 7.0 (TID 352)
[2024-12-14T19:41:35.467+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 18.0 in stage 7.0 (TID 334) in 136 ms on localhost (executor driver) (127/200)
24/12/14 19:41:34 INFO Executor: Finished task 28.0 in stage 7.0 (TID 340). 5819 bytes result sent to driver
[2024-12-14T19:41:35.474+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 66.0 in stage 7.0 (TID 353) (localhost, executor driver, partition 66, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:34 INFO Executor: Finished task 24.0 in stage 7.0 (TID 338). 5862 bytes result sent to driver
[2024-12-14T19:41:35.481+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.490+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:35.496+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.515+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:35.521+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.526+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:35.535+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 66.0 in stage 7.0 (TID 353)
[2024-12-14T19:41:35.542+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 37.0 in stage 7.0 (TID 344). 5819 bytes result sent to driver
[2024-12-14T19:41:35.547+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO TaskSetManager: Starting task 67.0 in stage 7.0 (TID 354) (localhost, executor driver, partition 67, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.551+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2024-12-14T19:41:35.558+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 67.0 in stage 7.0 (TID 354)
[2024-12-14T19:41:35.569+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 38.0 in stage 7.0 (TID 345). 5819 bytes result sent to driver
[2024-12-14T19:41:35.571+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 87.0 in stage 7.0 (TID 355) (localhost, executor driver, partition 87, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.576+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 87.0 in stage 7.0 (TID 355)
[2024-12-14T19:41:35.580+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 33.0 in stage 7.0 (TID 342). 5819 bytes result sent to driver
[2024-12-14T19:41:35.584+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 56.0 in stage 7.0 (TID 350). 5776 bytes result sent to driver
[2024-12-14T19:41:35.588+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 58.0 in stage 7.0 (TID 351). 5776 bytes result sent to driver
[2024-12-14T19:41:35.591+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 36.0 in stage 7.0 (TID 343). 5819 bytes result sent to driver
24/12/14 19:41:34 INFO TaskSetManager: Starting task 91.0 in stage 7.0 (TID 356) (localhost, executor driver, partition 91, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.594+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 11.0 in stage 7.0 (TID 330) in 212 ms on localhost (executor driver) (128/200)
[2024-12-14T19:41:35.597+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.601+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
24/12/14 19:41:34 INFO TaskSetManager: Finished task 21.0 in stage 7.0 (TID 336) in 158 ms on localhost (executor driver) (129/200)
24/12/14 19:41:34 INFO Executor: Finished task 41.0 in stage 7.0 (TID 346). 5819 bytes result sent to driver
[2024-12-14T19:41:35.604+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 91.0 in stage 7.0 (TID 356)
24/12/14 19:41:34 INFO Executor: Finished task 44.0 in stage 7.0 (TID 347). 5776 bytes result sent to driver
[2024-12-14T19:41:35.607+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.610+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:34 INFO TaskSetManager: Starting task 93.0 in stage 7.0 (TID 357) (localhost, executor driver, partition 93, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.615+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO Executor: Running task 93.0 in stage 7.0 (TID 357)
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:35.622+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 94.0 in stage 7.0 (TID 358) (localhost, executor driver, partition 94, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:34 INFO TaskSetManager: Finished task 15.0 in stage 7.0 (TID 332) in 204 ms on localhost (executor driver) (130/200)
24/12/14 19:41:34 INFO Executor: Finished task 55.0 in stage 7.0 (TID 349). 5819 bytes result sent to driver
24/12/14 19:41:34 INFO TaskSetManager: Finished task 30.0 in stage 7.0 (TID 341) in 155 ms on localhost (executor driver) (131/200)
24/12/14 19:41:34 INFO TaskSetManager: Finished task 28.0 in stage 7.0 (TID 340) in 159 ms on localhost (executor driver) (132/200)
24/12/14 19:41:34 INFO Executor: Running task 94.0 in stage 7.0 (TID 358)
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:35.625+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 24.0 in stage 7.0 (TID 338) in 177 ms on localhost (executor driver) (133/200)
[2024-12-14T19:41:35.628+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 45.0 in stage 7.0 (TID 348). 5776 bytes result sent to driver
[2024-12-14T19:41:35.631+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 27.0 in stage 7.0 (TID 339) in 173 ms on localhost (executor driver) (134/200)
[2024-12-14T19:41:35.634+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 67.0 in stage 7.0 (TID 354). 5776 bytes result sent to driver
24/12/14 19:41:34 INFO TaskSetManager: Finished task 37.0 in stage 7.0 (TID 344) in 157 ms on localhost (executor driver) (135/200)
[2024-12-14T19:41:35.637+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 23.0 in stage 7.0 (TID 337) in 182 ms on localhost (executor driver) (136/200)
[2024-12-14T19:41:35.639+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 20.0 in stage 7.0 (TID 335) in 201 ms on localhost (executor driver) (137/200)
[2024-12-14T19:41:35.642+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.645+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:35.648+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 87.0 in stage 7.0 (TID 355). 5776 bytes result sent to driver
24/12/14 19:41:34 INFO Executor: Finished task 91.0 in stage 7.0 (TID 356). 5776 bytes result sent to driver
[2024-12-14T19:41:35.650+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 107.0 in stage 7.0 (TID 359) (localhost, executor driver, partition 107, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.653+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 110.0 in stage 7.0 (TID 360) (localhost, executor driver, partition 110, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.656+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO Executor: Finished task 65.0 in stage 7.0 (TID 352). 5776 bytes result sent to driver
24/12/14 19:41:34 INFO Executor: Running task 107.0 in stage 7.0 (TID 359)
24/12/14 19:41:34 INFO TaskSetManager: Finished task 33.0 in stage 7.0 (TID 342) in 179 ms on localhost (executor driver) (138/200)
24/12/14 19:41:34 INFO TaskSetManager: Finished task 38.0 in stage 7.0 (TID 345) in 168 ms on localhost (executor driver) (139/200)
24/12/14 19:41:34 INFO Executor: Running task 110.0 in stage 7.0 (TID 360)
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
24/12/14 19:41:34 INFO Executor: Finished task 66.0 in stage 7.0 (TID 353). 5776 bytes result sent to driver
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.658+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:35.661+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 112.0 in stage 7.0 (TID 361) (localhost, executor driver, partition 112, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.664+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 114.0 in stage 7.0 (TID 362) (localhost, executor driver, partition 114, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.666+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 112.0 in stage 7.0 (TID 361)
24/12/14 19:41:34 INFO TaskSetManager: Finished task 56.0 in stage 7.0 (TID 350) in 112 ms on localhost (executor driver) (140/200)
[2024-12-14T19:41:35.669+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 58.0 in stage 7.0 (TID 351) in 106 ms on localhost (executor driver) (141/200)
[2024-12-14T19:41:35.671+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 114.0 in stage 7.0 (TID 362)
[2024-12-14T19:41:35.674+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 115.0 in stage 7.0 (TID 363) (localhost, executor driver, partition 115, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:34 INFO Executor: Running task 115.0 in stage 7.0 (TID 363)
[2024-12-14T19:41:35.677+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.679+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:35.682+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 116.0 in stage 7.0 (TID 364) (localhost, executor driver, partition 116, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.685+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 36.0 in stage 7.0 (TID 343) in 207 ms on localhost (executor driver) (142/200)
[2024-12-14T19:41:35.688+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO Executor: Finished task 93.0 in stage 7.0 (TID 357). 5776 bytes result sent to driver
24/12/14 19:41:34 INFO Executor: Running task 116.0 in stage 7.0 (TID 364)
[2024-12-14T19:41:35.690+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2024-12-14T19:41:35.693+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Starting task 117.0 in stage 7.0 (TID 365) (localhost, executor driver, partition 117, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.696+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 117.0 in stage 7.0 (TID 365)
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO TaskSetManager: Starting task 118.0 in stage 7.0 (TID 366) (localhost, executor driver, partition 118, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:34 INFO TaskSetManager: Starting task 119.0 in stage 7.0 (TID 367) (localhost, executor driver, partition 119, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.699+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 119.0 in stage 7.0 (TID 367)
[2024-12-14T19:41:35.702+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO Executor: Running task 118.0 in stage 7.0 (TID 366)
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
24/12/14 19:41:34 INFO TaskSetManager: Starting task 121.0 in stage 7.0 (TID 368) (localhost, executor driver, partition 121, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2024-12-14T19:41:35.703+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 41.0 in stage 7.0 (TID 346) in 221 ms on localhost (executor driver) (143/200)
[2024-12-14T19:41:35.706+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 107.0 in stage 7.0 (TID 359). 5776 bytes result sent to driver
[2024-12-14T19:41:35.709+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 121.0 in stage 7.0 (TID 368)
[2024-12-14T19:41:35.711+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO TaskSetManager: Finished task 67.0 in stage 7.0 (TID 354) in 136 ms on localhost (executor driver) (144/200)
24/12/14 19:41:34 INFO Executor: Finished task 94.0 in stage 7.0 (TID 358). 5776 bytes result sent to driver
24/12/14 19:41:34 INFO TaskSetManager: Starting task 122.0 in stage 7.0 (TID 369) (localhost, executor driver, partition 122, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.714+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Finished task 112.0 in stage 7.0 (TID 361). 5776 bytes result sent to driver
[2024-12-14T19:41:35.716+0000] {docker.py:413} INFO - 24/12/14 19:41:34 INFO Executor: Running task 122.0 in stage 7.0 (TID 369)
[2024-12-14T19:41:35.719+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Starting task 126.0 in stage 7.0 (TID 370) (localhost, executor driver, partition 126, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.721+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Running task 126.0 in stage 7.0 (TID 370)
[2024-12-14T19:41:35.724+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Finished task 115.0 in stage 7.0 (TID 363). 5776 bytes result sent to driver
24/12/14 19:41:35 INFO TaskSetManager: Starting task 128.0 in stage 7.0 (TID 371) (localhost, executor driver, partition 128, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:35 INFO TaskSetManager: Finished task 55.0 in stage 7.0 (TID 349) in 190 ms on localhost (executor driver) (145/200)
24/12/14 19:41:35 INFO Executor: Running task 128.0 in stage 7.0 (TID 371)
24/12/14 19:41:35 INFO TaskSetManager: Starting task 131.0 in stage 7.0 (TID 372) (localhost, executor driver, partition 131, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.725+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Finished task 110.0 in stage 7.0 (TID 360). 5776 bytes result sent to driver
[2024-12-14T19:41:35.735+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.738+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Starting task 133.0 in stage 7.0 (TID 373) (localhost, executor driver, partition 133, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.741+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
24/12/14 19:41:35 INFO TaskSetManager: Finished task 45.0 in stage 7.0 (TID 348) in 200 ms on localhost (executor driver) (146/200)
24/12/14 19:41:35 INFO Executor: Running task 133.0 in stage 7.0 (TID 373)
24/12/14 19:41:35 INFO Executor: Finished task 114.0 in stage 7.0 (TID 362). 5776 bytes result sent to driver
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:35 INFO TaskSetManager: Finished task 65.0 in stage 7.0 (TID 352) in 183 ms on localhost (executor driver) (147/200)
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
24/12/14 19:41:35 INFO Executor: Running task 131.0 in stage 7.0 (TID 372)
[2024-12-14T19:41:35.743+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:35.745+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 66.0 in stage 7.0 (TID 353) in 167 ms on localhost (executor driver) (148/200)
[2024-12-14T19:41:35.747+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 93.0 in stage 7.0 (TID 357) in 129 ms on localhost (executor driver) (149/200)
[2024-12-14T19:41:35.750+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 44.0 in stage 7.0 (TID 347) in 255 ms on localhost (executor driver) (150/200)
[2024-12-14T19:41:35.753+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.755+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2024-12-14T19:41:35.758+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 91.0 in stage 7.0 (TID 356) in 153 ms on localhost (executor driver) (151/200)
[2024-12-14T19:41:35.760+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.762+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2024-12-14T19:41:35.765+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Starting task 134.0 in stage 7.0 (TID 374) (localhost, executor driver, partition 134, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.767+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 87.0 in stage 7.0 (TID 355) in 170 ms on localhost (executor driver) (152/200)
[2024-12-14T19:41:35.768+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.770+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
[2024-12-14T19:41:35.774+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 107.0 in stage 7.0 (TID 359) in 119 ms on localhost (executor driver) (153/200)
[2024-12-14T19:41:35.776+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Finished task 118.0 in stage 7.0 (TID 366). 5776 bytes result sent to driver
[2024-12-14T19:41:35.779+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Running task 134.0 in stage 7.0 (TID 374)
[2024-12-14T19:41:35.781+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Starting task 138.0 in stage 7.0 (TID 375) (localhost, executor driver, partition 138, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.784+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Running task 138.0 in stage 7.0 (TID 375)
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.787+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
[2024-12-14T19:41:35.789+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Starting task 139.0 in stage 7.0 (TID 376) (localhost, executor driver, partition 139, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.790+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.793+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.795+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Starting task 140.0 in stage 7.0 (TID 377) (localhost, executor driver, partition 140, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.797+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Finished task 116.0 in stage 7.0 (TID 364). 5819 bytes result sent to driver
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:35.800+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
[2024-12-14T19:41:35.803+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Running task 139.0 in stage 7.0 (TID 376)
24/12/14 19:41:35 INFO Executor: Finished task 119.0 in stage 7.0 (TID 367). 5819 bytes result sent to driver
24/12/14 19:41:35 INFO Executor: Running task 140.0 in stage 7.0 (TID 377)
24/12/14 19:41:35 INFO Executor: Finished task 126.0 in stage 7.0 (TID 370). 5776 bytes result sent to driver
[2024-12-14T19:41:35.805+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Starting task 141.0 in stage 7.0 (TID 378) (localhost, executor driver, partition 141, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.808+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Starting task 143.0 in stage 7.0 (TID 379) (localhost, executor driver, partition 143, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.810+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Running task 143.0 in stage 7.0 (TID 379)
24/12/14 19:41:35 INFO Executor: Running task 141.0 in stage 7.0 (TID 378)
[2024-12-14T19:41:35.811+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Finished task 128.0 in stage 7.0 (TID 371). 5776 bytes result sent to driver
[2024-12-14T19:41:35.813+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Finished task 133.0 in stage 7.0 (TID 373). 5776 bytes result sent to driver
24/12/14 19:41:35 INFO TaskSetManager: Starting task 144.0 in stage 7.0 (TID 380) (localhost, executor driver, partition 144, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.815+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Finished task 121.0 in stage 7.0 (TID 368). 5776 bytes result sent to driver
24/12/14 19:41:35 INFO Executor: Running task 144.0 in stage 7.0 (TID 380)
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:35 INFO TaskSetManager: Starting task 147.0 in stage 7.0 (TID 381) (localhost, executor driver, partition 147, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:35.817+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Running task 147.0 in stage 7.0 (TID 381)
24/12/14 19:41:35 INFO TaskSetManager: Starting task 153.0 in stage 7.0 (TID 382) (localhost, executor driver, partition 153, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.819+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:35.822+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Running task 153.0 in stage 7.0 (TID 382)
[2024-12-14T19:41:35.823+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:35 INFO Executor: Finished task 117.0 in stage 7.0 (TID 365). 5776 bytes result sent to driver
[2024-12-14T19:41:35.825+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Finished task 122.0 in stage 7.0 (TID 369). 5776 bytes result sent to driver
[2024-12-14T19:41:35.827+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Finished task 131.0 in stage 7.0 (TID 372). 5776 bytes result sent to driver
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:35.831+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:35.833+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Finished task 138.0 in stage 7.0 (TID 375). 5776 bytes result sent to driver
[2024-12-14T19:41:35.835+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:35.837+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Starting task 155.0 in stage 7.0 (TID 383) (localhost, executor driver, partition 155, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:35 INFO Executor: Finished task 139.0 in stage 7.0 (TID 376). 5776 bytes result sent to driver
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:35 INFO TaskSetManager: Finished task 115.0 in stage 7.0 (TID 363) in 164 ms on localhost (executor driver) (154/200)
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:35 INFO Executor: Running task 155.0 in stage 7.0 (TID 383)
24/12/14 19:41:35 INFO TaskSetManager: Finished task 112.0 in stage 7.0 (TID 361) in 172 ms on localhost (executor driver) (155/200)
[2024-12-14T19:41:35.839+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 94.0 in stage 7.0 (TID 358) in 208 ms on localhost (executor driver) (156/200)
24/12/14 19:41:35 INFO TaskSetManager: Finished task 116.0 in stage 7.0 (TID 364) in 147 ms on localhost (executor driver) (157/200)
[2024-12-14T19:41:35.842+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Finished task 143.0 in stage 7.0 (TID 379). 5776 bytes result sent to driver
24/12/14 19:41:35 INFO TaskSetManager: Finished task 118.0 in stage 7.0 (TID 366) in 133 ms on localhost (executor driver) (158/200)
[2024-12-14T19:41:35.844+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 119.0 in stage 7.0 (TID 367) in 132 ms on localhost (executor driver) (159/200)
[2024-12-14T19:41:35.847+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Finished task 141.0 in stage 7.0 (TID 378). 5776 bytes result sent to driver
[2024-12-14T19:41:35.849+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 126.0 in stage 7.0 (TID 370) in 113 ms on localhost (executor driver) (160/200)
[2024-12-14T19:41:35.851+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Finished task 134.0 in stage 7.0 (TID 374). 5776 bytes result sent to driver
[2024-12-14T19:41:35.855+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 110.0 in stage 7.0 (TID 360) in 185 ms on localhost (executor driver) (161/200)
[2024-12-14T19:41:35.857+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 114.0 in stage 7.0 (TID 362) in 177 ms on localhost (executor driver) (162/200)
[2024-12-14T19:41:35.859+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Starting task 156.0 in stage 7.0 (TID 384) (localhost, executor driver, partition 156, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.861+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Running task 156.0 in stage 7.0 (TID 384)
24/12/14 19:41:35 INFO Executor: Finished task 144.0 in stage 7.0 (TID 380). 5776 bytes result sent to driver
[2024-12-14T19:41:35.863+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Starting task 157.0 in stage 7.0 (TID 385) (localhost, executor driver, partition 157, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:35 INFO TaskSetManager: Finished task 128.0 in stage 7.0 (TID 371) in 117 ms on localhost (executor driver) (163/200)
24/12/14 19:41:35 INFO Executor: Running task 157.0 in stage 7.0 (TID 385)
24/12/14 19:41:35 INFO TaskSetManager: Finished task 133.0 in stage 7.0 (TID 373) in 106 ms on localhost (executor driver) (164/200)
[2024-12-14T19:41:35.865+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Starting task 160.0 in stage 7.0 (TID 386) (localhost, executor driver, partition 160, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.867+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Running task 160.0 in stage 7.0 (TID 386)
24/12/14 19:41:35 INFO TaskSetManager: Starting task 163.0 in stage 7.0 (TID 387) (localhost, executor driver, partition 163, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.869+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Starting task 166.0 in stage 7.0 (TID 388) (localhost, executor driver, partition 166, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.871+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 117.0 in stage 7.0 (TID 365) in 164 ms on localhost (executor driver) (165/200)
[2024-12-14T19:41:35.874+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 121.0 in stage 7.0 (TID 368) in 146 ms on localhost (executor driver) (166/200)
[2024-12-14T19:41:35.876+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Finished task 147.0 in stage 7.0 (TID 381). 5776 bytes result sent to driver
24/12/14 19:41:35 INFO TaskSetManager: Finished task 122.0 in stage 7.0 (TID 369) in 141 ms on localhost (executor driver) (167/200)
[2024-12-14T19:41:35.878+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Running task 163.0 in stage 7.0 (TID 387)
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.879+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
[2024-12-14T19:41:35.881+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Finished task 140.0 in stage 7.0 (TID 377). 5819 bytes result sent to driver
24/12/14 19:41:35 INFO TaskSetManager: Starting task 169.0 in stage 7.0 (TID 389) (localhost, executor driver, partition 169, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.883+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Running task 166.0 in stage 7.0 (TID 388)
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:35 INFO TaskSetManager: Starting task 176.0 in stage 7.0 (TID 390) (localhost, executor driver, partition 176, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:35 INFO Executor: Running task 169.0 in stage 7.0 (TID 389)
[2024-12-14T19:41:35.886+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 138.0 in stage 7.0 (TID 375) in 102 ms on localhost (executor driver) (168/200)
[2024-12-14T19:41:35.887+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 131.0 in stage 7.0 (TID 372) in 133 ms on localhost (executor driver) (169/200)
[2024-12-14T19:41:35.889+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Starting task 177.0 in stage 7.0 (TID 391) (localhost, executor driver, partition 177, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.891+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Running task 176.0 in stage 7.0 (TID 390)
[2024-12-14T19:41:35.893+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.895+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:35.897+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Running task 177.0 in stage 7.0 (TID 391)
[2024-12-14T19:41:35.898+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:35 INFO TaskSetManager: Starting task 178.0 in stage 7.0 (TID 392) (localhost, executor driver, partition 178, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.899+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 139.0 in stage 7.0 (TID 376) in 105 ms on localhost (executor driver) (170/200)
24/12/14 19:41:35 INFO Executor: Finished task 153.0 in stage 7.0 (TID 382). 5776 bytes result sent to driver
[2024-12-14T19:41:35.901+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Running task 178.0 in stage 7.0 (TID 392)
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.904+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:35.907+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:35.910+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Starting task 180.0 in stage 7.0 (TID 393) (localhost, executor driver, partition 180, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.912+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 143.0 in stage 7.0 (TID 379) in 99 ms on localhost (executor driver) (171/200)
[2024-12-14T19:41:35.914+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:35 INFO Executor: Running task 180.0 in stage 7.0 (TID 393)
[2024-12-14T19:41:35.917+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:35 INFO TaskSetManager: Starting task 182.0 in stage 7.0 (TID 394) (localhost, executor driver, partition 182, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.919+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Starting task 183.0 in stage 7.0 (TID 395) (localhost, executor driver, partition 183, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.922+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Running task 182.0 in stage 7.0 (TID 394)
24/12/14 19:41:35 INFO Executor: Finished task 157.0 in stage 7.0 (TID 385). 5776 bytes result sent to driver
[2024-12-14T19:41:35.924+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Finished task 155.0 in stage 7.0 (TID 383). 5819 bytes result sent to driver
[2024-12-14T19:41:35.926+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Running task 183.0 in stage 7.0 (TID 395)
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:35 INFO TaskSetManager: Starting task 185.0 in stage 7.0 (TID 396) (localhost, executor driver, partition 185, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.928+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Finished task 166.0 in stage 7.0 (TID 388). 5776 bytes result sent to driver
[2024-12-14T19:41:35.931+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Running task 185.0 in stage 7.0 (TID 396)
[2024-12-14T19:41:35.933+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Starting task 187.0 in stage 7.0 (TID 397) (localhost, executor driver, partition 187, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.935+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Running task 187.0 in stage 7.0 (TID 397)
24/12/14 19:41:35 INFO TaskSetManager: Starting task 188.0 in stage 7.0 (TID 398) (localhost, executor driver, partition 188, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.936+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.938+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:35.941+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Running task 188.0 in stage 7.0 (TID 398)
[2024-12-14T19:41:35.944+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Finished task 156.0 in stage 7.0 (TID 384). 5819 bytes result sent to driver
24/12/14 19:41:35 INFO Executor: Finished task 163.0 in stage 7.0 (TID 387). 5819 bytes result sent to driver
[2024-12-14T19:41:35.946+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Starting task 189.0 in stage 7.0 (TID 399) (localhost, executor driver, partition 189, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.948+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 134.0 in stage 7.0 (TID 374) in 156 ms on localhost (executor driver) (172/200)
[2024-12-14T19:41:35.950+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Running task 189.0 in stage 7.0 (TID 399)
[2024-12-14T19:41:35.953+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.955+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
[2024-12-14T19:41:35.957+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Starting task 190.0 in stage 7.0 (TID 400) (localhost, executor driver, partition 190, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.958+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
[2024-12-14T19:41:35.960+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Running task 190.0 in stage 7.0 (TID 400)
24/12/14 19:41:35 INFO Executor: Finished task 160.0 in stage 7.0 (TID 386). 5776 bytes result sent to driver
[2024-12-14T19:41:35.962+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.965+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:35 INFO TaskSetManager: Starting task 191.0 in stage 7.0 (TID 401) (localhost, executor driver, partition 191, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.966+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
24/12/14 19:41:35 INFO TaskSetManager: Finished task 144.0 in stage 7.0 (TID 380) in 135 ms on localhost (executor driver) (173/200)
24/12/14 19:41:35 INFO Executor: Finished task 169.0 in stage 7.0 (TID 389). 5776 bytes result sent to driver
24/12/14 19:41:35 INFO TaskSetManager: Finished task 147.0 in stage 7.0 (TID 381) in 133 ms on localhost (executor driver) (174/200)
[2024-12-14T19:41:35.968+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 141.0 in stage 7.0 (TID 378) in 155 ms on localhost (executor driver) (175/200)
[2024-12-14T19:41:35.969+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Finished task 180.0 in stage 7.0 (TID 393). 5776 bytes result sent to driver
[2024-12-14T19:41:35.971+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Starting task 193.0 in stage 7.0 (TID 402) (localhost, executor driver, partition 193, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:35 INFO Executor: Running task 191.0 in stage 7.0 (TID 401)
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:35.973+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Starting task 197.0 in stage 7.0 (TID 403) (localhost, executor driver, partition 197, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:35.975+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Running task 197.0 in stage 7.0 (TID 403)
[2024-12-14T19:41:35.976+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
24/12/14 19:41:35 INFO Executor: Running task 193.0 in stage 7.0 (TID 402)
[2024-12-14T19:41:35.978+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Starting task 198.0 in stage 7.0 (TID 404) (localhost, executor driver, partition 198, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:35 INFO Executor: Finished task 182.0 in stage 7.0 (TID 394). 5776 bytes result sent to driver
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:35.979+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Running task 198.0 in stage 7.0 (TID 404)
[2024-12-14T19:41:35.981+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:35 INFO TaskSetManager: Starting task 199.0 in stage 7.0 (TID 405) (localhost, executor driver, partition 199, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:35 INFO Executor: Finished task 187.0 in stage 7.0 (TID 397). 5776 bytes result sent to driver
[2024-12-14T19:41:35.983+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Running task 199.0 in stage 7.0 (TID 405)
[2024-12-14T19:41:35.985+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 140.0 in stage 7.0 (TID 377) in 178 ms on localhost (executor driver) (176/200)
24/12/14 19:41:35 INFO TaskSetManager: Finished task 166.0 in stage 7.0 (TID 388) in 102 ms on localhost (executor driver) (177/200)
[2024-12-14T19:41:35.987+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:35.988+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:35.990+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 155.0 in stage 7.0 (TID 383) in 149 ms on localhost (executor driver) (178/200)
[2024-12-14T19:41:35.992+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 163.0 in stage 7.0 (TID 387) in 110 ms on localhost (executor driver) (179/200)
[2024-12-14T19:41:35.994+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 160.0 in stage 7.0 (TID 386) in 117 ms on localhost (executor driver) (180/200)
[2024-12-14T19:41:35.996+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 153.0 in stage 7.0 (TID 382) in 163 ms on localhost (executor driver) (181/200)
[2024-12-14T19:41:35.998+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 180.0 in stage 7.0 (TID 393) in 82 ms on localhost (executor driver) (182/200)
[2024-12-14T19:41:36.000+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 156.0 in stage 7.0 (TID 384) in 130 ms on localhost (executor driver) (183/200)
24/12/14 19:41:35 INFO TaskSetManager: Finished task 157.0 in stage 7.0 (TID 385) in 126 ms on localhost (executor driver) (184/200)
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:35 INFO TaskSetManager: Finished task 169.0 in stage 7.0 (TID 389) in 108 ms on localhost (executor driver) (185/200)
[2024-12-14T19:41:36.002+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 182.0 in stage 7.0 (TID 394) in 80 ms on localhost (executor driver) (186/200)
[2024-12-14T19:41:36.003+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:35 INFO TaskSetManager: Finished task 187.0 in stage 7.0 (TID 397) in 71 ms on localhost (executor driver) (187/200)
[2024-12-14T19:41:36.005+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Finished task 185.0 in stage 7.0 (TID 396). 5776 bytes result sent to driver
[2024-12-14T19:41:36.007+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:36.012+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:36.014+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 185.0 in stage 7.0 (TID 396) in 82 ms on localhost (executor driver) (188/200)
[2024-12-14T19:41:36.015+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:36.019+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:36.022+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:36.023+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 16 ms
[2024-12-14T19:41:36.024+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Finished task 177.0 in stage 7.0 (TID 391). 5819 bytes result sent to driver
[2024-12-14T19:41:36.026+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 42 ms
[2024-12-14T19:41:36.027+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Finished task 191.0 in stage 7.0 (TID 401). 5862 bytes result sent to driver
[2024-12-14T19:41:36.029+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Finished task 178.0 in stage 7.0 (TID 392). 5819 bytes result sent to driver
[2024-12-14T19:41:36.031+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 177.0 in stage 7.0 (TID 391) in 148 ms on localhost (executor driver) (189/200)
24/12/14 19:41:35 INFO Executor: Finished task 189.0 in stage 7.0 (TID 399). 5862 bytes result sent to driver
[2024-12-14T19:41:36.032+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 191.0 in stage 7.0 (TID 401) in 92 ms on localhost (executor driver) (190/200)
24/12/14 19:41:35 INFO Executor: Finished task 176.0 in stage 7.0 (TID 390). 5819 bytes result sent to driver
24/12/14 19:41:35 INFO TaskSetManager: Finished task 178.0 in stage 7.0 (TID 392) in 154 ms on localhost (executor driver) (191/200)
[2024-12-14T19:41:36.035+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Finished task 199.0 in stage 7.0 (TID 405). 5819 bytes result sent to driver
[2024-12-14T19:41:36.037+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 176.0 in stage 7.0 (TID 390) in 165 ms on localhost (executor driver) (192/200)
[2024-12-14T19:41:36.040+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 199.0 in stage 7.0 (TID 405) in 87 ms on localhost (executor driver) (193/200)
[2024-12-14T19:41:36.043+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 189.0 in stage 7.0 (TID 399) in 119 ms on localhost (executor driver) (194/200)
[2024-12-14T19:41:36.045+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Finished task 188.0 in stage 7.0 (TID 398). 5819 bytes result sent to driver
[2024-12-14T19:41:36.047+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 188.0 in stage 7.0 (TID 398) in 137 ms on localhost (executor driver) (195/200)
[2024-12-14T19:41:36.049+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Finished task 183.0 in stage 7.0 (TID 395). 5819 bytes result sent to driver
[2024-12-14T19:41:36.051+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Finished task 197.0 in stage 7.0 (TID 403). 5819 bytes result sent to driver
[2024-12-14T19:41:36.053+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Finished task 193.0 in stage 7.0 (TID 402). 5862 bytes result sent to driver
[2024-12-14T19:41:36.055+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Finished task 190.0 in stage 7.0 (TID 400). 5862 bytes result sent to driver
[2024-12-14T19:41:36.057+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 197.0 in stage 7.0 (TID 403) in 122 ms on localhost (executor driver) (196/200)
[2024-12-14T19:41:36.059+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 193.0 in stage 7.0 (TID 402) in 125 ms on localhost (executor driver) (197/200)
24/12/14 19:41:35 INFO TaskSetManager: Finished task 183.0 in stage 7.0 (TID 395) in 169 ms on localhost (executor driver) (198/200)
24/12/14 19:41:35 INFO TaskSetManager: Finished task 190.0 in stage 7.0 (TID 400) in 141 ms on localhost (executor driver) (199/200)
[2024-12-14T19:41:36.061+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Finished task 198.0 in stage 7.0 (TID 404). 5819 bytes result sent to driver
[2024-12-14T19:41:36.067+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 198.0 in stage 7.0 (TID 404) in 128 ms on localhost (executor driver) (200/200)
[2024-12-14T19:41:36.069+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool
[2024-12-14T19:41:36.072+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO DAGScheduler: ShuffleMapStage 7 (start at NativeMethodAccessorImpl.java:0) finished in 2.160 s
24/12/14 19:41:35 INFO DAGScheduler: looking for newly runnable stages
24/12/14 19:41:35 INFO DAGScheduler: running: Set()
24/12/14 19:41:35 INFO DAGScheduler: waiting: Set(ResultStage 8)
24/12/14 19:41:35 INFO DAGScheduler: failed: Set()
[2024-12-14T19:41:36.075+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[27] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-12-14T19:41:36.076+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 12.5 KiB, free 434.3 MiB)
[2024-12-14T19:41:36.078+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.3 MiB)
[2024-12-14T19:41:36.080+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:32963 (size: 5.9 KiB, free: 434.4 MiB)
[2024-12-14T19:41:36.082+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1580
[2024-12-14T19:41:36.085+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[27] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/12/14 19:41:35 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
[2024-12-14T19:41:36.089+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 406) (localhost, executor driver, partition 0, NODE_LOCAL, 9963 bytes)
[2024-12-14T19:41:36.091+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Running task 0.0 in stage 8.0 (TID 406)
[2024-12-14T19:41:36.093+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Getting 200 (11.7 KiB) non-empty blocks including 200 (11.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:36.096+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
[2024-12-14T19:41:36.099+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Finished task 0.0 in stage 8.0 (TID 406). 4038 bytes result sent to driver
[2024-12-14T19:41:36.101+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 406) in 155 ms on localhost (executor driver) (1/1)
24/12/14 19:41:35 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool
[2024-12-14T19:41:36.103+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO DAGScheduler: ResultStage 8 (start at NativeMethodAccessorImpl.java:0) finished in 0.210 s
[2024-12-14T19:41:36.106+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
24/12/14 19:41:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
[2024-12-14T19:41:36.108+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO DAGScheduler: Job 3 finished: start at NativeMethodAccessorImpl.java:0, took 3.258750 s
[2024-12-14T19:41:36.109+0000] {docker.py:413} INFO - 2024-12-14 19:41:35,588 [INFO] Successfully transformed 180 posts
[2024-12-14T19:41:36.111+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
[2024-12-14T19:41:36.113+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO DAGScheduler: Registering RDD 29 (start at NativeMethodAccessorImpl.java:0) as input to shuffle 5
[2024-12-14T19:41:36.115+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO DAGScheduler: Registering RDD 32 (start at NativeMethodAccessorImpl.java:0) as input to shuffle 6
[2024-12-14T19:41:36.117+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO DAGScheduler: Got job 4 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/12/14 19:41:35 INFO DAGScheduler: Final stage: ResultStage 11 (start at NativeMethodAccessorImpl.java:0)
24/12/14 19:41:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
[2024-12-14T19:41:36.118+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
[2024-12-14T19:41:36.120+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[29] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-12-14T19:41:36.121+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 51.8 KiB, free 434.2 MiB)
[2024-12-14T19:41:36.123+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 434.2 MiB)
[2024-12-14T19:41:36.125+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:32963 (size: 20.7 KiB, free: 434.3 MiB)
[2024-12-14T19:41:36.126+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1580
[2024-12-14T19:41:36.127+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[29] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2024-12-14T19:41:36.129+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
[2024-12-14T19:41:36.132+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 407) (localhost, executor driver, partition 0, PROCESS_LOCAL, 10838 bytes)
[2024-12-14T19:41:36.134+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO Executor: Running task 0.0 in stage 9.0 (TID 407)
[2024-12-14T19:41:36.136+0000] {docker.py:413} INFO - 24/12/14 19:41:35 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=reddit_data-0 fromOffset=0 untilOffset=650, for query queryId=380f0ba5-0895-4b92-9659-cdf82c87bac4 batchId=0 taskId=407 partitionId=0
[2024-12-14T19:41:36.138+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO KafkaConsumer: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to offset 0 for partition reddit_data-0
[2024-12-14T19:41:36.140+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to earliest offset of partition reddit_data-0
[2024-12-14T19:41:36.142+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Resetting offset for partition reddit_data-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 0 rack: null)], epoch=32}}.
[2024-12-14T19:41:36.143+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to latest offset of partition reddit_data-0
[2024-12-14T19:41:36.144+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Resetting offset for partition reddit_data-0 to position FetchPosition{offset=650, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 0 rack: null)], epoch=32}}.
[2024-12-14T19:41:36.145+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO BlockManagerInfo: Removed broadcast_8_piece0 on localhost:32963 in memory (size: 5.9 KiB, free: 434.4 MiB)
[2024-12-14T19:41:36.146+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO KafkaConsumer: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to offset 500 for partition reddit_data-0
[2024-12-14T19:41:36.147+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to earliest offset of partition reddit_data-0
[2024-12-14T19:41:36.646+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Resetting offset for partition reddit_data-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 0 rack: null)], epoch=32}}.
[2024-12-14T19:41:36.648+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to latest offset of partition reddit_data-0
[2024-12-14T19:41:36.651+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Resetting offset for partition reddit_data-0 to position FetchPosition{offset=650, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 0 rack: null)], epoch=32}}.
[2024-12-14T19:41:36.688+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO KafkaDataConsumer: From Kafka topicPartition=reddit_data-0 groupId=reddit_processor_group read 650 records through 2 polls (polled  out 650 records), taking 563298194 nanos, during time span of 683552537 nanos.
[2024-12-14T19:41:36.691+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Finished task 0.0 in stage 9.0 (TID 407). 2903 bytes result sent to driver
[2024-12-14T19:41:36.692+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 407) in 761 ms on localhost (executor driver) (1/1)
[2024-12-14T19:41:36.694+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool
[2024-12-14T19:41:36.697+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO DAGScheduler: ShuffleMapStage 9 (start at NativeMethodAccessorImpl.java:0) finished in 0.786 s
[2024-12-14T19:41:36.698+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO DAGScheduler: looking for newly runnable stages
24/12/14 19:41:36 INFO DAGScheduler: running: Set()
[2024-12-14T19:41:36.699+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO DAGScheduler: waiting: Set(ShuffleMapStage 10, ResultStage 11)
[2024-12-14T19:41:36.700+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO DAGScheduler: failed: Set()
[2024-12-14T19:41:36.701+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[32] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-12-14T19:41:36.716+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 63.8 KiB, free 434.2 MiB)
[2024-12-14T19:41:36.722+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 25.8 KiB, free 434.2 MiB)
[2024-12-14T19:41:36.723+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:32963 (size: 25.8 KiB, free: 434.3 MiB)
[2024-12-14T19:41:36.724+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1580
[2024-12-14T19:41:36.725+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO DAGScheduler: Submitting 200 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[32] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
24/12/14 19:41:36 INFO TaskSchedulerImpl: Adding task set 10.0 with 200 tasks resource profile 0
[2024-12-14T19:41:36.733+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 408) (localhost, executor driver, partition 0, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:36.734+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 409) (localhost, executor driver, partition 3, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:36.735+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 410) (localhost, executor driver, partition 4, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:36.736+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 411) (localhost, executor driver, partition 5, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:36.737+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 412) (localhost, executor driver, partition 6, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:36.740+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 413) (localhost, executor driver, partition 7, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:36.741+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 414) (localhost, executor driver, partition 8, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:36.743+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 415) (localhost, executor driver, partition 9, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:36.745+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Starting task 12.0 in stage 10.0 (TID 416) (localhost, executor driver, partition 12, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:36.746+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Starting task 14.0 in stage 10.0 (TID 417) (localhost, executor driver, partition 14, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:36.748+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Starting task 16.0 in stage 10.0 (TID 418) (localhost, executor driver, partition 16, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:36 INFO TaskSetManager: Starting task 19.0 in stage 10.0 (TID 419) (localhost, executor driver, partition 19, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:36.750+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Starting task 22.0 in stage 10.0 (TID 420) (localhost, executor driver, partition 22, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:36.751+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Starting task 25.0 in stage 10.0 (TID 421) (localhost, executor driver, partition 25, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:36.753+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Starting task 26.0 in stage 10.0 (TID 422) (localhost, executor driver, partition 26, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:36.755+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Starting task 29.0 in stage 10.0 (TID 423) (localhost, executor driver, partition 29, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:36.756+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Running task 0.0 in stage 10.0 (TID 408)
24/12/14 19:41:36 INFO Executor: Running task 4.0 in stage 10.0 (TID 410)
24/12/14 19:41:36 INFO Executor: Running task 5.0 in stage 10.0 (TID 411)
24/12/14 19:41:36 INFO Executor: Running task 6.0 in stage 10.0 (TID 412)
24/12/14 19:41:36 INFO Executor: Running task 3.0 in stage 10.0 (TID 409)
24/12/14 19:41:36 INFO Executor: Running task 16.0 in stage 10.0 (TID 418)
24/12/14 19:41:36 INFO Executor: Running task 22.0 in stage 10.0 (TID 420)
24/12/14 19:41:36 INFO Executor: Running task 29.0 in stage 10.0 (TID 423)
24/12/14 19:41:36 INFO Executor: Running task 8.0 in stage 10.0 (TID 414)
24/12/14 19:41:36 INFO Executor: Running task 9.0 in stage 10.0 (TID 415)
[2024-12-14T19:41:36.758+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Running task 19.0 in stage 10.0 (TID 419)
[2024-12-14T19:41:36.759+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Running task 26.0 in stage 10.0 (TID 422)
[2024-12-14T19:41:36.761+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Running task 7.0 in stage 10.0 (TID 413)
[2024-12-14T19:41:36.764+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Running task 12.0 in stage 10.0 (TID 416)
[2024-12-14T19:41:36.766+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Running task 25.0 in stage 10.0 (TID 421)
[2024-12-14T19:41:36.771+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Running task 14.0 in stage 10.0 (TID 417)
[2024-12-14T19:41:36.773+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:36.776+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:36.777+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:36.778+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:36.780+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2024-12-14T19:41:36.781+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:36.788+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:36.789+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
[2024-12-14T19:41:36.792+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:36.793+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:36.804+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
24/12/14 19:41:36 INFO Executor: Finished task 5.0 in stage 10.0 (TID 411). 5819 bytes result sent to driver
24/12/14 19:41:36 INFO Executor: Finished task 22.0 in stage 10.0 (TID 420). 5819 bytes result sent to driver
24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 34 ms
24/12/14 19:41:36 INFO TaskSetManager: Starting task 31.0 in stage 10.0 (TID 424) (localhost, executor driver, partition 31, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:36.811+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Starting task 32.0 in stage 10.0 (TID 425) (localhost, executor driver, partition 32, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:36.817+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 411) in 72 ms on localhost (executor driver) (1/200)
[2024-12-14T19:41:36.820+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Finished task 8.0 in stage 10.0 (TID 414). 5819 bytes result sent to driver
[2024-12-14T19:41:36.823+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Running task 31.0 in stage 10.0 (TID 424)
[2024-12-14T19:41:36.827+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Running task 32.0 in stage 10.0 (TID 425)
[2024-12-14T19:41:36.829+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Finished task 19.0 in stage 10.0 (TID 419). 5819 bytes result sent to driver
24/12/14 19:41:36 INFO BlockManagerInfo: Removed broadcast_9_piece0 on localhost:32963 in memory (size: 20.7 KiB, free: 434.3 MiB)
[2024-12-14T19:41:36.831+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:36.836+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:36.840+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Finished task 4.0 in stage 10.0 (TID 410). 5819 bytes result sent to driver
[2024-12-14T19:41:36.843+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:36.847+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Starting task 34.0 in stage 10.0 (TID 426) (localhost, executor driver, partition 34, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:36.850+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Finished task 9.0 in stage 10.0 (TID 415). 5819 bytes result sent to driver
[2024-12-14T19:41:36.856+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Finished task 22.0 in stage 10.0 (TID 420) in 82 ms on localhost (executor driver) (2/200)
[2024-12-14T19:41:36.858+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:36.863+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:36.868+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Running task 34.0 in stage 10.0 (TID 426)
[2024-12-14T19:41:36.871+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 414) in 86 ms on localhost (executor driver) (3/200)
[2024-12-14T19:41:36.872+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
[2024-12-14T19:41:36.875+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Finished task 7.0 in stage 10.0 (TID 413). 5862 bytes result sent to driver
[2024-12-14T19:41:36.876+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Finished task 12.0 in stage 10.0 (TID 416). 5819 bytes result sent to driver
[2024-12-14T19:41:36.878+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Starting task 35.0 in stage 10.0 (TID 427) (localhost, executor driver, partition 35, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:36.880+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Starting task 39.0 in stage 10.0 (TID 428) (localhost, executor driver, partition 39, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:36 INFO Executor: Running task 35.0 in stage 10.0 (TID 427)
[2024-12-14T19:41:36.882+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Running task 39.0 in stage 10.0 (TID 428)
24/12/14 19:41:36 INFO TaskSetManager: Finished task 19.0 in stage 10.0 (TID 419) in 96 ms on localhost (executor driver) (4/200)
24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:36 INFO TaskSetManager: Starting task 40.0 in stage 10.0 (TID 429) (localhost, executor driver, partition 40, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:36.886+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:36 INFO TaskSetManager: Starting task 42.0 in stage 10.0 (TID 430) (localhost, executor driver, partition 42, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
24/12/14 19:41:36 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 415) in 102 ms on localhost (executor driver) (5/200)
24/12/14 19:41:36 INFO Executor: Running task 42.0 in stage 10.0 (TID 430)
[2024-12-14T19:41:36.890+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:36.896+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
[2024-12-14T19:41:36.897+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Running task 40.0 in stage 10.0 (TID 429)
[2024-12-14T19:41:36.899+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Starting task 43.0 in stage 10.0 (TID 431) (localhost, executor driver, partition 43, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:36.900+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:36.901+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:36.903+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Finished task 12.0 in stage 10.0 (TID 416) in 121 ms on localhost (executor driver) (6/200)
[2024-12-14T19:41:36.904+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 410) in 125 ms on localhost (executor driver) (7/200)
24/12/14 19:41:36 INFO Executor: Running task 43.0 in stage 10.0 (TID 431)
[2024-12-14T19:41:36.907+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 413) in 125 ms on localhost (executor driver) (8/200)
[2024-12-14T19:41:36.910+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Finished task 14.0 in stage 10.0 (TID 417). 5819 bytes result sent to driver
[2024-12-14T19:41:36.914+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Finished task 26.0 in stage 10.0 (TID 422). 5819 bytes result sent to driver
[2024-12-14T19:41:36.917+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Finished task 0.0 in stage 10.0 (TID 408). 5862 bytes result sent to driver
[2024-12-14T19:41:36.922+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Finished task 32.0 in stage 10.0 (TID 425). 5776 bytes result sent to driver
[2024-12-14T19:41:36.926+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Finished task 6.0 in stage 10.0 (TID 412). 5819 bytes result sent to driver
24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:36.933+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2024-12-14T19:41:36.943+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Finished task 29.0 in stage 10.0 (TID 423). 5819 bytes result sent to driver
[2024-12-14T19:41:36.945+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Finished task 42.0 in stage 10.0 (TID 430). 5776 bytes result sent to driver
[2024-12-14T19:41:36.950+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:36 INFO Executor: Finished task 3.0 in stage 10.0 (TID 409). 5819 bytes result sent to driver
[2024-12-14T19:41:36.955+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Finished task 16.0 in stage 10.0 (TID 418). 5819 bytes result sent to driver
[2024-12-14T19:41:36.965+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2024-12-14T19:41:36.973+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Starting task 46.0 in stage 10.0 (TID 432) (localhost, executor driver, partition 46, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:36 INFO Executor: Finished task 39.0 in stage 10.0 (TID 428). 5776 bytes result sent to driver
24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:36.980+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:36.983+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Running task 46.0 in stage 10.0 (TID 432)
[2024-12-14T19:41:36.987+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Starting task 47.0 in stage 10.0 (TID 433) (localhost, executor driver, partition 47, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:36.990+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Running task 47.0 in stage 10.0 (TID 433)
24/12/14 19:41:36 INFO TaskSetManager: Starting task 48.0 in stage 10.0 (TID 434) (localhost, executor driver, partition 48, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:36.993+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Running task 48.0 in stage 10.0 (TID 434)
[2024-12-14T19:41:36.996+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Starting task 49.0 in stage 10.0 (TID 435) (localhost, executor driver, partition 49, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:36.998+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Finished task 14.0 in stage 10.0 (TID 417) in 185 ms on localhost (executor driver) (9/200)
[2024-12-14T19:41:37.002+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 408) in 191 ms on localhost (executor driver) (10/200)
[2024-12-14T19:41:37.007+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Finished task 32.0 in stage 10.0 (TID 425) in 119 ms on localhost (executor driver) (11/200)
24/12/14 19:41:36 INFO Executor: Running task 49.0 in stage 10.0 (TID 435)
[2024-12-14T19:41:37.010+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Finished task 26.0 in stage 10.0 (TID 422) in 184 ms on localhost (executor driver) (12/200)
[2024-12-14T19:41:37.013+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.020+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.023+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.025+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 26 ms
24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.027+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Starting task 50.0 in stage 10.0 (TID 436) (localhost, executor driver, partition 50, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.029+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Finished task 31.0 in stage 10.0 (TID 424). 5819 bytes result sent to driver
[2024-12-14T19:41:37.032+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Starting task 51.0 in stage 10.0 (TID 437) (localhost, executor driver, partition 51, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.035+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Running task 50.0 in stage 10.0 (TID 436)
24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2024-12-14T19:41:37.037+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Finished task 25.0 in stage 10.0 (TID 421). 5862 bytes result sent to driver
24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:36 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 412) in 215 ms on localhost (executor driver) (13/200)
[2024-12-14T19:41:37.038+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Finished task 46.0 in stage 10.0 (TID 432). 5776 bytes result sent to driver
[2024-12-14T19:41:37.043+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.044+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Finished task 35.0 in stage 10.0 (TID 427). 5819 bytes result sent to driver
[2024-12-14T19:41:37.046+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Starting task 52.0 in stage 10.0 (TID 438) (localhost, executor driver, partition 52, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.047+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2024-12-14T19:41:37.049+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
24/12/14 19:41:36 INFO Executor: Running task 51.0 in stage 10.0 (TID 437)
24/12/14 19:41:36 INFO TaskSetManager: Starting task 53.0 in stage 10.0 (TID 439) (localhost, executor driver, partition 53, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.051+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Running task 52.0 in stage 10.0 (TID 438)
[2024-12-14T19:41:37.053+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Running task 53.0 in stage 10.0 (TID 439)
[2024-12-14T19:41:37.055+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Starting task 54.0 in stage 10.0 (TID 440) (localhost, executor driver, partition 54, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.057+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Finished task 47.0 in stage 10.0 (TID 433). 5776 bytes result sent to driver
24/12/14 19:41:36 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost:32963 in memory (size: 25.8 KiB, free: 434.4 MiB)
24/12/14 19:41:36 INFO TaskSetManager: Starting task 57.0 in stage 10.0 (TID 441) (localhost, executor driver, partition 57, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:36 INFO Executor: Running task 54.0 in stage 10.0 (TID 440)
24/12/14 19:41:36 INFO TaskSetManager: Finished task 29.0 in stage 10.0 (TID 423) in 229 ms on localhost (executor driver) (14/200)
24/12/14 19:41:36 INFO Executor: Finished task 43.0 in stage 10.0 (TID 431). 5776 bytes result sent to driver
24/12/14 19:41:36 INFO Executor: Running task 57.0 in stage 10.0 (TID 441)
[2024-12-14T19:41:37.069+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Finished task 39.0 in stage 10.0 (TID 428) in 142 ms on localhost (executor driver) (15/200)
[2024-12-14T19:41:37.071+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Starting task 59.0 in stage 10.0 (TID 442) (localhost, executor driver, partition 59, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.074+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 409) in 248 ms on localhost (executor driver) (16/200)
[2024-12-14T19:41:37.076+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.077+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:37.079+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.081+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.083+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.086+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:36 INFO Executor: Finished task 49.0 in stage 10.0 (TID 435). 5776 bytes result sent to driver
[2024-12-14T19:41:37.088+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Running task 59.0 in stage 10.0 (TID 442)
[2024-12-14T19:41:37.089+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Finished task 34.0 in stage 10.0 (TID 426). 5819 bytes result sent to driver
24/12/14 19:41:36 INFO TaskSetManager: Starting task 60.0 in stage 10.0 (TID 443) (localhost, executor driver, partition 60, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.091+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Running task 60.0 in stage 10.0 (TID 443)
24/12/14 19:41:36 INFO TaskSetManager: Finished task 16.0 in stage 10.0 (TID 418) in 260 ms on localhost (executor driver) (17/200)
[2024-12-14T19:41:37.092+0000] {docker.py:413} INFO - 24/12/14 19:41:36 INFO Executor: Finished task 40.0 in stage 10.0 (TID 429). 5776 bytes result sent to driver
24/12/14 19:41:36 INFO TaskSetManager: Finished task 42.0 in stage 10.0 (TID 430) in 163 ms on localhost (executor driver) (18/200)
24/12/14 19:41:36 INFO TaskSetManager: Starting task 61.0 in stage 10.0 (TID 444) (localhost, executor driver, partition 61, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO TaskSetManager: Starting task 62.0 in stage 10.0 (TID 445) (localhost, executor driver, partition 62, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.094+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 62.0 in stage 10.0 (TID 445)
[2024-12-14T19:41:37.098+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 63.0 in stage 10.0 (TID 446) (localhost, executor driver, partition 63, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.100+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 64.0 in stage 10.0 (TID 447) (localhost, executor driver, partition 64, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO Executor: Running task 61.0 in stage 10.0 (TID 444)
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.101+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 68.0 in stage 10.0 (TID 448) (localhost, executor driver, partition 68, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.102+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 64.0 in stage 10.0 (TID 447)
[2024-12-14T19:41:37.104+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 53.0 in stage 10.0 (TID 439). 5776 bytes result sent to driver
[2024-12-14T19:41:37.105+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.107+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2024-12-14T19:41:37.110+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 63.0 in stage 10.0 (TID 446)
24/12/14 19:41:37 INFO Executor: Running task 68.0 in stage 10.0 (TID 448)
[2024-12-14T19:41:37.111+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 31.0 in stage 10.0 (TID 424) in 209 ms on localhost (executor driver) (19/200)
[2024-12-14T19:41:37.114+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 25.0 in stage 10.0 (TID 421) in 276 ms on localhost (executor driver) (20/200)
[2024-12-14T19:41:37.115+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 43.0 in stage 10.0 (TID 431) in 176 ms on localhost (executor driver) (21/200)
[2024-12-14T19:41:37.117+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.118+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.120+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 69.0 in stage 10.0 (TID 449) (localhost, executor driver, partition 69, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.121+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.123+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.126+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 69.0 in stage 10.0 (TID 449)
[2024-12-14T19:41:37.128+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 70.0 in stage 10.0 (TID 450) (localhost, executor driver, partition 70, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.130+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 50.0 in stage 10.0 (TID 436). 5776 bytes result sent to driver
24/12/14 19:41:37 INFO Executor: Finished task 57.0 in stage 10.0 (TID 441). 5776 bytes result sent to driver
[2024-12-14T19:41:37.132+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 48.0 in stage 10.0 (TID 434). 5819 bytes result sent to driver
[2024-12-14T19:41:37.138+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 71.0 in stage 10.0 (TID 451) (localhost, executor driver, partition 71, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.140+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 71.0 in stage 10.0 (TID 451)
[2024-12-14T19:41:37.142+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.144+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 70.0 in stage 10.0 (TID 450)
[2024-12-14T19:41:37.146+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.148+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 54.0 in stage 10.0 (TID 440). 5776 bytes result sent to driver
[2024-12-14T19:41:37.150+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
24/12/14 19:41:37 INFO Executor: Finished task 52.0 in stage 10.0 (TID 438). 5776 bytes result sent to driver
24/12/14 19:41:37 INFO Executor: Finished task 60.0 in stage 10.0 (TID 443). 5776 bytes result sent to driver
[2024-12-14T19:41:37.152+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 72.0 in stage 10.0 (TID 452) (localhost, executor driver, partition 72, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.154+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 68.0 in stage 10.0 (TID 448). 5776 bytes result sent to driver
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO Executor: Running task 72.0 in stage 10.0 (TID 452)
24/12/14 19:41:37 INFO Executor: Finished task 62.0 in stage 10.0 (TID 445). 5776 bytes result sent to driver
24/12/14 19:41:37 INFO TaskSetManager: Finished task 49.0 in stage 10.0 (TID 435) in 147 ms on localhost (executor driver) (22/200)
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO Executor: Finished task 51.0 in stage 10.0 (TID 437). 5819 bytes result sent to driver
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.156+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 73.0 in stage 10.0 (TID 453) (localhost, executor driver, partition 73, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.160+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 74.0 in stage 10.0 (TID 454) (localhost, executor driver, partition 74, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO TaskSetManager: Finished task 35.0 in stage 10.0 (TID 427) in 220 ms on localhost (executor driver) (23/200)
24/12/14 19:41:37 INFO Executor: Running task 73.0 in stage 10.0 (TID 453)
24/12/14 19:41:37 INFO Executor: Running task 74.0 in stage 10.0 (TID 454)
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2024-12-14T19:41:37.163+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 40.0 in stage 10.0 (TID 429) in 219 ms on localhost (executor driver) (24/200)
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2024-12-14T19:41:37.165+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 47.0 in stage 10.0 (TID 433) in 166 ms on localhost (executor driver) (25/200)
[2024-12-14T19:41:37.166+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 75.0 in stage 10.0 (TID 455) (localhost, executor driver, partition 75, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO TaskSetManager: Finished task 46.0 in stage 10.0 (TID 432) in 192 ms on localhost (executor driver) (26/200)
[2024-12-14T19:41:37.168+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.170+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.172+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 57.0 in stage 10.0 (TID 441) in 96 ms on localhost (executor driver) (27/200)
[2024-12-14T19:41:37.174+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.179+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 75.0 in stage 10.0 (TID 455)
[2024-12-14T19:41:37.181+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 76.0 in stage 10.0 (TID 456) (localhost, executor driver, partition 76, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.183+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 76.0 in stage 10.0 (TID 456)
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.187+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.189+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 77.0 in stage 10.0 (TID 457) (localhost, executor driver, partition 77, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2024-12-14T19:41:37.190+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 77.0 in stage 10.0 (TID 457)
[2024-12-14T19:41:37.193+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 78.0 in stage 10.0 (TID 458) (localhost, executor driver, partition 78, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.194+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 34.0 in stage 10.0 (TID 426) in 253 ms on localhost (executor driver) (28/200)
[2024-12-14T19:41:37.196+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 78.0 in stage 10.0 (TID 458)
[2024-12-14T19:41:37.198+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 61.0 in stage 10.0 (TID 444). 5819 bytes result sent to driver
[2024-12-14T19:41:37.200+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 59.0 in stage 10.0 (TID 442). 5819 bytes result sent to driver
24/12/14 19:41:37 INFO TaskSetManager: Finished task 48.0 in stage 10.0 (TID 434) in 180 ms on localhost (executor driver) (29/200)
[2024-12-14T19:41:37.203+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 50.0 in stage 10.0 (TID 436) in 155 ms on localhost (executor driver) (30/200)
[2024-12-14T19:41:37.207+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 53.0 in stage 10.0 (TID 439) in 121 ms on localhost (executor driver) (31/200)
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO Executor: Finished task 69.0 in stage 10.0 (TID 449). 5776 bytes result sent to driver
24/12/14 19:41:37 INFO TaskSetManager: Starting task 79.0 in stage 10.0 (TID 459) (localhost, executor driver, partition 79, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.213+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 72.0 in stage 10.0 (TID 452). 5819 bytes result sent to driver
[2024-12-14T19:41:37.218+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 54.0 in stage 10.0 (TID 440) in 125 ms on localhost (executor driver) (32/200)
[2024-12-14T19:41:37.220+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 63.0 in stage 10.0 (TID 446). 5776 bytes result sent to driver
[2024-12-14T19:41:37.222+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 51.0 in stage 10.0 (TID 437) in 151 ms on localhost (executor driver) (33/200)
24/12/14 19:41:37 INFO Executor: Finished task 74.0 in stage 10.0 (TID 454). 5776 bytes result sent to driver
[2024-12-14T19:41:37.224+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 60.0 in stage 10.0 (TID 443) in 104 ms on localhost (executor driver) (34/200)
[2024-12-14T19:41:37.227+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 80.0 in stage 10.0 (TID 460) (localhost, executor driver, partition 80, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.228+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 70.0 in stage 10.0 (TID 450). 5776 bytes result sent to driver
[2024-12-14T19:41:37.230+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 79.0 in stage 10.0 (TID 459)
[2024-12-14T19:41:37.240+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 71.0 in stage 10.0 (TID 451). 5776 bytes result sent to driver
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.242+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 80.0 in stage 10.0 (TID 460)
[2024-12-14T19:41:37.244+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:37.246+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.248+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2024-12-14T19:41:37.249+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 81.0 in stage 10.0 (TID 461) (localhost, executor driver, partition 81, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.251+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 52.0 in stage 10.0 (TID 438) in 147 ms on localhost (executor driver) (35/200)
[2024-12-14T19:41:37.253+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 81.0 in stage 10.0 (TID 461)
24/12/14 19:41:37 INFO Executor: Finished task 77.0 in stage 10.0 (TID 457). 5776 bytes result sent to driver
[2024-12-14T19:41:37.255+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.258+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2024-12-14T19:41:37.260+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO TaskSetManager: Starting task 82.0 in stage 10.0 (TID 462) (localhost, executor driver, partition 82, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.261+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 64.0 in stage 10.0 (TID 447). 5776 bytes result sent to driver
[2024-12-14T19:41:37.265+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 82.0 in stage 10.0 (TID 462)
[2024-12-14T19:41:37.272+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 83.0 in stage 10.0 (TID 463) (localhost, executor driver, partition 83, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.273+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 61.0 in stage 10.0 (TID 444) in 105 ms on localhost (executor driver) (36/200)
[2024-12-14T19:41:37.275+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 62.0 in stage 10.0 (TID 445) in 105 ms on localhost (executor driver) (37/200)
[2024-12-14T19:41:37.277+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 69.0 in stage 10.0 (TID 449) in 92 ms on localhost (executor driver) (38/200)
[2024-12-14T19:41:37.279+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 68.0 in stage 10.0 (TID 448) in 101 ms on localhost (executor driver) (39/200)
[2024-12-14T19:41:37.282+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 83.0 in stage 10.0 (TID 463)
[2024-12-14T19:41:37.284+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 73.0 in stage 10.0 (TID 453). 5776 bytes result sent to driver
[2024-12-14T19:41:37.286+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.288+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:37.290+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 75.0 in stage 10.0 (TID 455). 5776 bytes result sent to driver
24/12/14 19:41:37 INFO TaskSetManager: Starting task 84.0 in stage 10.0 (TID 464) (localhost, executor driver, partition 84, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.292+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 85.0 in stage 10.0 (TID 465) (localhost, executor driver, partition 85, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO Executor: Running task 84.0 in stage 10.0 (TID 464)
[2024-12-14T19:41:37.294+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.297+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 72.0 in stage 10.0 (TID 452) in 89 ms on localhost (executor driver) (40/200)
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.301+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 63.0 in stage 10.0 (TID 446) in 114 ms on localhost (executor driver) (41/200)
[2024-12-14T19:41:37.302+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 78.0 in stage 10.0 (TID 458). 5776 bytes result sent to driver
24/12/14 19:41:37 INFO TaskSetManager: Starting task 86.0 in stage 10.0 (TID 466) (localhost, executor driver, partition 86, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.303+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO Executor: Running task 85.0 in stage 10.0 (TID 465)
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2024-12-14T19:41:37.305+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 86.0 in stage 10.0 (TID 466)
24/12/14 19:41:37 INFO Executor: Finished task 76.0 in stage 10.0 (TID 456). 5819 bytes result sent to driver
[2024-12-14T19:41:37.306+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 88.0 in stage 10.0 (TID 467) (localhost, executor driver, partition 88, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.309+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 81.0 in stage 10.0 (TID 461). 5776 bytes result sent to driver
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.310+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 88.0 in stage 10.0 (TID 467)
[2024-12-14T19:41:37.311+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 89.0 in stage 10.0 (TID 468) (localhost, executor driver, partition 89, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO TaskSetManager: Finished task 59.0 in stage 10.0 (TID 442) in 154 ms on localhost (executor driver) (42/200)
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO TaskSetManager: Finished task 71.0 in stage 10.0 (TID 451) in 109 ms on localhost (executor driver) (43/200)
[2024-12-14T19:41:37.313+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 89.0 in stage 10.0 (TID 468)
[2024-12-14T19:41:37.314+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 82.0 in stage 10.0 (TID 462). 5819 bytes result sent to driver
[2024-12-14T19:41:37.316+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 90.0 in stage 10.0 (TID 469) (localhost, executor driver, partition 90, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO Executor: Running task 90.0 in stage 10.0 (TID 469)
[2024-12-14T19:41:37.317+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 92.0 in stage 10.0 (TID 470) (localhost, executor driver, partition 92, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.320+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.321+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 77.0 in stage 10.0 (TID 457) in 75 ms on localhost (executor driver) (44/200)
24/12/14 19:41:37 INFO Executor: Finished task 79.0 in stage 10.0 (TID 459). 5776 bytes result sent to driver
[2024-12-14T19:41:37.324+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 84.0 in stage 10.0 (TID 464). 5776 bytes result sent to driver
24/12/14 19:41:37 INFO Executor: Running task 92.0 in stage 10.0 (TID 470)
[2024-12-14T19:41:37.329+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.331+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.333+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:37.336+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 95.0 in stage 10.0 (TID 471) (localhost, executor driver, partition 95, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.341+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 64.0 in stage 10.0 (TID 447) in 142 ms on localhost (executor driver) (45/200)
[2024-12-14T19:41:37.343+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 75.0 in stage 10.0 (TID 455) in 90 ms on localhost (executor driver) (46/200)
[2024-12-14T19:41:37.345+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 95.0 in stage 10.0 (TID 471)
[2024-12-14T19:41:37.346+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:37.348+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.351+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:37 INFO TaskSetManager: Starting task 96.0 in stage 10.0 (TID 472) (localhost, executor driver, partition 96, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.353+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 85.0 in stage 10.0 (TID 465). 5776 bytes result sent to driver
24/12/14 19:41:37 INFO TaskSetManager: Starting task 97.0 in stage 10.0 (TID 473) (localhost, executor driver, partition 97, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO Executor: Running task 96.0 in stage 10.0 (TID 472)
24/12/14 19:41:37 INFO TaskSetManager: Finished task 74.0 in stage 10.0 (TID 454) in 107 ms on localhost (executor driver) (47/200)
24/12/14 19:41:37 INFO TaskSetManager: Finished task 78.0 in stage 10.0 (TID 458) in 88 ms on localhost (executor driver) (48/200)
24/12/14 19:41:37 INFO TaskSetManager: Finished task 70.0 in stage 10.0 (TID 450) in 139 ms on localhost (executor driver) (49/200)
24/12/14 19:41:37 INFO TaskSetManager: Finished task 73.0 in stage 10.0 (TID 453) in 111 ms on localhost (executor driver) (50/200)
[2024-12-14T19:41:37.354+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 98.0 in stage 10.0 (TID 474) (localhost, executor driver, partition 98, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.356+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 86.0 in stage 10.0 (TID 466). 5776 bytes result sent to driver
[2024-12-14T19:41:37.359+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 83.0 in stage 10.0 (TID 463). 5776 bytes result sent to driver
[2024-12-14T19:41:37.360+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 76.0 in stage 10.0 (TID 456) in 97 ms on localhost (executor driver) (51/200)
[2024-12-14T19:41:37.362+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 88.0 in stage 10.0 (TID 467). 5776 bytes result sent to driver
24/12/14 19:41:37 INFO Executor: Running task 98.0 in stage 10.0 (TID 474)
24/12/14 19:41:37 INFO Executor: Running task 97.0 in stage 10.0 (TID 473)
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.363+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO TaskSetManager: Starting task 99.0 in stage 10.0 (TID 475) (localhost, executor driver, partition 99, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.366+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 99.0 in stage 10.0 (TID 475)
[2024-12-14T19:41:37.368+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 82.0 in stage 10.0 (TID 462) in 65 ms on localhost (executor driver) (52/200)
24/12/14 19:41:37 INFO Executor: Finished task 80.0 in stage 10.0 (TID 460). 5776 bytes result sent to driver
[2024-12-14T19:41:37.370+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.372+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 100.0 in stage 10.0 (TID 476) (localhost, executor driver, partition 100, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.374+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 81.0 in stage 10.0 (TID 461) in 76 ms on localhost (executor driver) (53/200)
[2024-12-14T19:41:37.378+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 100.0 in stage 10.0 (TID 476)
24/12/14 19:41:37 INFO TaskSetManager: Starting task 101.0 in stage 10.0 (TID 477) (localhost, executor driver, partition 101, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.382+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.383+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:37 INFO TaskSetManager: Finished task 79.0 in stage 10.0 (TID 459) in 90 ms on localhost (executor driver) (54/200)
[2024-12-14T19:41:37.386+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 101.0 in stage 10.0 (TID 477)
[2024-12-14T19:41:37.388+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 102.0 in stage 10.0 (TID 478) (localhost, executor driver, partition 102, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.389+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 102.0 in stage 10.0 (TID 478)
[2024-12-14T19:41:37.391+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 103.0 in stage 10.0 (TID 479) (localhost, executor driver, partition 103, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO TaskSetManager: Finished task 84.0 in stage 10.0 (TID 464) in 62 ms on localhost (executor driver) (55/200)
24/12/14 19:41:37 INFO Executor: Finished task 89.0 in stage 10.0 (TID 468). 5819 bytes result sent to driver
[2024-12-14T19:41:37.392+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 85.0 in stage 10.0 (TID 465) in 61 ms on localhost (executor driver) (56/200)
[2024-12-14T19:41:37.395+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 90.0 in stage 10.0 (TID 469). 5819 bytes result sent to driver
[2024-12-14T19:41:37.397+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.399+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.402+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 103.0 in stage 10.0 (TID 479)
[2024-12-14T19:41:37.403+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 96.0 in stage 10.0 (TID 472). 5776 bytes result sent to driver
24/12/14 19:41:37 INFO TaskSetManager: Starting task 104.0 in stage 10.0 (TID 480) (localhost, executor driver, partition 104, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.405+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 104.0 in stage 10.0 (TID 480)
24/12/14 19:41:37 INFO TaskSetManager: Starting task 105.0 in stage 10.0 (TID 481) (localhost, executor driver, partition 105, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.406+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.408+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2024-12-14T19:41:37.409+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 106.0 in stage 10.0 (TID 482) (localhost, executor driver, partition 106, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.411+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 92.0 in stage 10.0 (TID 470). 5776 bytes result sent to driver
[2024-12-14T19:41:37.412+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 95.0 in stage 10.0 (TID 471). 5776 bytes result sent to driver
[2024-12-14T19:41:37.415+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 105.0 in stage 10.0 (TID 481)
[2024-12-14T19:41:37.416+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.422+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.424+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 106.0 in stage 10.0 (TID 482)
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.425+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 108.0 in stage 10.0 (TID 483) (localhost, executor driver, partition 108, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO TaskSetManager: Finished task 86.0 in stage 10.0 (TID 466) in 84 ms on localhost (executor driver) (57/200)
[2024-12-14T19:41:37.427+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 88.0 in stage 10.0 (TID 467) in 82 ms on localhost (executor driver) (58/200)
[2024-12-14T19:41:37.429+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 108.0 in stage 10.0 (TID 483)
24/12/14 19:41:37 INFO Executor: Finished task 98.0 in stage 10.0 (TID 474). 5819 bytes result sent to driver
24/12/14 19:41:37 INFO TaskSetManager: Starting task 109.0 in stage 10.0 (TID 484) (localhost, executor driver, partition 109, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO TaskSetManager: Finished task 83.0 in stage 10.0 (TID 463) in 105 ms on localhost (executor driver) (59/200)
24/12/14 19:41:37 INFO Executor: Running task 109.0 in stage 10.0 (TID 484)
24/12/14 19:41:37 INFO TaskSetManager: Finished task 89.0 in stage 10.0 (TID 468) in 80 ms on localhost (executor driver) (60/200)
[2024-12-14T19:41:37.431+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 101.0 in stage 10.0 (TID 477). 5819 bytes result sent to driver
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO TaskSetManager: Starting task 111.0 in stage 10.0 (TID 485) (localhost, executor driver, partition 111, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO Executor: Running task 111.0 in stage 10.0 (TID 485)
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO TaskSetManager: Starting task 113.0 in stage 10.0 (TID 486) (localhost, executor driver, partition 113, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO Executor: Finished task 97.0 in stage 10.0 (TID 473). 5819 bytes result sent to driver
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.432+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 113.0 in stage 10.0 (TID 486)
[2024-12-14T19:41:37.434+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 120.0 in stage 10.0 (TID 487) (localhost, executor driver, partition 120, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO TaskSetManager: Finished task 80.0 in stage 10.0 (TID 460) in 125 ms on localhost (executor driver) (61/200)
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO Executor: Finished task 102.0 in stage 10.0 (TID 478). 5819 bytes result sent to driver
24/12/14 19:41:37 INFO TaskSetManager: Starting task 123.0 in stage 10.0 (TID 488) (localhost, executor driver, partition 123, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO Executor: Running task 120.0 in stage 10.0 (TID 487)
24/12/14 19:41:37 INFO Executor: Running task 123.0 in stage 10.0 (TID 488)
[2024-12-14T19:41:37.438+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 124.0 in stage 10.0 (TID 489) (localhost, executor driver, partition 124, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.440+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 124.0 in stage 10.0 (TID 489)
24/12/14 19:41:37 INFO TaskSetManager: Starting task 125.0 in stage 10.0 (TID 490) (localhost, executor driver, partition 125, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO TaskSetManager: Starting task 127.0 in stage 10.0 (TID 491) (localhost, executor driver, partition 127, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO TaskSetManager: Finished task 92.0 in stage 10.0 (TID 470) in 84 ms on localhost (executor driver) (62/200)
[2024-12-14T19:41:37.444+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 127.0 in stage 10.0 (TID 491)
[2024-12-14T19:41:37.446+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:37.447+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 125.0 in stage 10.0 (TID 490)
[2024-12-14T19:41:37.449+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 98.0 in stage 10.0 (TID 474) in 66 ms on localhost (executor driver) (63/200)
[2024-12-14T19:41:37.450+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 99.0 in stage 10.0 (TID 475). 5819 bytes result sent to driver
[2024-12-14T19:41:37.452+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 104.0 in stage 10.0 (TID 480). 5819 bytes result sent to driver
[2024-12-14T19:41:37.453+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 101.0 in stage 10.0 (TID 477) in 57 ms on localhost (executor driver) (64/200)
[2024-12-14T19:41:37.455+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 95.0 in stage 10.0 (TID 471) in 85 ms on localhost (executor driver) (65/200)
[2024-12-14T19:41:37.456+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 97.0 in stage 10.0 (TID 473) in 75 ms on localhost (executor driver) (66/200)
[2024-12-14T19:41:37.458+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.460+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.461+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 129.0 in stage 10.0 (TID 492) (localhost, executor driver, partition 129, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.464+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 129.0 in stage 10.0 (TID 492)
[2024-12-14T19:41:37.465+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 105.0 in stage 10.0 (TID 481). 5819 bytes result sent to driver
24/12/14 19:41:37 INFO Executor: Finished task 100.0 in stage 10.0 (TID 476). 5819 bytes result sent to driver
24/12/14 19:41:37 INFO Executor: Finished task 103.0 in stage 10.0 (TID 479). 5819 bytes result sent to driver
24/12/14 19:41:37 INFO Executor: Finished task 106.0 in stage 10.0 (TID 482). 5776 bytes result sent to driver
24/12/14 19:41:37 INFO TaskSetManager: Starting task 130.0 in stage 10.0 (TID 493) (localhost, executor driver, partition 130, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.470+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 90.0 in stage 10.0 (TID 469) in 101 ms on localhost (executor driver) (67/200)
24/12/14 19:41:37 INFO Executor: Finished task 111.0 in stage 10.0 (TID 485). 5776 bytes result sent to driver
[2024-12-14T19:41:37.472+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 130.0 in stage 10.0 (TID 493)
24/12/14 19:41:37 INFO TaskSetManager: Finished task 96.0 in stage 10.0 (TID 472) in 85 ms on localhost (executor driver) (68/200)
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.475+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.479+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 102.0 in stage 10.0 (TID 478) in 66 ms on localhost (executor driver) (69/200)
[2024-12-14T19:41:37.482+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.484+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 99.0 in stage 10.0 (TID 475) in 76 ms on localhost (executor driver) (70/200)
[2024-12-14T19:41:37.490+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.492+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 104.0 in stage 10.0 (TID 480) in 57 ms on localhost (executor driver) (71/200)
[2024-12-14T19:41:37.494+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 132.0 in stage 10.0 (TID 494) (localhost, executor driver, partition 132, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.496+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 132.0 in stage 10.0 (TID 494)
[2024-12-14T19:41:37.497+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 135.0 in stage 10.0 (TID 495) (localhost, executor driver, partition 135, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.498+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 105.0 in stage 10.0 (TID 481) in 62 ms on localhost (executor driver) (72/200)
[2024-12-14T19:41:37.500+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO Executor: Running task 135.0 in stage 10.0 (TID 495)
[2024-12-14T19:41:37.501+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.504+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO TaskSetManager: Starting task 136.0 in stage 10.0 (TID 496) (localhost, executor driver, partition 136, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.508+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 136.0 in stage 10.0 (TID 496)
[2024-12-14T19:41:37.510+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
[2024-12-14T19:41:37.515+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.518+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:37.523+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.525+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.529+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 137.0 in stage 10.0 (TID 497) (localhost, executor driver, partition 137, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.531+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 124.0 in stage 10.0 (TID 489). 5862 bytes result sent to driver
[2024-12-14T19:41:37.532+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 142.0 in stage 10.0 (TID 498) (localhost, executor driver, partition 142, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO Executor: Running task 137.0 in stage 10.0 (TID 497)
24/12/14 19:41:37 INFO Executor: Running task 142.0 in stage 10.0 (TID 498)
[2024-12-14T19:41:37.534+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 145.0 in stage 10.0 (TID 499) (localhost, executor driver, partition 145, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.536+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 100.0 in stage 10.0 (TID 476) in 105 ms on localhost (executor driver) (73/200)
[2024-12-14T19:41:37.538+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 145.0 in stage 10.0 (TID 499)
[2024-12-14T19:41:37.540+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO TaskSetManager: Starting task 146.0 in stage 10.0 (TID 500) (localhost, executor driver, partition 146, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO TaskSetManager: Finished task 103.0 in stage 10.0 (TID 479) in 101 ms on localhost (executor driver) (74/200)
24/12/14 19:41:37 INFO Executor: Finished task 129.0 in stage 10.0 (TID 492). 5819 bytes result sent to driver
24/12/14 19:41:37 INFO TaskSetManager: Finished task 106.0 in stage 10.0 (TID 482) in 90 ms on localhost (executor driver) (75/200)
24/12/14 19:41:37 INFO Executor: Finished task 108.0 in stage 10.0 (TID 483). 5862 bytes result sent to driver
24/12/14 19:41:37 INFO Executor: Finished task 123.0 in stage 10.0 (TID 488). 5819 bytes result sent to driver
24/12/14 19:41:37 INFO TaskSetManager: Finished task 111.0 in stage 10.0 (TID 485) in 66 ms on localhost (executor driver) (76/200)
24/12/14 19:41:37 INFO Executor: Running task 146.0 in stage 10.0 (TID 500)
24/12/14 19:41:37 INFO Executor: Finished task 127.0 in stage 10.0 (TID 491). 5819 bytes result sent to driver
[2024-12-14T19:41:37.541+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 120.0 in stage 10.0 (TID 487). 5819 bytes result sent to driver
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.543+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 148.0 in stage 10.0 (TID 501) (localhost, executor driver, partition 148, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.544+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
24/12/14 19:41:37 INFO TaskSetManager: Finished task 124.0 in stage 10.0 (TID 489) in 65 ms on localhost (executor driver) (77/200)
24/12/14 19:41:37 INFO Executor: Running task 148.0 in stage 10.0 (TID 501)
24/12/14 19:41:37 INFO TaskSetManager: Finished task 129.0 in stage 10.0 (TID 492) in 51 ms on localhost (executor driver) (78/200)
24/12/14 19:41:37 INFO Executor: Finished task 113.0 in stage 10.0 (TID 486). 5819 bytes result sent to driver
[2024-12-14T19:41:37.549+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.553+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.556+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO Executor: Finished task 109.0 in stage 10.0 (TID 484). 5819 bytes result sent to driver
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:37 INFO Executor: Finished task 130.0 in stage 10.0 (TID 493). 5819 bytes result sent to driver
24/12/14 19:41:37 INFO TaskSetManager: Starting task 149.0 in stage 10.0 (TID 502) (localhost, executor driver, partition 149, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.558+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.560+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.562+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 125.0 in stage 10.0 (TID 490). 5819 bytes result sent to driver
[2024-12-14T19:41:37.564+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 149.0 in stage 10.0 (TID 502)
[2024-12-14T19:41:37.566+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 132.0 in stage 10.0 (TID 494). 5819 bytes result sent to driver
[2024-12-14T19:41:37.568+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 150.0 in stage 10.0 (TID 503) (localhost, executor driver, partition 150, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.569+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.571+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.572+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.574+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.576+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 150.0 in stage 10.0 (TID 503)
24/12/14 19:41:37 INFO TaskSetManager: Starting task 151.0 in stage 10.0 (TID 504) (localhost, executor driver, partition 151, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.578+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 136.0 in stage 10.0 (TID 496). 5819 bytes result sent to driver
[2024-12-14T19:41:37.580+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 152.0 in stage 10.0 (TID 505) (localhost, executor driver, partition 152, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.582+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 151.0 in stage 10.0 (TID 504)
[2024-12-14T19:41:37.583+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 142.0 in stage 10.0 (TID 498). 5776 bytes result sent to driver
[2024-12-14T19:41:37.586+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 123.0 in stage 10.0 (TID 488) in 100 ms on localhost (executor driver) (79/200)
24/12/14 19:41:37 INFO Executor: Running task 152.0 in stage 10.0 (TID 505)
[2024-12-14T19:41:37.588+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 154.0 in stage 10.0 (TID 506) (localhost, executor driver, partition 154, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.590+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 108.0 in stage 10.0 (TID 483) in 126 ms on localhost (executor driver) (80/200)
[2024-12-14T19:41:37.592+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 120.0 in stage 10.0 (TID 487) in 113 ms on localhost (executor driver) (81/200)
24/12/14 19:41:37 INFO Executor: Running task 154.0 in stage 10.0 (TID 506)
24/12/14 19:41:37 INFO Executor: Finished task 135.0 in stage 10.0 (TID 495). 5819 bytes result sent to driver
[2024-12-14T19:41:37.598+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 158.0 in stage 10.0 (TID 507) (localhost, executor driver, partition 158, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.606+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 159.0 in stage 10.0 (TID 508) (localhost, executor driver, partition 159, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.614+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 137.0 in stage 10.0 (TID 497). 5819 bytes result sent to driver
[2024-12-14T19:41:37.616+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 158.0 in stage 10.0 (TID 507)
[2024-12-14T19:41:37.619+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 127.0 in stage 10.0 (TID 491) in 111 ms on localhost (executor driver) (82/200)
[2024-12-14T19:41:37.625+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 113.0 in stage 10.0 (TID 486) in 121 ms on localhost (executor driver) (83/200)
[2024-12-14T19:41:37.627+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 130.0 in stage 10.0 (TID 493) in 99 ms on localhost (executor driver) (84/200)
[2024-12-14T19:41:37.632+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 159.0 in stage 10.0 (TID 508)
[2024-12-14T19:41:37.634+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 145.0 in stage 10.0 (TID 499). 5819 bytes result sent to driver
24/12/14 19:41:37 INFO TaskSetManager: Starting task 161.0 in stage 10.0 (TID 509) (localhost, executor driver, partition 161, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.636+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 161.0 in stage 10.0 (TID 509)
24/12/14 19:41:37 INFO TaskSetManager: Starting task 162.0 in stage 10.0 (TID 510) (localhost, executor driver, partition 162, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO TaskSetManager: Starting task 164.0 in stage 10.0 (TID 511) (localhost, executor driver, partition 164, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.637+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 109.0 in stage 10.0 (TID 484) in 132 ms on localhost (executor driver) (85/200)
[2024-12-14T19:41:37.639+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 125.0 in stage 10.0 (TID 490) in 120 ms on localhost (executor driver) (86/200)
[2024-12-14T19:41:37.643+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 162.0 in stage 10.0 (TID 510)
24/12/14 19:41:37 INFO TaskSetManager: Finished task 132.0 in stage 10.0 (TID 494) in 99 ms on localhost (executor driver) (87/200)
[2024-12-14T19:41:37.651+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.656+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2024-12-14T19:41:37.659+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.661+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 165.0 in stage 10.0 (TID 512) (localhost, executor driver, partition 165, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.667+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 164.0 in stage 10.0 (TID 511)
[2024-12-14T19:41:37.670+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 146.0 in stage 10.0 (TID 500). 5819 bytes result sent to driver
[2024-12-14T19:41:37.673+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.676+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:37.678+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 136.0 in stage 10.0 (TID 496) in 102 ms on localhost (executor driver) (88/200)
[2024-12-14T19:41:37.681+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 165.0 in stage 10.0 (TID 512)
[2024-12-14T19:41:37.682+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.684+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2024-12-14T19:41:37.685+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.687+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.689+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 149.0 in stage 10.0 (TID 502). 5819 bytes result sent to driver
[2024-12-14T19:41:37.691+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.693+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2024-12-14T19:41:37.695+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 167.0 in stage 10.0 (TID 513) (localhost, executor driver, partition 167, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.697+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 150.0 in stage 10.0 (TID 503). 5819 bytes result sent to driver
[2024-12-14T19:41:37.699+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.701+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO Executor: Finished task 158.0 in stage 10.0 (TID 507). 5776 bytes result sent to driver
24/12/14 19:41:37 INFO TaskSetManager: Starting task 168.0 in stage 10.0 (TID 514) (localhost, executor driver, partition 168, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.702+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 137.0 in stage 10.0 (TID 497) in 102 ms on localhost (executor driver) (89/200)
[2024-12-14T19:41:37.704+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 168.0 in stage 10.0 (TID 514)
24/12/14 19:41:37 INFO Executor: Running task 167.0 in stage 10.0 (TID 513)
[2024-12-14T19:41:37.706+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 135.0 in stage 10.0 (TID 495) in 124 ms on localhost (executor driver) (90/200)
[2024-12-14T19:41:37.709+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 142.0 in stage 10.0 (TID 498) in 103 ms on localhost (executor driver) (91/200)
[2024-12-14T19:41:37.714+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 151.0 in stage 10.0 (TID 504). 5819 bytes result sent to driver
[2024-12-14T19:41:37.715+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.716+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.719+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:37.724+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 161.0 in stage 10.0 (TID 509). 5776 bytes result sent to driver
24/12/14 19:41:37 INFO Executor: Finished task 152.0 in stage 10.0 (TID 505). 5776 bytes result sent to driver
24/12/14 19:41:37 INFO Executor: Finished task 162.0 in stage 10.0 (TID 510). 5776 bytes result sent to driver
[2024-12-14T19:41:37.726+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 170.0 in stage 10.0 (TID 515) (localhost, executor driver, partition 170, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.727+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 148.0 in stage 10.0 (TID 501). 5819 bytes result sent to driver
24/12/14 19:41:37 INFO Executor: Running task 170.0 in stage 10.0 (TID 515)
24/12/14 19:41:37 INFO Executor: Finished task 159.0 in stage 10.0 (TID 508). 5776 bytes result sent to driver
[2024-12-14T19:41:37.729+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 171.0 in stage 10.0 (TID 516) (localhost, executor driver, partition 171, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.732+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 145.0 in stage 10.0 (TID 499) in 114 ms on localhost (executor driver) (92/200)
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.739+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 146.0 in stage 10.0 (TID 500) in 112 ms on localhost (executor driver) (93/200)
[2024-12-14T19:41:37.744+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 171.0 in stage 10.0 (TID 516)
[2024-12-14T19:41:37.746+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 164.0 in stage 10.0 (TID 511). 5776 bytes result sent to driver
[2024-12-14T19:41:37.747+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.749+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.751+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 172.0 in stage 10.0 (TID 517) (localhost, executor driver, partition 172, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.754+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 173.0 in stage 10.0 (TID 518) (localhost, executor driver, partition 173, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.756+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 172.0 in stage 10.0 (TID 517)
[2024-12-14T19:41:37.758+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 165.0 in stage 10.0 (TID 512). 5776 bytes result sent to driver
[2024-12-14T19:41:37.760+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 173.0 in stage 10.0 (TID 518)
[2024-12-14T19:41:37.762+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 174.0 in stage 10.0 (TID 519) (localhost, executor driver, partition 174, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO TaskSetManager: Finished task 149.0 in stage 10.0 (TID 502) in 116 ms on localhost (executor driver) (94/200)
[2024-12-14T19:41:37.766+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 158.0 in stage 10.0 (TID 507) in 74 ms on localhost (executor driver) (95/200)
[2024-12-14T19:41:37.768+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 174.0 in stage 10.0 (TID 519)
[2024-12-14T19:41:37.770+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 150.0 in stage 10.0 (TID 503) in 116 ms on localhost (executor driver) (96/200)
[2024-12-14T19:41:37.772+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 175.0 in stage 10.0 (TID 520) (localhost, executor driver, partition 175, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO Executor: Finished task 170.0 in stage 10.0 (TID 515). 5776 bytes result sent to driver
24/12/14 19:41:37 INFO Executor: Finished task 154.0 in stage 10.0 (TID 506). 5776 bytes result sent to driver
[2024-12-14T19:41:37.773+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 175.0 in stage 10.0 (TID 520)
[2024-12-14T19:41:37.775+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 179.0 in stage 10.0 (TID 521) (localhost, executor driver, partition 179, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.777+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 181.0 in stage 10.0 (TID 522) (localhost, executor driver, partition 181, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.779+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 179.0 in stage 10.0 (TID 521)
24/12/14 19:41:37 INFO TaskSetManager: Finished task 151.0 in stage 10.0 (TID 504) in 115 ms on localhost (executor driver) (97/200)
24/12/14 19:41:37 INFO TaskSetManager: Finished task 161.0 in stage 10.0 (TID 509) in 78 ms on localhost (executor driver) (98/200)
[2024-12-14T19:41:37.782+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 184.0 in stage 10.0 (TID 523) (localhost, executor driver, partition 184, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.784+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 181.0 in stage 10.0 (TID 522)
[2024-12-14T19:41:37.787+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 186.0 in stage 10.0 (TID 524) (localhost, executor driver, partition 186, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.789+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.794+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2024-12-14T19:41:37.796+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 162.0 in stage 10.0 (TID 510) in 80 ms on localhost (executor driver) (99/200)
[2024-12-14T19:41:37.798+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.800+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 184.0 in stage 10.0 (TID 523)
[2024-12-14T19:41:37.802+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.804+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 152.0 in stage 10.0 (TID 505) in 118 ms on localhost (executor driver) (100/200)
[2024-12-14T19:41:37.806+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 186.0 in stage 10.0 (TID 524)
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.808+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2024-12-14T19:41:37.810+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.811+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2024-12-14T19:41:37.813+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.815+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 148.0 in stage 10.0 (TID 501) in 141 ms on localhost (executor driver) (101/200)
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2024-12-14T19:41:37.818+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.819+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.821+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2024-12-14T19:41:37.823+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2024-12-14T19:41:37.825+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 192.0 in stage 10.0 (TID 525) (localhost, executor driver, partition 192, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.828+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO Executor: Running task 192.0 in stage 10.0 (TID 525)
24/12/14 19:41:37 INFO Executor: Finished task 168.0 in stage 10.0 (TID 514). 5776 bytes result sent to driver
[2024-12-14T19:41:37.834+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 194.0 in stage 10.0 (TID 526) (localhost, executor driver, partition 194, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.836+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.838+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:37.840+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 194.0 in stage 10.0 (TID 526)
24/12/14 19:41:37 INFO Executor: Finished task 167.0 in stage 10.0 (TID 513). 5776 bytes result sent to driver
[2024-12-14T19:41:37.842+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 195.0 in stage 10.0 (TID 527) (localhost, executor driver, partition 195, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.846+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
24/12/14 19:41:37 INFO TaskSetManager: Finished task 164.0 in stage 10.0 (TID 511) in 118 ms on localhost (executor driver) (102/200)
24/12/14 19:41:37 INFO Executor: Finished task 184.0 in stage 10.0 (TID 523). 5776 bytes result sent to driver
24/12/14 19:41:37 INFO TaskSetManager: Finished task 159.0 in stage 10.0 (TID 508) in 127 ms on localhost (executor driver) (103/200)
24/12/14 19:41:37 INFO Executor: Running task 195.0 in stage 10.0 (TID 527)
[2024-12-14T19:41:37.848+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 170.0 in stage 10.0 (TID 515) in 87 ms on localhost (executor driver) (104/200)
[2024-12-14T19:41:37.850+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.851+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO Executor: Finished task 171.0 in stage 10.0 (TID 516). 5776 bytes result sent to driver
[2024-12-14T19:41:37.854+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 165.0 in stage 10.0 (TID 512) in 116 ms on localhost (executor driver) (105/200)
[2024-12-14T19:41:37.856+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 186.0 in stage 10.0 (TID 524). 5776 bytes result sent to driver
[2024-12-14T19:41:37.857+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 196.0 in stage 10.0 (TID 528) (localhost, executor driver, partition 196, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.860+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 196.0 in stage 10.0 (TID 528)
24/12/14 19:41:37 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 529) (localhost, executor driver, partition 1, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO Executor: Running task 1.0 in stage 10.0 (TID 529)
24/12/14 19:41:37 INFO Executor: Finished task 172.0 in stage 10.0 (TID 517). 5776 bytes result sent to driver
[2024-12-14T19:41:37.862+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 530) (localhost, executor driver, partition 2, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.864+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 168.0 in stage 10.0 (TID 514) in 109 ms on localhost (executor driver) (106/200)
24/12/14 19:41:37 INFO Executor: Running task 2.0 in stage 10.0 (TID 530)
24/12/14 19:41:37 INFO TaskSetManager: Finished task 154.0 in stage 10.0 (TID 506) in 147 ms on localhost (executor driver) (107/200)
24/12/14 19:41:37 INFO TaskSetManager: Starting task 10.0 in stage 10.0 (TID 531) (localhost, executor driver, partition 10, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.865+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 11.0 in stage 10.0 (TID 532) (localhost, executor driver, partition 11, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO Executor: Running task 11.0 in stage 10.0 (TID 532)
24/12/14 19:41:37 INFO Executor: Running task 10.0 in stage 10.0 (TID 531)
[2024-12-14T19:41:37.867+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.869+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.871+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2024-12-14T19:41:37.878+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 13.0 in stage 10.0 (TID 533) (localhost, executor driver, partition 13, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.880+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 171.0 in stage 10.0 (TID 516) in 102 ms on localhost (executor driver) (108/200)
[2024-12-14T19:41:37.884+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 15.0 in stage 10.0 (TID 534) (localhost, executor driver, partition 15, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO Executor: Running task 13.0 in stage 10.0 (TID 533)
[2024-12-14T19:41:37.890+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 173.0 in stage 10.0 (TID 518). 5776 bytes result sent to driver
24/12/14 19:41:37 INFO Executor: Finished task 192.0 in stage 10.0 (TID 525). 5776 bytes result sent to driver
[2024-12-14T19:41:37.891+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 15.0 in stage 10.0 (TID 534)
[2024-12-14T19:41:37.894+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 181.0 in stage 10.0 (TID 522). 5776 bytes result sent to driver
[2024-12-14T19:41:37.897+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.901+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.904+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 179.0 in stage 10.0 (TID 521). 5776 bytes result sent to driver
[2024-12-14T19:41:37.906+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 17.0 in stage 10.0 (TID 535) (localhost, executor driver, partition 17, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO Executor: Finished task 1.0 in stage 10.0 (TID 529). 5776 bytes result sent to driver
[2024-12-14T19:41:37.912+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 184.0 in stage 10.0 (TID 523) in 83 ms on localhost (executor driver) (109/200)
[2024-12-14T19:41:37.915+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 167.0 in stage 10.0 (TID 513) in 143 ms on localhost (executor driver) (110/200)
[2024-12-14T19:41:37.919+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 174.0 in stage 10.0 (TID 519). 5776 bytes result sent to driver
24/12/14 19:41:37 INFO Executor: Finished task 175.0 in stage 10.0 (TID 520). 5819 bytes result sent to driver
[2024-12-14T19:41:37.924+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 172.0 in stage 10.0 (TID 517) in 108 ms on localhost (executor driver) (111/200)
[2024-12-14T19:41:37.929+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 186.0 in stage 10.0 (TID 524) in 88 ms on localhost (executor driver) (112/200)
[2024-12-14T19:41:37.934+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.936+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:37.939+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 18.0 in stage 10.0 (TID 536) (localhost, executor driver, partition 18, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.940+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 18.0 in stage 10.0 (TID 536)
[2024-12-14T19:41:37.945+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 20.0 in stage 10.0 (TID 537) (localhost, executor driver, partition 20, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.947+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 21.0 in stage 10.0 (TID 538) (localhost, executor driver, partition 21, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO Executor: Running task 17.0 in stage 10.0 (TID 535)
24/12/14 19:41:37 INFO Executor: Finished task 196.0 in stage 10.0 (TID 528). 5776 bytes result sent to driver
[2024-12-14T19:41:37.949+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 21.0 in stage 10.0 (TID 538)
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.950+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.954+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 20.0 in stage 10.0 (TID 537)
[2024-12-14T19:41:37.957+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.959+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.961+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 23.0 in stage 10.0 (TID 539) (localhost, executor driver, partition 23, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.966+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 23.0 in stage 10.0 (TID 539)
[2024-12-14T19:41:37.971+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 195.0 in stage 10.0 (TID 527). 5819 bytes result sent to driver
[2024-12-14T19:41:37.973+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 194.0 in stage 10.0 (TID 526). 5819 bytes result sent to driver
[2024-12-14T19:41:37.977+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.979+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.981+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.985+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.988+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO Executor: Finished task 2.0 in stage 10.0 (TID 530). 5819 bytes result sent to driver
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:37.991+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:37.993+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2024-12-14T19:41:37.995+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 24.0 in stage 10.0 (TID 540) (localhost, executor driver, partition 24, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:37.997+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 192.0 in stage 10.0 (TID 525) in 108 ms on localhost (executor driver) (113/200)
[2024-12-14T19:41:37.999+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 529) in 74 ms on localhost (executor driver) (114/200)
[2024-12-14T19:41:38.001+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.002+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:38.004+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 24.0 in stage 10.0 (TID 540)
[2024-12-14T19:41:38.006+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 181.0 in stage 10.0 (TID 522) in 134 ms on localhost (executor driver) (115/200)
[2024-12-14T19:41:38.011+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 21.0 in stage 10.0 (TID 538). 5776 bytes result sent to driver
24/12/14 19:41:37 INFO Executor: Finished task 13.0 in stage 10.0 (TID 533). 5776 bytes result sent to driver
24/12/14 19:41:37 INFO Executor: Finished task 23.0 in stage 10.0 (TID 539). 5776 bytes result sent to driver
[2024-12-14T19:41:38.013+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 179.0 in stage 10.0 (TID 521) in 142 ms on localhost (executor driver) (116/200)
[2024-12-14T19:41:38.015+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 27.0 in stage 10.0 (TID 541) (localhost, executor driver, partition 27, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.016+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 174.0 in stage 10.0 (TID 519) in 151 ms on localhost (executor driver) (117/200)
24/12/14 19:41:37 INFO TaskSetManager: Finished task 173.0 in stage 10.0 (TID 518) in 157 ms on localhost (executor driver) (118/200)
24/12/14 19:41:37 INFO Executor: Running task 27.0 in stage 10.0 (TID 541)
[2024-12-14T19:41:38.017+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 28.0 in stage 10.0 (TID 542) (localhost, executor driver, partition 28, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO Executor: Finished task 11.0 in stage 10.0 (TID 532). 5776 bytes result sent to driver
[2024-12-14T19:41:38.019+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 196.0 in stage 10.0 (TID 528) in 92 ms on localhost (executor driver) (119/200)
24/12/14 19:41:37 INFO Executor: Running task 28.0 in stage 10.0 (TID 542)
[2024-12-14T19:41:38.021+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 30.0 in stage 10.0 (TID 543) (localhost, executor driver, partition 30, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.023+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 10.0 in stage 10.0 (TID 531). 5776 bytes result sent to driver
[2024-12-14T19:41:38.024+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 18.0 in stage 10.0 (TID 536). 5776 bytes result sent to driver
[2024-12-14T19:41:38.025+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 175.0 in stage 10.0 (TID 520) in 156 ms on localhost (executor driver) (120/200)
[2024-12-14T19:41:38.026+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 30.0 in stage 10.0 (TID 543)
[2024-12-14T19:41:38.030+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO Executor: Finished task 20.0 in stage 10.0 (TID 537). 5776 bytes result sent to driver
24/12/14 19:41:37 INFO Executor: Finished task 17.0 in stage 10.0 (TID 535). 5776 bytes result sent to driver
[2024-12-14T19:41:38.031+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 15.0 in stage 10.0 (TID 534). 5776 bytes result sent to driver
[2024-12-14T19:41:38.033+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 33.0 in stage 10.0 (TID 544) (localhost, executor driver, partition 33, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.034+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 33.0 in stage 10.0 (TID 544)
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO TaskSetManager: Starting task 36.0 in stage 10.0 (TID 545) (localhost, executor driver, partition 36, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.036+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 36.0 in stage 10.0 (TID 545)
[2024-12-14T19:41:38.037+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 37.0 in stage 10.0 (TID 546) (localhost, executor driver, partition 37, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.038+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 37.0 in stage 10.0 (TID 546)
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO TaskSetManager: Starting task 38.0 in stage 10.0 (TID 547) (localhost, executor driver, partition 38, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:38.040+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 41.0 in stage 10.0 (TID 548) (localhost, executor driver, partition 41, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.041+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 38.0 in stage 10.0 (TID 547)
[2024-12-14T19:41:38.043+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 41.0 in stage 10.0 (TID 548)
[2024-12-14T19:41:38.044+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 44.0 in stage 10.0 (TID 549) (localhost, executor driver, partition 44, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.048+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 45.0 in stage 10.0 (TID 550) (localhost, executor driver, partition 45, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.052+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.053+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2024-12-14T19:41:38.055+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 44.0 in stage 10.0 (TID 549)
[2024-12-14T19:41:38.056+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.058+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 55.0 in stage 10.0 (TID 551) (localhost, executor driver, partition 55, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:38.059+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 195.0 in stage 10.0 (TID 527) in 134 ms on localhost (executor driver) (121/200)
24/12/14 19:41:37 INFO Executor: Running task 45.0 in stage 10.0 (TID 550)
24/12/14 19:41:37 INFO Executor: Finished task 27.0 in stage 10.0 (TID 541). 5776 bytes result sent to driver
[2024-12-14T19:41:38.060+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 55.0 in stage 10.0 (TID 551)
[2024-12-14T19:41:38.062+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 28.0 in stage 10.0 (TID 542). 5776 bytes result sent to driver
24/12/14 19:41:37 INFO TaskSetManager: Finished task 21.0 in stage 10.0 (TID 538) in 81 ms on localhost (executor driver) (122/200)
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.064+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 24.0 in stage 10.0 (TID 540). 5776 bytes result sent to driver
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:38.066+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 13.0 in stage 10.0 (TID 533) in 109 ms on localhost (executor driver) (123/200)
[2024-12-14T19:41:38.068+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 11.0 in stage 10.0 (TID 532) in 118 ms on localhost (executor driver) (124/200)
[2024-12-14T19:41:38.069+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 10.0 in stage 10.0 (TID 531) in 120 ms on localhost (executor driver) (125/200)
24/12/14 19:41:37 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 530) in 124 ms on localhost (executor driver) (126/200)
24/12/14 19:41:37 INFO TaskSetManager: Finished task 194.0 in stage 10.0 (TID 526) in 152 ms on localhost (executor driver) (127/200)
24/12/14 19:41:37 INFO TaskSetManager: Starting task 56.0 in stage 10.0 (TID 552) (localhost, executor driver, partition 56, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO Executor: Running task 56.0 in stage 10.0 (TID 552)
24/12/14 19:41:37 INFO Executor: Finished task 36.0 in stage 10.0 (TID 545). 5776 bytes result sent to driver
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.072+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.073+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:38.075+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 58.0 in stage 10.0 (TID 553) (localhost, executor driver, partition 58, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.076+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:38.076+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 58.0 in stage 10.0 (TID 553)
[2024-12-14T19:41:38.077+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.078+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 65.0 in stage 10.0 (TID 554) (localhost, executor driver, partition 65, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.078+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.079+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2024-12-14T19:41:38.080+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 65.0 in stage 10.0 (TID 554)
[2024-12-14T19:41:38.081+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 23.0 in stage 10.0 (TID 539) in 87 ms on localhost (executor driver) (128/200)
[2024-12-14T19:41:38.082+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 30.0 in stage 10.0 (TID 543). 5776 bytes result sent to driver
[2024-12-14T19:41:38.083+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.085+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:38.086+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO Executor: Finished task 33.0 in stage 10.0 (TID 544). 5776 bytes result sent to driver
24/12/14 19:41:37 INFO TaskSetManager: Finished task 17.0 in stage 10.0 (TID 535) in 121 ms on localhost (executor driver) (129/200)
[2024-12-14T19:41:38.088+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 18.0 in stage 10.0 (TID 536) in 106 ms on localhost (executor driver) (130/200)
[2024-12-14T19:41:38.090+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO TaskSetManager: Starting task 66.0 in stage 10.0 (TID 555) (localhost, executor driver, partition 66, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.091+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 67.0 in stage 10.0 (TID 556) (localhost, executor driver, partition 67, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.093+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 87.0 in stage 10.0 (TID 557) (localhost, executor driver, partition 87, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.094+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 15.0 in stage 10.0 (TID 534) in 129 ms on localhost (executor driver) (131/200)
24/12/14 19:41:37 INFO TaskSetManager: Finished task 20.0 in stage 10.0 (TID 537) in 108 ms on localhost (executor driver) (132/200)
[2024-12-14T19:41:38.095+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 66.0 in stage 10.0 (TID 555)
24/12/14 19:41:37 INFO TaskSetManager: Finished task 27.0 in stage 10.0 (TID 541) in 64 ms on localhost (executor driver) (133/200)
[2024-12-14T19:41:38.096+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.097+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:38.097+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 37.0 in stage 10.0 (TID 546). 5819 bytes result sent to driver
[2024-12-14T19:41:38.098+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 28.0 in stage 10.0 (TID 542) in 62 ms on localhost (executor driver) (134/200)
[2024-12-14T19:41:38.099+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO Executor: Running task 67.0 in stage 10.0 (TID 556)
[2024-12-14T19:41:38.100+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 55.0 in stage 10.0 (TID 551). 5776 bytes result sent to driver
[2024-12-14T19:41:38.101+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 91.0 in stage 10.0 (TID 558) (localhost, executor driver, partition 91, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.102+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 41.0 in stage 10.0 (TID 548). 5776 bytes result sent to driver
[2024-12-14T19:41:38.102+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 87.0 in stage 10.0 (TID 557)
[2024-12-14T19:41:38.103+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.104+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:38.105+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 91.0 in stage 10.0 (TID 558)
[2024-12-14T19:41:38.105+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 38.0 in stage 10.0 (TID 547). 5776 bytes result sent to driver
[2024-12-14T19:41:38.106+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 93.0 in stage 10.0 (TID 559) (localhost, executor driver, partition 93, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.107+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 58.0 in stage 10.0 (TID 553). 5776 bytes result sent to driver
[2024-12-14T19:41:38.108+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 93.0 in stage 10.0 (TID 559)
24/12/14 19:41:37 INFO TaskSetManager: Starting task 94.0 in stage 10.0 (TID 560) (localhost, executor driver, partition 94, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.108+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.109+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO Executor: Finished task 45.0 in stage 10.0 (TID 550). 5776 bytes result sent to driver
24/12/14 19:41:37 INFO Executor: Finished task 44.0 in stage 10.0 (TID 549). 5776 bytes result sent to driver
24/12/14 19:41:37 INFO Executor: Finished task 56.0 in stage 10.0 (TID 552). 5776 bytes result sent to driver
24/12/14 19:41:37 INFO TaskSetManager: Starting task 107.0 in stage 10.0 (TID 561) (localhost, executor driver, partition 107, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO Executor: Running task 94.0 in stage 10.0 (TID 560)
[2024-12-14T19:41:38.109+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 24.0 in stage 10.0 (TID 540) in 117 ms on localhost (executor driver) (135/200)
24/12/14 19:41:37 INFO TaskSetManager: Finished task 36.0 in stage 10.0 (TID 545) in 69 ms on localhost (executor driver) (136/200)
[2024-12-14T19:41:38.110+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 33.0 in stage 10.0 (TID 544) in 70 ms on localhost (executor driver) (137/200)
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO Executor: Running task 107.0 in stage 10.0 (TID 561)
24/12/14 19:41:37 INFO TaskSetManager: Starting task 110.0 in stage 10.0 (TID 562) (localhost, executor driver, partition 110, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO TaskSetManager: Finished task 30.0 in stage 10.0 (TID 543) in 81 ms on localhost (executor driver) (138/200)
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO Executor: Running task 110.0 in stage 10.0 (TID 562)
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/12/14 19:41:37 INFO TaskSetManager: Finished task 37.0 in stage 10.0 (TID 546) in 70 ms on localhost (executor driver) (139/200)
[2024-12-14T19:41:38.110+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 65.0 in stage 10.0 (TID 554). 5776 bytes result sent to driver
[2024-12-14T19:41:38.111+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 112.0 in stage 10.0 (TID 563) (localhost, executor driver, partition 112, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.111+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:38.112+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 66.0 in stage 10.0 (TID 555). 5776 bytes result sent to driver
[2024-12-14T19:41:38.112+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 114.0 in stage 10.0 (TID 564) (localhost, executor driver, partition 114, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.113+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 114.0 in stage 10.0 (TID 564)
[2024-12-14T19:41:38.113+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 55.0 in stage 10.0 (TID 551) in 65 ms on localhost (executor driver) (140/200)
[2024-12-14T19:41:38.114+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 112.0 in stage 10.0 (TID 563)
[2024-12-14T19:41:38.116+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 41.0 in stage 10.0 (TID 548) in 75 ms on localhost (executor driver) (141/200)
[2024-12-14T19:41:38.117+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.118+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO Executor: Finished task 91.0 in stage 10.0 (TID 558). 5819 bytes result sent to driver
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:38.119+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 115.0 in stage 10.0 (TID 565) (localhost, executor driver, partition 115, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.120+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 116.0 in stage 10.0 (TID 566) (localhost, executor driver, partition 116, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.120+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 38.0 in stage 10.0 (TID 547) in 85 ms on localhost (executor driver) (142/200)
[2024-12-14T19:41:38.121+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 115.0 in stage 10.0 (TID 565)
24/12/14 19:41:37 INFO TaskSetManager: Finished task 58.0 in stage 10.0 (TID 553) in 60 ms on localhost (executor driver) (143/200)
[2024-12-14T19:41:38.121+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 117.0 in stage 10.0 (TID 567) (localhost, executor driver, partition 117, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.122+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 117.0 in stage 10.0 (TID 567)
[2024-12-14T19:41:38.122+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.123+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:37 INFO Executor: Running task 116.0 in stage 10.0 (TID 566)
[2024-12-14T19:41:38.123+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.124+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:38.124+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 67.0 in stage 10.0 (TID 556). 5819 bytes result sent to driver
[2024-12-14T19:41:38.125+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 118.0 in stage 10.0 (TID 568) (localhost, executor driver, partition 118, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.125+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 118.0 in stage 10.0 (TID 568)
[2024-12-14T19:41:38.126+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 119.0 in stage 10.0 (TID 569) (localhost, executor driver, partition 119, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO TaskSetManager: Finished task 45.0 in stage 10.0 (TID 550) in 92 ms on localhost (executor driver) (144/200)
[2024-12-14T19:41:38.126+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 119.0 in stage 10.0 (TID 569)
[2024-12-14T19:41:38.127+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 121.0 in stage 10.0 (TID 570) (localhost, executor driver, partition 121, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.128+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 44.0 in stage 10.0 (TID 549) in 114 ms on localhost (executor driver) (145/200)
[2024-12-14T19:41:38.129+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 65.0 in stage 10.0 (TID 554) in 88 ms on localhost (executor driver) (146/200)
24/12/14 19:41:37 INFO Executor: Finished task 110.0 in stage 10.0 (TID 562). 5862 bytes result sent to driver
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:38.131+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 122.0 in stage 10.0 (TID 571) (localhost, executor driver, partition 122, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.132+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 126.0 in stage 10.0 (TID 572) (localhost, executor driver, partition 126, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.133+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 121.0 in stage 10.0 (TID 570)
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO Executor: Running task 126.0 in stage 10.0 (TID 572)
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO TaskSetManager: Finished task 91.0 in stage 10.0 (TID 558) in 71 ms on localhost (executor driver) (147/200)
[2024-12-14T19:41:38.135+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 66.0 in stage 10.0 (TID 555) in 84 ms on localhost (executor driver) (148/200)
24/12/14 19:41:37 INFO Executor: Running task 122.0 in stage 10.0 (TID 571)
[2024-12-14T19:41:38.136+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 128.0 in stage 10.0 (TID 573) (localhost, executor driver, partition 128, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO TaskSetManager: Starting task 131.0 in stage 10.0 (TID 574) (localhost, executor driver, partition 131, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.137+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 56.0 in stage 10.0 (TID 552) in 103 ms on localhost (executor driver) (149/200)
[2024-12-14T19:41:38.138+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 67.0 in stage 10.0 (TID 556) in 88 ms on localhost (executor driver) (150/200)
[2024-12-14T19:41:38.139+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 128.0 in stage 10.0 (TID 573)
24/12/14 19:41:37 INFO TaskSetManager: Finished task 110.0 in stage 10.0 (TID 562) in 62 ms on localhost (executor driver) (151/200)
[2024-12-14T19:41:38.141+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 93.0 in stage 10.0 (TID 559). 5819 bytes result sent to driver
[2024-12-14T19:41:38.142+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 107.0 in stage 10.0 (TID 561). 5819 bytes result sent to driver
[2024-12-14T19:41:38.144+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 112.0 in stage 10.0 (TID 563). 5819 bytes result sent to driver
[2024-12-14T19:41:38.145+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 131.0 in stage 10.0 (TID 574)
[2024-12-14T19:41:38.146+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 87.0 in stage 10.0 (TID 557). 5819 bytes result sent to driver
24/12/14 19:41:37 INFO Executor: Finished task 94.0 in stage 10.0 (TID 560). 5819 bytes result sent to driver
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO TaskSetManager: Starting task 133.0 in stage 10.0 (TID 575) (localhost, executor driver, partition 133, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.147+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 133.0 in stage 10.0 (TID 575)
24/12/14 19:41:37 INFO TaskSetManager: Starting task 134.0 in stage 10.0 (TID 576) (localhost, executor driver, partition 134, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.149+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 134.0 in stage 10.0 (TID 576)
[2024-12-14T19:41:38.150+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 138.0 in stage 10.0 (TID 577) (localhost, executor driver, partition 138, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO Executor: Running task 138.0 in stage 10.0 (TID 577)
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2024-12-14T19:41:38.151+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 139.0 in stage 10.0 (TID 578) (localhost, executor driver, partition 139, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.152+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 115.0 in stage 10.0 (TID 565). 5819 bytes result sent to driver
[2024-12-14T19:41:38.154+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 139.0 in stage 10.0 (TID 578)
24/12/14 19:41:37 INFO TaskSetManager: Finished task 112.0 in stage 10.0 (TID 563) in 78 ms on localhost (executor driver) (152/200)
24/12/14 19:41:37 INFO TaskSetManager: Finished task 107.0 in stage 10.0 (TID 561) in 92 ms on localhost (executor driver) (153/200)
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO TaskSetManager: Finished task 93.0 in stage 10.0 (TID 559) in 95 ms on localhost (executor driver) (154/200)
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
24/12/14 19:41:37 INFO TaskSetManager: Finished task 87.0 in stage 10.0 (TID 557) in 111 ms on localhost (executor driver) (155/200)
[2024-12-14T19:41:38.155+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 140.0 in stage 10.0 (TID 579) (localhost, executor driver, partition 140, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.156+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:38.157+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 141.0 in stage 10.0 (TID 580) (localhost, executor driver, partition 141, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.158+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.158+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO Executor: Finished task 118.0 in stage 10.0 (TID 568). 5862 bytes result sent to driver
24/12/14 19:41:37 INFO Executor: Running task 140.0 in stage 10.0 (TID 579)
[2024-12-14T19:41:38.159+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
24/12/14 19:41:37 INFO Executor: Running task 141.0 in stage 10.0 (TID 580)
[2024-12-14T19:41:38.161+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.162+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO Executor: Finished task 114.0 in stage 10.0 (TID 564). 5862 bytes result sent to driver
[2024-12-14T19:41:38.163+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 143.0 in stage 10.0 (TID 581) (localhost, executor driver, partition 143, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.164+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.165+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 143.0 in stage 10.0 (TID 581)
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.166+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO TaskSetManager: Starting task 144.0 in stage 10.0 (TID 582) (localhost, executor driver, partition 144, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.167+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2024-12-14T19:41:38.168+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.169+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 94.0 in stage 10.0 (TID 560) in 114 ms on localhost (executor driver) (156/200)
[2024-12-14T19:41:38.170+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:38.171+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.172+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2024-12-14T19:41:38.173+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 118.0 in stage 10.0 (TID 568) in 84 ms on localhost (executor driver) (157/200)
24/12/14 19:41:37 INFO Executor: Finished task 116.0 in stage 10.0 (TID 566). 5819 bytes result sent to driver
24/12/14 19:41:37 INFO Executor: Running task 144.0 in stage 10.0 (TID 582)
[2024-12-14T19:41:38.174+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO Executor: Finished task 117.0 in stage 10.0 (TID 567). 5819 bytes result sent to driver
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
[2024-12-14T19:41:38.175+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.176+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2024-12-14T19:41:38.177+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2024-12-14T19:41:38.178+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 131.0 in stage 10.0 (TID 574). 5819 bytes result sent to driver
[2024-12-14T19:41:38.178+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 128.0 in stage 10.0 (TID 573). 5819 bytes result sent to driver
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.179+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 126.0 in stage 10.0 (TID 572). 5776 bytes result sent to driver
[2024-12-14T19:41:38.180+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:38.181+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 147.0 in stage 10.0 (TID 583) (localhost, executor driver, partition 147, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.182+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 119.0 in stage 10.0 (TID 569). 5819 bytes result sent to driver
[2024-12-14T19:41:38.184+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 114.0 in stage 10.0 (TID 564) in 127 ms on localhost (executor driver) (158/200)
[2024-12-14T19:41:38.186+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 115.0 in stage 10.0 (TID 565) in 121 ms on localhost (executor driver) (159/200)
24/12/14 19:41:37 INFO Executor: Running task 147.0 in stage 10.0 (TID 583)
[2024-12-14T19:41:38.188+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.189+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:38.191+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 153.0 in stage 10.0 (TID 584) (localhost, executor driver, partition 153, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.192+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 138.0 in stage 10.0 (TID 577). 5819 bytes result sent to driver
[2024-12-14T19:41:38.194+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 116.0 in stage 10.0 (TID 566) in 125 ms on localhost (executor driver) (160/200)
[2024-12-14T19:41:38.195+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 121.0 in stage 10.0 (TID 570). 5819 bytes result sent to driver
24/12/14 19:41:37 INFO Executor: Finished task 139.0 in stage 10.0 (TID 578). 5819 bytes result sent to driver
[2024-12-14T19:41:38.198+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 153.0 in stage 10.0 (TID 584)
[2024-12-14T19:41:38.199+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:38.201+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 122.0 in stage 10.0 (TID 571). 5819 bytes result sent to driver
[2024-12-14T19:41:38.202+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 140.0 in stage 10.0 (TID 579). 5819 bytes result sent to driver
[2024-12-14T19:41:38.203+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 155.0 in stage 10.0 (TID 585) (localhost, executor driver, partition 155, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.204+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:38.205+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 117.0 in stage 10.0 (TID 567) in 130 ms on localhost (executor driver) (161/200)
[2024-12-14T19:41:38.206+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 131.0 in stage 10.0 (TID 574) in 97 ms on localhost (executor driver) (162/200)
24/12/14 19:41:37 INFO Executor: Running task 155.0 in stage 10.0 (TID 585)
24/12/14 19:41:37 INFO Executor: Finished task 134.0 in stage 10.0 (TID 576). 5819 bytes result sent to driver
24/12/14 19:41:37 INFO Executor: Finished task 144.0 in stage 10.0 (TID 582). 5819 bytes result sent to driver
24/12/14 19:41:37 INFO Executor: Finished task 133.0 in stage 10.0 (TID 575). 5819 bytes result sent to driver
[2024-12-14T19:41:38.207+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 143.0 in stage 10.0 (TID 581). 5862 bytes result sent to driver
[2024-12-14T19:41:38.208+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 156.0 in stage 10.0 (TID 586) (localhost, executor driver, partition 156, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO Executor: Finished task 147.0 in stage 10.0 (TID 583). 5776 bytes result sent to driver
[2024-12-14T19:41:38.208+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:38.209+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 156.0 in stage 10.0 (TID 586)
[2024-12-14T19:41:38.210+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 157.0 in stage 10.0 (TID 587) (localhost, executor driver, partition 157, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.210+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 157.0 in stage 10.0 (TID 587)
[2024-12-14T19:41:38.211+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 160.0 in stage 10.0 (TID 588) (localhost, executor driver, partition 160, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO Executor: Finished task 141.0 in stage 10.0 (TID 580). 5862 bytes result sent to driver
[2024-12-14T19:41:38.212+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 128.0 in stage 10.0 (TID 573) in 130 ms on localhost (executor driver) (163/200)
24/12/14 19:41:37 INFO Executor: Running task 160.0 in stage 10.0 (TID 588)
[2024-12-14T19:41:38.212+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 126.0 in stage 10.0 (TID 572) in 135 ms on localhost (executor driver) (164/200)
[2024-12-14T19:41:38.213+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 163.0 in stage 10.0 (TID 589) (localhost, executor driver, partition 163, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.214+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.216+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 163.0 in stage 10.0 (TID 589)
24/12/14 19:41:37 INFO TaskSetManager: Starting task 166.0 in stage 10.0 (TID 590) (localhost, executor driver, partition 166, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.217+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2024-12-14T19:41:38.218+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 119.0 in stage 10.0 (TID 569) in 159 ms on localhost (executor driver) (165/200)
[2024-12-14T19:41:38.219+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 138.0 in stage 10.0 (TID 577) in 120 ms on localhost (executor driver) (166/200)
[2024-12-14T19:41:38.220+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 121.0 in stage 10.0 (TID 570) in 158 ms on localhost (executor driver) (167/200)
[2024-12-14T19:41:38.221+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 166.0 in stage 10.0 (TID 590)
[2024-12-14T19:41:38.222+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.223+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:38.225+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 169.0 in stage 10.0 (TID 591) (localhost, executor driver, partition 169, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.226+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 176.0 in stage 10.0 (TID 592) (localhost, executor driver, partition 176, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.227+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 169.0 in stage 10.0 (TID 591)
[2024-12-14T19:41:38.228+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.230+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO Executor: Finished task 153.0 in stage 10.0 (TID 584). 5819 bytes result sent to driver
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:38.237+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 176.0 in stage 10.0 (TID 592)
[2024-12-14T19:41:38.238+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO TaskSetManager: Starting task 177.0 in stage 10.0 (TID 593) (localhost, executor driver, partition 177, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.242+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2024-12-14T19:41:38.244+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 178.0 in stage 10.0 (TID 594) (localhost, executor driver, partition 178, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.245+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 177.0 in stage 10.0 (TID 593)
[2024-12-14T19:41:38.247+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 178.0 in stage 10.0 (TID 594)
[2024-12-14T19:41:38.248+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 157.0 in stage 10.0 (TID 587). 5862 bytes result sent to driver
[2024-12-14T19:41:38.249+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 163.0 in stage 10.0 (TID 589). 5776 bytes result sent to driver
24/12/14 19:41:37 INFO TaskSetManager: Finished task 122.0 in stage 10.0 (TID 571) in 157 ms on localhost (executor driver) (168/200)
[2024-12-14T19:41:38.251+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 160.0 in stage 10.0 (TID 588). 5776 bytes result sent to driver
[2024-12-14T19:41:38.253+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 180.0 in stage 10.0 (TID 595) (localhost, executor driver, partition 180, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO Executor: Finished task 155.0 in stage 10.0 (TID 585). 5819 bytes result sent to driver
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO TaskSetManager: Starting task 182.0 in stage 10.0 (TID 596) (localhost, executor driver, partition 182, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.254+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 166.0 in stage 10.0 (TID 590). 5776 bytes result sent to driver
[2024-12-14T19:41:38.255+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 156.0 in stage 10.0 (TID 586). 5819 bytes result sent to driver
[2024-12-14T19:41:38.256+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 180.0 in stage 10.0 (TID 595)
[2024-12-14T19:41:38.258+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 134.0 in stage 10.0 (TID 576) in 154 ms on localhost (executor driver) (169/200)
24/12/14 19:41:37 INFO Executor: Running task 182.0 in stage 10.0 (TID 596)
24/12/14 19:41:37 INFO TaskSetManager: Finished task 139.0 in stage 10.0 (TID 578) in 145 ms on localhost (executor driver) (170/200)
[2024-12-14T19:41:38.259+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 144.0 in stage 10.0 (TID 582) in 128 ms on localhost (executor driver) (171/200)
[2024-12-14T19:41:38.260+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 140.0 in stage 10.0 (TID 579) in 140 ms on localhost (executor driver) (172/200)
24/12/14 19:41:37 INFO TaskSetManager: Starting task 183.0 in stage 10.0 (TID 597) (localhost, executor driver, partition 183, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.261+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO TaskSetManager: Starting task 185.0 in stage 10.0 (TID 598) (localhost, executor driver, partition 185, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.262+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 143.0 in stage 10.0 (TID 581) in 135 ms on localhost (executor driver) (173/200)
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.263+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 147.0 in stage 10.0 (TID 583) in 112 ms on localhost (executor driver) (174/200)
[2024-12-14T19:41:38.264+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 183.0 in stage 10.0 (TID 597)
[2024-12-14T19:41:38.266+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.266+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:38.267+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 176.0 in stage 10.0 (TID 592). 5776 bytes result sent to driver
[2024-12-14T19:41:38.268+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 185.0 in stage 10.0 (TID 598)
[2024-12-14T19:41:38.269+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO TaskSetManager: Starting task 187.0 in stage 10.0 (TID 599) (localhost, executor driver, partition 187, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:38.270+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 187.0 in stage 10.0 (TID 599)
[2024-12-14T19:41:38.272+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 188.0 in stage 10.0 (TID 600) (localhost, executor driver, partition 188, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO Executor: Running task 188.0 in stage 10.0 (TID 600)
[2024-12-14T19:41:38.273+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 189.0 in stage 10.0 (TID 601) (localhost, executor driver, partition 189, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.274+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.275+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO TaskSetManager: Finished task 133.0 in stage 10.0 (TID 575) in 181 ms on localhost (executor driver) (175/200)
24/12/14 19:41:37 INFO Executor: Finished task 178.0 in stage 10.0 (TID 594). 5776 bytes result sent to driver
24/12/14 19:41:37 INFO TaskSetManager: Finished task 153.0 in stage 10.0 (TID 584) in 113 ms on localhost (executor driver) (176/200)
24/12/14 19:41:37 INFO Executor: Finished task 180.0 in stage 10.0 (TID 595). 5776 bytes result sent to driver
[2024-12-14T19:41:38.277+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 141.0 in stage 10.0 (TID 580) in 165 ms on localhost (executor driver) (177/200)
24/12/14 19:41:37 INFO TaskSetManager: Finished task 157.0 in stage 10.0 (TID 587) in 92 ms on localhost (executor driver) (178/200)
[2024-12-14T19:41:38.278+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 189.0 in stage 10.0 (TID 601)
24/12/14 19:41:37 INFO Executor: Finished task 169.0 in stage 10.0 (TID 591). 5776 bytes result sent to driver
24/12/14 19:41:37 INFO TaskSetManager: Starting task 190.0 in stage 10.0 (TID 602) (localhost, executor driver, partition 190, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO Executor: Running task 190.0 in stage 10.0 (TID 602)
24/12/14 19:41:37 INFO TaskSetManager: Starting task 191.0 in stage 10.0 (TID 603) (localhost, executor driver, partition 191, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO TaskSetManager: Finished task 163.0 in stage 10.0 (TID 589) in 75 ms on localhost (executor driver) (179/200)
24/12/14 19:41:37 INFO Executor: Finished task 177.0 in stage 10.0 (TID 593). 5776 bytes result sent to driver
[2024-12-14T19:41:38.279+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 182.0 in stage 10.0 (TID 596). 5776 bytes result sent to driver
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.280+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 193.0 in stage 10.0 (TID 604) (localhost, executor driver, partition 193, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:38.281+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 191.0 in stage 10.0 (TID 603)
[2024-12-14T19:41:38.282+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.283+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:38.284+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Starting task 197.0 in stage 10.0 (TID 605) (localhost, executor driver, partition 197, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.284+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 155.0 in stage 10.0 (TID 585) in 121 ms on localhost (executor driver) (180/200)
[2024-12-14T19:41:38.285+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 166.0 in stage 10.0 (TID 590) in 85 ms on localhost (executor driver) (181/200)
[2024-12-14T19:41:38.286+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 183.0 in stage 10.0 (TID 597). 5819 bytes result sent to driver
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.287+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 197.0 in stage 10.0 (TID 605)
[2024-12-14T19:41:38.288+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:38.289+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 160.0 in stage 10.0 (TID 588) in 103 ms on localhost (executor driver) (182/200)
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:37 INFO Executor: Running task 193.0 in stage 10.0 (TID 604)
[2024-12-14T19:41:38.290+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 187.0 in stage 10.0 (TID 599). 5776 bytes result sent to driver
24/12/14 19:41:37 INFO TaskSetManager: Starting task 198.0 in stage 10.0 (TID 606) (localhost, executor driver, partition 198, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:37 INFO Executor: Running task 198.0 in stage 10.0 (TID 606)
[2024-12-14T19:41:38.290+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 185.0 in stage 10.0 (TID 598). 5776 bytes result sent to driver
[2024-12-14T19:41:38.291+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
24/12/14 19:41:37 INFO TaskSetManager: Starting task 199.0 in stage 10.0 (TID 607) (localhost, executor driver, partition 199, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.292+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 176.0 in stage 10.0 (TID 592) in 98 ms on localhost (executor driver) (183/200)
[2024-12-14T19:41:38.294+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:38.295+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Running task 199.0 in stage 10.0 (TID 607)
[2024-12-14T19:41:38.297+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 156.0 in stage 10.0 (TID 586) in 138 ms on localhost (executor driver) (184/200)
[2024-12-14T19:41:38.298+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 178.0 in stage 10.0 (TID 594) in 92 ms on localhost (executor driver) (185/200)
[2024-12-14T19:41:38.299+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 188.0 in stage 10.0 (TID 600). 5776 bytes result sent to driver
[2024-12-14T19:41:38.300+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 180.0 in stage 10.0 (TID 595) in 87 ms on localhost (executor driver) (186/200)
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:37 INFO TaskSetManager: Finished task 177.0 in stage 10.0 (TID 593) in 100 ms on localhost (executor driver) (187/200)
[2024-12-14T19:41:38.300+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 169.0 in stage 10.0 (TID 591) in 113 ms on localhost (executor driver) (188/200)
[2024-12-14T19:41:38.301+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 182.0 in stage 10.0 (TID 596) in 102 ms on localhost (executor driver) (189/200)
[2024-12-14T19:41:38.303+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 183.0 in stage 10.0 (TID 597) in 97 ms on localhost (executor driver) (190/200)
[2024-12-14T19:41:38.304+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 188.0 in stage 10.0 (TID 600) in 85 ms on localhost (executor driver) (191/200)
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.305+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 189.0 in stage 10.0 (TID 601). 5776 bytes result sent to driver
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:38.306+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 190.0 in stage 10.0 (TID 602). 5776 bytes result sent to driver
[2024-12-14T19:41:38.307+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 197.0 in stage 10.0 (TID 605). 5776 bytes result sent to driver
[2024-12-14T19:41:38.309+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:37 INFO TaskSetManager: Finished task 187.0 in stage 10.0 (TID 599) in 95 ms on localhost (executor driver) (192/200)
24/12/14 19:41:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:38.310+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 185.0 in stage 10.0 (TID 598) in 104 ms on localhost (executor driver) (193/200)
[2024-12-14T19:41:38.311+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 191.0 in stage 10.0 (TID 603). 5776 bytes result sent to driver
[2024-12-14T19:41:38.312+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 189.0 in stage 10.0 (TID 601) in 89 ms on localhost (executor driver) (194/200)
[2024-12-14T19:41:38.313+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 197.0 in stage 10.0 (TID 605) in 66 ms on localhost (executor driver) (195/200)
[2024-12-14T19:41:38.314+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 193.0 in stage 10.0 (TID 604). 5776 bytes result sent to driver
[2024-12-14T19:41:38.315+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 193.0 in stage 10.0 (TID 604) in 75 ms on localhost (executor driver) (196/200)
[2024-12-14T19:41:38.315+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 190.0 in stage 10.0 (TID 602) in 83 ms on localhost (executor driver) (197/200)
[2024-12-14T19:41:38.317+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 191.0 in stage 10.0 (TID 603) in 82 ms on localhost (executor driver) (198/200)
[2024-12-14T19:41:38.319+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 199.0 in stage 10.0 (TID 607). 5776 bytes result sent to driver
[2024-12-14T19:41:38.320+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO Executor: Finished task 198.0 in stage 10.0 (TID 606). 5776 bytes result sent to driver
[2024-12-14T19:41:38.322+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 199.0 in stage 10.0 (TID 607) in 59 ms on localhost (executor driver) (199/200)
[2024-12-14T19:41:38.323+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSetManager: Finished task 198.0 in stage 10.0 (TID 606) in 63 ms on localhost (executor driver) (200/200)
[2024-12-14T19:41:38.324+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool
[2024-12-14T19:41:38.325+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO DAGScheduler: ShuffleMapStage 10 (start at NativeMethodAccessorImpl.java:0) finished in 1.279 s
24/12/14 19:41:37 INFO DAGScheduler: looking for newly runnable stages
24/12/14 19:41:37 INFO DAGScheduler: running: Set()
24/12/14 19:41:37 INFO DAGScheduler: waiting: Set(ResultStage 11)
[2024-12-14T19:41:38.327+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO DAGScheduler: failed: Set()
[2024-12-14T19:41:38.328+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[35] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-12-14T19:41:38.329+0000] {docker.py:413} INFO - 24/12/14 19:41:37 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 12.5 KiB, free 434.3 MiB)
[2024-12-14T19:41:38.330+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.3 MiB)
[2024-12-14T19:41:38.332+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:32963 (size: 5.9 KiB, free: 434.4 MiB)
[2024-12-14T19:41:38.333+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1580
[2024-12-14T19:41:38.334+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[35] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/12/14 19:41:38 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
[2024-12-14T19:41:38.336+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 608) (localhost, executor driver, partition 0, NODE_LOCAL, 9963 bytes)
[2024-12-14T19:41:38.337+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO Executor: Running task 0.0 in stage 11.0 (TID 608)
[2024-12-14T19:41:38.338+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Getting 200 (11.7 KiB) non-empty blocks including 200 (11.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:38.339+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO Executor: Finished task 0.0 in stage 11.0 (TID 608). 3995 bytes result sent to driver
[2024-12-14T19:41:38.340+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 608) in 32 ms on localhost (executor driver) (1/1)
[2024-12-14T19:41:38.341+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool
[2024-12-14T19:41:38.342+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO DAGScheduler: ResultStage 11 (start at NativeMethodAccessorImpl.java:0) finished in 0.048 s
[2024-12-14T19:41:38.343+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-12-14T19:41:38.344+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
[2024-12-14T19:41:38.345+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO DAGScheduler: Job 4 finished: start at NativeMethodAccessorImpl.java:0, took 2.152363 s
[2024-12-14T19:41:38.346+0000] {docker.py:413} INFO - 2024-12-14 19:41:38,047 [INFO] Transformed 180 posts
2024-12-14 19:41:38,048 [INFO] Saving posts to PostgreSQL...
[2024-12-14T19:41:38.347+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
[2024-12-14T19:41:38.348+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO DAGScheduler: Registering RDD 37 (start at NativeMethodAccessorImpl.java:0) as input to shuffle 7
[2024-12-14T19:41:38.349+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO DAGScheduler: Registering RDD 40 (start at NativeMethodAccessorImpl.java:0) as input to shuffle 8
[2024-12-14T19:41:38.350+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO DAGScheduler: Got job 5 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/12/14 19:41:38 INFO DAGScheduler: Final stage: ResultStage 14 (start at NativeMethodAccessorImpl.java:0)
24/12/14 19:41:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
[2024-12-14T19:41:38.352+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
[2024-12-14T19:41:38.354+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[37] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-12-14T19:41:38.355+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 51.8 KiB, free 434.2 MiB)
[2024-12-14T19:41:38.356+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 434.2 MiB)
[2024-12-14T19:41:38.358+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:32963 (size: 20.7 KiB, free: 434.3 MiB)
[2024-12-14T19:41:38.359+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1580
[2024-12-14T19:41:38.359+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[37] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/12/14 19:41:38 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
[2024-12-14T19:41:38.360+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 609) (localhost, executor driver, partition 0, PROCESS_LOCAL, 10838 bytes)
[2024-12-14T19:41:38.362+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO Executor: Running task 0.0 in stage 12.0 (TID 609)
[2024-12-14T19:41:38.363+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=reddit_data-0 fromOffset=0 untilOffset=650, for query queryId=380f0ba5-0895-4b92-9659-cdf82c87bac4 batchId=0 taskId=609 partitionId=0
[2024-12-14T19:41:38.365+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO KafkaConsumer: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to offset 0 for partition reddit_data-0
[2024-12-14T19:41:38.366+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to earliest offset of partition reddit_data-0
[2024-12-14T19:41:38.367+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Resetting offset for partition reddit_data-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 0 rack: null)], epoch=32}}.
[2024-12-14T19:41:38.369+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to latest offset of partition reddit_data-0
[2024-12-14T19:41:38.370+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Resetting offset for partition reddit_data-0 to position FetchPosition{offset=650, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 0 rack: null)], epoch=32}}.
[2024-12-14T19:41:38.371+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO KafkaConsumer: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to offset 500 for partition reddit_data-0
[2024-12-14T19:41:38.373+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to earliest offset of partition reddit_data-0
[2024-12-14T19:41:38.826+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Resetting offset for partition reddit_data-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 0 rack: null)], epoch=32}}.
[2024-12-14T19:41:38.828+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to latest offset of partition reddit_data-0
[2024-12-14T19:41:38.831+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Resetting offset for partition reddit_data-0 to position FetchPosition{offset=650, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 0 rack: null)], epoch=32}}.
[2024-12-14T19:41:38.870+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO KafkaDataConsumer: From Kafka topicPartition=reddit_data-0 groupId=reddit_processor_group read 650 records through 2 polls (polled  out 650 records), taking 545516366 nanos, during time span of 631212223 nanos.
[2024-12-14T19:41:38.873+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO Executor: Finished task 0.0 in stage 12.0 (TID 609). 2860 bytes result sent to driver
[2024-12-14T19:41:38.875+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 609) in 670 ms on localhost (executor driver) (1/1)
[2024-12-14T19:41:38.877+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool
[2024-12-14T19:41:38.880+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO DAGScheduler: ShuffleMapStage 12 (start at NativeMethodAccessorImpl.java:0) finished in 0.685 s
[2024-12-14T19:41:38.882+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO DAGScheduler: looking for newly runnable stages
[2024-12-14T19:41:38.883+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO DAGScheduler: running: Set()
24/12/14 19:41:38 INFO DAGScheduler: waiting: Set(ShuffleMapStage 13, ResultStage 14)
[2024-12-14T19:41:38.884+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO DAGScheduler: failed: Set()
[2024-12-14T19:41:38.885+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[40] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-12-14T19:41:38.896+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 63.8 KiB, free 434.2 MiB)
[2024-12-14T19:41:38.900+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 25.7 KiB, free 434.1 MiB)
[2024-12-14T19:41:38.902+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:32963 (size: 25.7 KiB, free: 434.3 MiB)
[2024-12-14T19:41:38.902+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1580
[2024-12-14T19:41:38.904+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO DAGScheduler: Submitting 200 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[40] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2024-12-14T19:41:38.906+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO TaskSchedulerImpl: Adding task set 13.0 with 200 tasks resource profile 0
[2024-12-14T19:41:38.910+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 610) (localhost, executor driver, partition 0, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.912+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO TaskSetManager: Starting task 3.0 in stage 13.0 (TID 611) (localhost, executor driver, partition 3, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:38 INFO TaskSetManager: Starting task 4.0 in stage 13.0 (TID 612) (localhost, executor driver, partition 4, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.914+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO TaskSetManager: Starting task 5.0 in stage 13.0 (TID 613) (localhost, executor driver, partition 5, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.918+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO TaskSetManager: Starting task 6.0 in stage 13.0 (TID 614) (localhost, executor driver, partition 6, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.924+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO TaskSetManager: Starting task 7.0 in stage 13.0 (TID 615) (localhost, executor driver, partition 7, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.929+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO TaskSetManager: Starting task 8.0 in stage 13.0 (TID 616) (localhost, executor driver, partition 8, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.934+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO TaskSetManager: Starting task 9.0 in stage 13.0 (TID 617) (localhost, executor driver, partition 9, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.937+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO TaskSetManager: Starting task 12.0 in stage 13.0 (TID 618) (localhost, executor driver, partition 12, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:38 INFO TaskSetManager: Starting task 14.0 in stage 13.0 (TID 619) (localhost, executor driver, partition 14, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.940+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO TaskSetManager: Starting task 16.0 in stage 13.0 (TID 620) (localhost, executor driver, partition 16, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.945+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO TaskSetManager: Starting task 19.0 in stage 13.0 (TID 621) (localhost, executor driver, partition 19, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.947+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO TaskSetManager: Starting task 22.0 in stage 13.0 (TID 622) (localhost, executor driver, partition 22, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.952+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO TaskSetManager: Starting task 25.0 in stage 13.0 (TID 623) (localhost, executor driver, partition 25, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.954+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO TaskSetManager: Starting task 26.0 in stage 13.0 (TID 624) (localhost, executor driver, partition 26, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.956+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO TaskSetManager: Starting task 29.0 in stage 13.0 (TID 625) (localhost, executor driver, partition 29, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:38.958+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO Executor: Running task 4.0 in stage 13.0 (TID 612)
24/12/14 19:41:38 INFO Executor: Running task 3.0 in stage 13.0 (TID 611)
24/12/14 19:41:38 INFO Executor: Running task 0.0 in stage 13.0 (TID 610)
24/12/14 19:41:38 INFO Executor: Running task 6.0 in stage 13.0 (TID 614)
[2024-12-14T19:41:38.960+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO Executor: Running task 5.0 in stage 13.0 (TID 613)
[2024-12-14T19:41:38.964+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO Executor: Running task 25.0 in stage 13.0 (TID 623)
24/12/14 19:41:38 INFO Executor: Running task 9.0 in stage 13.0 (TID 617)
24/12/14 19:41:38 INFO Executor: Running task 14.0 in stage 13.0 (TID 619)
24/12/14 19:41:38 INFO Executor: Running task 22.0 in stage 13.0 (TID 622)
24/12/14 19:41:38 INFO Executor: Running task 7.0 in stage 13.0 (TID 615)
[2024-12-14T19:41:38.966+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO Executor: Running task 12.0 in stage 13.0 (TID 618)
24/12/14 19:41:38 INFO Executor: Running task 16.0 in stage 13.0 (TID 620)
[2024-12-14T19:41:38.969+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO Executor: Running task 19.0 in stage 13.0 (TID 621)
[2024-12-14T19:41:38.971+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO Executor: Running task 8.0 in stage 13.0 (TID 616)
24/12/14 19:41:38 INFO Executor: Running task 29.0 in stage 13.0 (TID 625)
[2024-12-14T19:41:38.973+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO Executor: Running task 26.0 in stage 13.0 (TID 624)
[2024-12-14T19:41:38.975+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.982+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:38.987+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:38.988+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:38.990+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:38.996+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO Executor: Finished task 4.0 in stage 13.0 (TID 612). 5776 bytes result sent to driver
[2024-12-14T19:41:38.999+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO Executor: Finished task 19.0 in stage 13.0 (TID 621). 5776 bytes result sent to driver
24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.005+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
24/12/14 19:41:38 INFO TaskSetManager: Starting task 31.0 in stage 13.0 (TID 626) (localhost, executor driver, partition 31, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:38 INFO Executor: Finished task 12.0 in stage 13.0 (TID 618). 5776 bytes result sent to driver
[2024-12-14T19:41:39.008+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO Executor: Finished task 6.0 in stage 13.0 (TID 614). 5776 bytes result sent to driver
[2024-12-14T19:41:39.011+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:38 INFO TaskSetManager: Finished task 4.0 in stage 13.0 (TID 612) in 40 ms on localhost (executor driver) (1/200)
24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:38 INFO Executor: Finished task 29.0 in stage 13.0 (TID 625). 5776 bytes result sent to driver
24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.016+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
24/12/14 19:41:38 INFO Executor: Finished task 0.0 in stage 13.0 (TID 610). 5776 bytes result sent to driver
24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:39.019+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.021+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2024-12-14T19:41:39.031+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO Executor: Finished task 22.0 in stage 13.0 (TID 622). 5776 bytes result sent to driver
24/12/14 19:41:38 INFO TaskSetManager: Starting task 32.0 in stage 13.0 (TID 627) (localhost, executor driver, partition 32, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.039+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO Executor: Running task 32.0 in stage 13.0 (TID 627)
[2024-12-14T19:41:39.043+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO Executor: Running task 31.0 in stage 13.0 (TID 626)
[2024-12-14T19:41:39.059+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO Executor: Finished task 16.0 in stage 13.0 (TID 620). 5776 bytes result sent to driver
[2024-12-14T19:41:39.061+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO Executor: Finished task 26.0 in stage 13.0 (TID 624). 5776 bytes result sent to driver
24/12/14 19:41:38 INFO TaskSetManager: Starting task 34.0 in stage 13.0 (TID 628) (localhost, executor driver, partition 34, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.064+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO TaskSetManager: Finished task 12.0 in stage 13.0 (TID 618) in 53 ms on localhost (executor driver) (2/200)
[2024-12-14T19:41:39.069+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO TaskSetManager: Finished task 19.0 in stage 13.0 (TID 621) in 52 ms on localhost (executor driver) (3/200)
[2024-12-14T19:41:39.071+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO Executor: Finished task 14.0 in stage 13.0 (TID 619). 5776 bytes result sent to driver
[2024-12-14T19:41:39.074+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO Executor: Running task 34.0 in stage 13.0 (TID 628)
[2024-12-14T19:41:39.076+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO TaskSetManager: Starting task 35.0 in stage 13.0 (TID 629) (localhost, executor driver, partition 35, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.086+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO Executor: Finished task 9.0 in stage 13.0 (TID 617). 5776 bytes result sent to driver
[2024-12-14T19:41:39.092+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO Executor: Finished task 8.0 in stage 13.0 (TID 616). 5776 bytes result sent to driver
[2024-12-14T19:41:39.103+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO TaskSetManager: Starting task 39.0 in stage 13.0 (TID 630) (localhost, executor driver, partition 39, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.105+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO TaskSetManager: Finished task 6.0 in stage 13.0 (TID 614) in 61 ms on localhost (executor driver) (4/200)
[2024-12-14T19:41:39.108+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO Executor: Running task 35.0 in stage 13.0 (TID 629)
[2024-12-14T19:41:39.111+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO Executor: Running task 39.0 in stage 13.0 (TID 630)
[2024-12-14T19:41:39.113+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO Executor: Finished task 25.0 in stage 13.0 (TID 623). 5776 bytes result sent to driver
[2024-12-14T19:41:39.115+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO TaskSetManager: Finished task 29.0 in stage 13.0 (TID 625) in 57 ms on localhost (executor driver) (5/200)
[2024-12-14T19:41:39.118+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO TaskSetManager: Starting task 40.0 in stage 13.0 (TID 631) (localhost, executor driver, partition 40, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:38 INFO Executor: Running task 40.0 in stage 13.0 (TID 631)
24/12/14 19:41:38 INFO TaskSetManager: Starting task 42.0 in stage 13.0 (TID 632) (localhost, executor driver, partition 42, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.120+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO Executor: Finished task 7.0 in stage 13.0 (TID 615). 5819 bytes result sent to driver
24/12/14 19:41:38 INFO Executor: Running task 42.0 in stage 13.0 (TID 632)
[2024-12-14T19:41:39.121+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO TaskSetManager: Starting task 43.0 in stage 13.0 (TID 633) (localhost, executor driver, partition 43, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.123+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO Executor: Running task 43.0 in stage 13.0 (TID 633)
[2024-12-14T19:41:39.128+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO Executor: Finished task 3.0 in stage 13.0 (TID 611). 5776 bytes result sent to driver
[2024-12-14T19:41:39.130+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO TaskSetManager: Starting task 46.0 in stage 13.0 (TID 634) (localhost, executor driver, partition 46, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.132+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:38 INFO TaskSetManager: Starting task 47.0 in stage 13.0 (TID 635) (localhost, executor driver, partition 47, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:38 INFO Executor: Finished task 5.0 in stage 13.0 (TID 613). 5819 bytes result sent to driver
24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:39.136+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:38 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 610) in 77 ms on localhost (executor driver) (6/200)
[2024-12-14T19:41:39.138+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO TaskSetManager: Finished task 26.0 in stage 13.0 (TID 624) in 71 ms on localhost (executor driver) (7/200)
24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.140+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:39.142+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO TaskSetManager: Finished task 22.0 in stage 13.0 (TID 622) in 75 ms on localhost (executor driver) (8/200)
24/12/14 19:41:38 INFO Executor: Running task 47.0 in stage 13.0 (TID 635)
[2024-12-14T19:41:39.144+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO Executor: Running task 46.0 in stage 13.0 (TID 634)
[2024-12-14T19:41:39.147+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:39.150+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO TaskSetManager: Starting task 48.0 in stage 13.0 (TID 636) (localhost, executor driver, partition 48, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.153+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO TaskSetManager: Finished task 16.0 in stage 13.0 (TID 620) in 84 ms on localhost (executor driver) (9/200)
[2024-12-14T19:41:39.158+0000] {docker.py:413} INFO - 24/12/14 19:41:38 INFO Executor: Running task 48.0 in stage 13.0 (TID 636)
[2024-12-14T19:41:39.161+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.163+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO TaskSetManager: Starting task 49.0 in stage 13.0 (TID 637) (localhost, executor driver, partition 49, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO Executor: Finished task 34.0 in stage 13.0 (TID 628). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO TaskSetManager: Finished task 14.0 in stage 13.0 (TID 619) in 92 ms on localhost (executor driver) (10/200)
24/12/14 19:41:39 INFO TaskSetManager: Finished task 9.0 in stage 13.0 (TID 617) in 94 ms on localhost (executor driver) (11/200)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO Executor: Finished task 31.0 in stage 13.0 (TID 626). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
24/12/14 19:41:39 INFO TaskSetManager: Starting task 50.0 in stage 13.0 (TID 638) (localhost, executor driver, partition 50, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:39 INFO Executor: Finished task 35.0 in stage 13.0 (TID 629). 5776 bytes result sent to driver
[2024-12-14T19:41:39.165+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 50.0 in stage 13.0 (TID 638)
[2024-12-14T19:41:39.167+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 49.0 in stage 13.0 (TID 637)
[2024-12-14T19:41:39.169+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 32.0 in stage 13.0 (TID 627). 5776 bytes result sent to driver
[2024-12-14T19:41:39.171+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:39.174+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 51.0 in stage 13.0 (TID 639) (localhost, executor driver, partition 51, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.176+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 51.0 in stage 13.0 (TID 639)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.179+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 42.0 in stage 13.0 (TID 632). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO TaskSetManager: Starting task 52.0 in stage 13.0 (TID 640) (localhost, executor driver, partition 52, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.181+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 7.0 in stage 13.0 (TID 615) in 123 ms on localhost (executor driver) (12/200)
[2024-12-14T19:41:39.184+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO Executor: Running task 52.0 in stage 13.0 (TID 640)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:39.189+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 47.0 in stage 13.0 (TID 635). 5776 bytes result sent to driver
[2024-12-14T19:41:39.195+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
24/12/14 19:41:39 INFO Executor: Finished task 39.0 in stage 13.0 (TID 630). 5776 bytes result sent to driver
[2024-12-14T19:41:39.198+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 40.0 in stage 13.0 (TID 631). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO TaskSetManager: Finished task 25.0 in stage 13.0 (TID 623) in 122 ms on localhost (executor driver) (13/200)
24/12/14 19:41:39 INFO Executor: Finished task 43.0 in stage 13.0 (TID 633). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:39 INFO TaskSetManager: Starting task 53.0 in stage 13.0 (TID 641) (localhost, executor driver, partition 53, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:39 INFO TaskSetManager: Starting task 54.0 in stage 13.0 (TID 642) (localhost, executor driver, partition 54, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO Executor: Running task 53.0 in stage 13.0 (TID 641)
24/12/14 19:41:39 INFO Executor: Finished task 50.0 in stage 13.0 (TID 638). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO TaskSetManager: Finished task 8.0 in stage 13.0 (TID 616) in 142 ms on localhost (executor driver) (14/200)
24/12/14 19:41:39 INFO TaskSetManager: Starting task 57.0 in stage 13.0 (TID 643) (localhost, executor driver, partition 57, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO Executor: Running task 54.0 in stage 13.0 (TID 642)
24/12/14 19:41:39 INFO Executor: Finished task 46.0 in stage 13.0 (TID 634). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO Executor: Running task 57.0 in stage 13.0 (TID 643)
24/12/14 19:41:39 INFO Executor: Finished task 48.0 in stage 13.0 (TID 636). 5776 bytes result sent to driver
[2024-12-14T19:41:39.202+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 59.0 in stage 13.0 (TID 644) (localhost, executor driver, partition 59, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.205+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 51.0 in stage 13.0 (TID 639). 5862 bytes result sent to driver
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO TaskSetManager: Starting task 60.0 in stage 13.0 (TID 645) (localhost, executor driver, partition 60, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:39.212+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:39.214+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO BlockManagerInfo: Removed broadcast_11_piece0 on localhost:32963 in memory (size: 5.9 KiB, free: 434.3 MiB)
24/12/14 19:41:39 INFO Executor: Finished task 49.0 in stage 13.0 (TID 637). 5819 bytes result sent to driver
[2024-12-14T19:41:39.217+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.219+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 59.0 in stage 13.0 (TID 644)
[2024-12-14T19:41:39.221+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:39.226+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 5.0 in stage 13.0 (TID 613) in 185 ms on localhost (executor driver) (15/200)
24/12/14 19:41:39 INFO Executor: Running task 60.0 in stage 13.0 (TID 645)
24/12/14 19:41:39 INFO TaskSetManager: Finished task 35.0 in stage 13.0 (TID 629) in 128 ms on localhost (executor driver) (16/200)
[2024-12-14T19:41:39.231+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 3.0 in stage 13.0 (TID 611) in 189 ms on localhost (executor driver) (17/200)
[2024-12-14T19:41:39.233+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 61.0 in stage 13.0 (TID 646) (localhost, executor driver, partition 61, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO Executor: Running task 61.0 in stage 13.0 (TID 646)
[2024-12-14T19:41:39.238+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 62.0 in stage 13.0 (TID 647) (localhost, executor driver, partition 62, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.245+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 31.0 in stage 13.0 (TID 626) in 162 ms on localhost (executor driver) (18/200)
[2024-12-14T19:41:39.247+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 54.0 in stage 13.0 (TID 642). 5819 bytes result sent to driver
[2024-12-14T19:41:39.249+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 52.0 in stage 13.0 (TID 640). 5819 bytes result sent to driver
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.251+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 34.0 in stage 13.0 (TID 628) in 152 ms on localhost (executor driver) (19/200)
[2024-12-14T19:41:39.253+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO Executor: Finished task 53.0 in stage 13.0 (TID 641). 5819 bytes result sent to driver
[2024-12-14T19:41:39.256+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:39 INFO TaskSetManager: Finished task 32.0 in stage 13.0 (TID 627) in 155 ms on localhost (executor driver) (20/200)
[2024-12-14T19:41:39.259+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 42.0 in stage 13.0 (TID 632) in 133 ms on localhost (executor driver) (21/200)
[2024-12-14T19:41:39.261+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 63.0 in stage 13.0 (TID 648) (localhost, executor driver, partition 63, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.263+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 63.0 in stage 13.0 (TID 648)
24/12/14 19:41:39 INFO Executor: Running task 62.0 in stage 13.0 (TID 647)
[2024-12-14T19:41:39.266+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 64.0 in stage 13.0 (TID 649) (localhost, executor driver, partition 64, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO Executor: Running task 64.0 in stage 13.0 (TID 649)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
24/12/14 19:41:39 INFO Executor: Finished task 59.0 in stage 13.0 (TID 644). 5776 bytes result sent to driver
[2024-12-14T19:41:39.267+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO BlockManagerInfo: Removed broadcast_12_piece0 on localhost:32963 in memory (size: 20.7 KiB, free: 434.3 MiB)
[2024-12-14T19:41:39.269+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 68.0 in stage 13.0 (TID 650) (localhost, executor driver, partition 68, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.270+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 40.0 in stage 13.0 (TID 631) in 153 ms on localhost (executor driver) (22/200)
[2024-12-14T19:41:39.272+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 60.0 in stage 13.0 (TID 645). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO TaskSetManager: Finished task 47.0 in stage 13.0 (TID 635) in 152 ms on localhost (executor driver) (23/200)
24/12/14 19:41:39 INFO Executor: Running task 68.0 in stage 13.0 (TID 650)
24/12/14 19:41:39 INFO Executor: Finished task 61.0 in stage 13.0 (TID 646). 5776 bytes result sent to driver
[2024-12-14T19:41:39.274+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 69.0 in stage 13.0 (TID 651) (localhost, executor driver, partition 69, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.279+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 69.0 in stage 13.0 (TID 651)
[2024-12-14T19:41:39.282+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 57.0 in stage 13.0 (TID 643). 5819 bytes result sent to driver
[2024-12-14T19:41:39.284+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 70.0 in stage 13.0 (TID 652) (localhost, executor driver, partition 70, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.286+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 70.0 in stage 13.0 (TID 652)
24/12/14 19:41:39 INFO TaskSetManager: Starting task 71.0 in stage 13.0 (TID 653) (localhost, executor driver, partition 71, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.288+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 71.0 in stage 13.0 (TID 653)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO TaskSetManager: Starting task 72.0 in stage 13.0 (TID 654) (localhost, executor driver, partition 72, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:39.290+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO TaskSetManager: Starting task 73.0 in stage 13.0 (TID 655) (localhost, executor driver, partition 73, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:39.293+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 73.0 in stage 13.0 (TID 655)
[2024-12-14T19:41:39.295+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 39.0 in stage 13.0 (TID 630) in 177 ms on localhost (executor driver) (24/200)
[2024-12-14T19:41:39.298+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:39.300+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO Executor: Running task 72.0 in stage 13.0 (TID 654)
[2024-12-14T19:41:39.304+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2024-12-14T19:41:39.313+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 43.0 in stage 13.0 (TID 633) in 168 ms on localhost (executor driver) (25/200)
[2024-12-14T19:41:39.317+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 74.0 in stage 13.0 (TID 656) (localhost, executor driver, partition 74, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.322+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 46.0 in stage 13.0 (TID 634) in 172 ms on localhost (executor driver) (26/200)
[2024-12-14T19:41:39.324+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 50.0 in stage 13.0 (TID 638) in 151 ms on localhost (executor driver) (27/200)
24/12/14 19:41:39 INFO Executor: Running task 74.0 in stage 13.0 (TID 656)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO TaskSetManager: Starting task 75.0 in stage 13.0 (TID 657) (localhost, executor driver, partition 75, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO TaskSetManager: Finished task 49.0 in stage 13.0 (TID 637) in 161 ms on localhost (executor driver) (28/200)
[2024-12-14T19:41:39.326+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:39.329+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 75.0 in stage 13.0 (TID 657)
[2024-12-14T19:41:39.331+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 62.0 in stage 13.0 (TID 647). 5776 bytes result sent to driver
[2024-12-14T19:41:39.333+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 51.0 in stage 13.0 (TID 639) in 144 ms on localhost (executor driver) (29/200)
[2024-12-14T19:41:39.338+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.340+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 52.0 in stage 13.0 (TID 640) in 142 ms on localhost (executor driver) (30/200)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:39.343+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 63.0 in stage 13.0 (TID 648). 5776 bytes result sent to driver
[2024-12-14T19:41:39.346+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 68.0 in stage 13.0 (TID 650). 5776 bytes result sent to driver
[2024-12-14T19:41:39.348+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 76.0 in stage 13.0 (TID 658) (localhost, executor driver, partition 76, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.349+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 76.0 in stage 13.0 (TID 658)
[2024-12-14T19:41:39.353+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 48.0 in stage 13.0 (TID 636) in 182 ms on localhost (executor driver) (31/200)
[2024-12-14T19:41:39.355+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 64.0 in stage 13.0 (TID 649). 5776 bytes result sent to driver
[2024-12-14T19:41:39.359+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.361+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:39.363+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.367+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:39.372+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 77.0 in stage 13.0 (TID 659) (localhost, executor driver, partition 77, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.376+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.378+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 54.0 in stage 13.0 (TID 642) in 140 ms on localhost (executor driver) (32/200)
24/12/14 19:41:39 INFO Executor: Running task 77.0 in stage 13.0 (TID 659)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
24/12/14 19:41:39 INFO TaskSetManager: Starting task 78.0 in stage 13.0 (TID 660) (localhost, executor driver, partition 78, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.379+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 78.0 in stage 13.0 (TID 660)
[2024-12-14T19:41:39.382+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 79.0 in stage 13.0 (TID 661) (localhost, executor driver, partition 79, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.383+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 79.0 in stage 13.0 (TID 661)
[2024-12-14T19:41:39.385+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 71.0 in stage 13.0 (TID 653). 5819 bytes result sent to driver
[2024-12-14T19:41:39.389+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.391+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:39 INFO TaskSetManager: Finished task 53.0 in stage 13.0 (TID 641) in 149 ms on localhost (executor driver) (33/200)
[2024-12-14T19:41:39.394+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 75.0 in stage 13.0 (TID 657). 5819 bytes result sent to driver
[2024-12-14T19:41:39.396+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 80.0 in stage 13.0 (TID 662) (localhost, executor driver, partition 80, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO Executor: Running task 80.0 in stage 13.0 (TID 662)
24/12/14 19:41:39 INFO TaskSetManager: Starting task 81.0 in stage 13.0 (TID 663) (localhost, executor driver, partition 81, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.398+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 74.0 in stage 13.0 (TID 656). 5819 bytes result sent to driver
24/12/14 19:41:39 INFO TaskSetManager: Starting task 82.0 in stage 13.0 (TID 664) (localhost, executor driver, partition 82, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO Executor: Running task 81.0 in stage 13.0 (TID 663)
[2024-12-14T19:41:39.400+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 70.0 in stage 13.0 (TID 652). 5819 bytes result sent to driver
[2024-12-14T19:41:39.402+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO Executor: Running task 82.0 in stage 13.0 (TID 664)
[2024-12-14T19:41:39.404+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 83.0 in stage 13.0 (TID 665) (localhost, executor driver, partition 83, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.406+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2024-12-14T19:41:39.408+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 61.0 in stage 13.0 (TID 646) in 106 ms on localhost (executor driver) (34/200)
[2024-12-14T19:41:39.410+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 59.0 in stage 13.0 (TID 644) in 153 ms on localhost (executor driver) (35/200)
[2024-12-14T19:41:39.412+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:39 INFO TaskSetManager: Finished task 63.0 in stage 13.0 (TID 648) in 93 ms on localhost (executor driver) (36/200)
[2024-12-14T19:41:39.415+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 83.0 in stage 13.0 (TID 665)
[2024-12-14T19:41:39.418+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 73.0 in stage 13.0 (TID 655). 5819 bytes result sent to driver
[2024-12-14T19:41:39.420+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:39.423+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
[2024-12-14T19:41:39.426+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.428+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.431+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2024-12-14T19:41:39.433+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 76.0 in stage 13.0 (TID 658). 5862 bytes result sent to driver
24/12/14 19:41:39 INFO TaskSetManager: Finished task 68.0 in stage 13.0 (TID 650) in 88 ms on localhost (executor driver) (37/200)
24/12/14 19:41:39 INFO TaskSetManager: Starting task 84.0 in stage 13.0 (TID 666) (localhost, executor driver, partition 84, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO Executor: Running task 84.0 in stage 13.0 (TID 666)
24/12/14 19:41:39 INFO Executor: Finished task 77.0 in stage 13.0 (TID 659). 5776 bytes result sent to driver
[2024-12-14T19:41:39.434+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 80.0 in stage 13.0 (TID 662). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO TaskSetManager: Finished task 60.0 in stage 13.0 (TID 645) in 136 ms on localhost (executor driver) (38/200)
24/12/14 19:41:39 INFO TaskSetManager: Finished task 57.0 in stage 13.0 (TID 643) in 170 ms on localhost (executor driver) (39/200)
[2024-12-14T19:41:39.437+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 64.0 in stage 13.0 (TID 649) in 107 ms on localhost (executor driver) (40/200)
24/12/14 19:41:39 INFO TaskSetManager: Finished task 71.0 in stage 13.0 (TID 653) in 83 ms on localhost (executor driver) (41/200)
[2024-12-14T19:41:39.439+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 69.0 in stage 13.0 (TID 651). 5819 bytes result sent to driver
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.441+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:39.445+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 72.0 in stage 13.0 (TID 654). 5819 bytes result sent to driver
[2024-12-14T19:41:39.449+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 85.0 in stage 13.0 (TID 667) (localhost, executor driver, partition 85, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.450+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 79.0 in stage 13.0 (TID 661). 5776 bytes result sent to driver
[2024-12-14T19:41:39.452+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 85.0 in stage 13.0 (TID 667)
24/12/14 19:41:39 INFO TaskSetManager: Starting task 86.0 in stage 13.0 (TID 668) (localhost, executor driver, partition 86, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO TaskSetManager: Finished task 62.0 in stage 13.0 (TID 647) in 125 ms on localhost (executor driver) (42/200)
24/12/14 19:41:39 INFO Executor: Running task 86.0 in stage 13.0 (TID 668)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.453+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:39 INFO TaskSetManager: Starting task 88.0 in stage 13.0 (TID 669) (localhost, executor driver, partition 88, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.455+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 88.0 in stage 13.0 (TID 669)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:39.462+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:39.464+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 78.0 in stage 13.0 (TID 660). 5776 bytes result sent to driver
[2024-12-14T19:41:39.465+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 89.0 in stage 13.0 (TID 670) (localhost, executor driver, partition 89, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.471+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 75.0 in stage 13.0 (TID 657) in 80 ms on localhost (executor driver) (43/200)
[2024-12-14T19:41:39.473+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 81.0 in stage 13.0 (TID 663). 5776 bytes result sent to driver
[2024-12-14T19:41:39.476+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 74.0 in stage 13.0 (TID 656) in 85 ms on localhost (executor driver) (44/200)
[2024-12-14T19:41:39.480+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 73.0 in stage 13.0 (TID 655) in 95 ms on localhost (executor driver) (45/200)
[2024-12-14T19:41:39.483+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 89.0 in stage 13.0 (TID 670)
24/12/14 19:41:39 INFO Executor: Finished task 83.0 in stage 13.0 (TID 665). 5776 bytes result sent to driver
[2024-12-14T19:41:39.489+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 90.0 in stage 13.0 (TID 671) (localhost, executor driver, partition 90, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.491+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 90.0 in stage 13.0 (TID 671)
[2024-12-14T19:41:39.496+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 92.0 in stage 13.0 (TID 672) (localhost, executor driver, partition 92, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.498+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.500+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 92.0 in stage 13.0 (TID 672)
24/12/14 19:41:39 INFO TaskSetManager: Finished task 70.0 in stage 13.0 (TID 652) in 108 ms on localhost (executor driver) (46/200)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
24/12/14 19:41:39 INFO Executor: Finished task 84.0 in stage 13.0 (TID 666). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.502+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:39.504+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 76.0 in stage 13.0 (TID 658) in 82 ms on localhost (executor driver) (47/200)
[2024-12-14T19:41:39.510+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 82.0 in stage 13.0 (TID 664). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO TaskSetManager: Starting task 95.0 in stage 13.0 (TID 673) (localhost, executor driver, partition 95, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO TaskSetManager: Finished task 77.0 in stage 13.0 (TID 659) in 78 ms on localhost (executor driver) (48/200)
[2024-12-14T19:41:39.511+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 95.0 in stage 13.0 (TID 673)
[2024-12-14T19:41:39.513+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 96.0 in stage 13.0 (TID 674) (localhost, executor driver, partition 96, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.515+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 96.0 in stage 13.0 (TID 674)
[2024-12-14T19:41:39.517+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 97.0 in stage 13.0 (TID 675) (localhost, executor driver, partition 97, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.519+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 97.0 in stage 13.0 (TID 675)
24/12/14 19:41:39 INFO TaskSetManager: Finished task 80.0 in stage 13.0 (TID 662) in 61 ms on localhost (executor driver) (49/200)
[2024-12-14T19:41:39.520+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 98.0 in stage 13.0 (TID 676) (localhost, executor driver, partition 98, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.522+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 86.0 in stage 13.0 (TID 668). 5862 bytes result sent to driver
24/12/14 19:41:39 INFO Executor: Running task 98.0 in stage 13.0 (TID 676)
[2024-12-14T19:41:39.523+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.526+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 20 ms
[2024-12-14T19:41:39.528+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 99.0 in stage 13.0 (TID 677) (localhost, executor driver, partition 99, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.529+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:39.531+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 85.0 in stage 13.0 (TID 667). 5862 bytes result sent to driver
[2024-12-14T19:41:39.534+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:39 INFO Executor: Running task 99.0 in stage 13.0 (TID 677)
[2024-12-14T19:41:39.537+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 72.0 in stage 13.0 (TID 654) in 153 ms on localhost (executor driver) (50/200)
[2024-12-14T19:41:39.539+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 69.0 in stage 13.0 (TID 651) in 160 ms on localhost (executor driver) (51/200)
[2024-12-14T19:41:39.541+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO TaskSetManager: Starting task 100.0 in stage 13.0 (TID 678) (localhost, executor driver, partition 100, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.544+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:39.548+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 79.0 in stage 13.0 (TID 661) in 108 ms on localhost (executor driver) (52/200)
[2024-12-14T19:41:39.551+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 101.0 in stage 13.0 (TID 679) (localhost, executor driver, partition 101, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.554+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 101.0 in stage 13.0 (TID 679)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO TaskSetManager: Starting task 102.0 in stage 13.0 (TID 680) (localhost, executor driver, partition 102, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:39.555+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 81.0 in stage 13.0 (TID 663) in 104 ms on localhost (executor driver) (53/200)
[2024-12-14T19:41:39.557+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 100.0 in stage 13.0 (TID 678)
[2024-12-14T19:41:39.559+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.560+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:39.562+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 88.0 in stage 13.0 (TID 669). 5819 bytes result sent to driver
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO TaskSetManager: Finished task 83.0 in stage 13.0 (TID 665) in 106 ms on localhost (executor driver) (54/200)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:39.567+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 78.0 in stage 13.0 (TID 660) in 124 ms on localhost (executor driver) (55/200)
[2024-12-14T19:41:39.569+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO Executor: Finished task 95.0 in stage 13.0 (TID 673). 5819 bytes result sent to driver
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:39.571+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 102.0 in stage 13.0 (TID 680)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:39 INFO TaskSetManager: Starting task 103.0 in stage 13.0 (TID 681) (localhost, executor driver, partition 103, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO Executor: Finished task 98.0 in stage 13.0 (TID 676). 5819 bytes result sent to driver
24/12/14 19:41:39 INFO Executor: Running task 103.0 in stage 13.0 (TID 681)
24/12/14 19:41:39 INFO TaskSetManager: Starting task 104.0 in stage 13.0 (TID 682) (localhost, executor driver, partition 104, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.572+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 89.0 in stage 13.0 (TID 670). 5819 bytes result sent to driver
[2024-12-14T19:41:39.573+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 97.0 in stage 13.0 (TID 675). 5819 bytes result sent to driver
[2024-12-14T19:41:39.575+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 90.0 in stage 13.0 (TID 671). 5819 bytes result sent to driver
[2024-12-14T19:41:39.577+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 92.0 in stage 13.0 (TID 672). 5862 bytes result sent to driver
24/12/14 19:41:39 INFO Executor: Running task 104.0 in stage 13.0 (TID 682)
[2024-12-14T19:41:39.579+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 105.0 in stage 13.0 (TID 683) (localhost, executor driver, partition 105, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO TaskSetManager: Starting task 106.0 in stage 13.0 (TID 684) (localhost, executor driver, partition 106, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.581+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 96.0 in stage 13.0 (TID 674). 5819 bytes result sent to driver
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO Executor: Finished task 99.0 in stage 13.0 (TID 677). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:39 INFO Executor: Running task 106.0 in stage 13.0 (TID 684)
24/12/14 19:41:39 INFO TaskSetManager: Starting task 108.0 in stage 13.0 (TID 685) (localhost, executor driver, partition 108, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.584+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 105.0 in stage 13.0 (TID 683)
[2024-12-14T19:41:39.586+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 101.0 in stage 13.0 (TID 679). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO Executor: Running task 108.0 in stage 13.0 (TID 685)
[2024-12-14T19:41:39.588+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.591+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:39.594+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 109.0 in stage 13.0 (TID 686) (localhost, executor driver, partition 109, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.596+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:39.599+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 109.0 in stage 13.0 (TID 686)
[2024-12-14T19:41:39.601+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 111.0 in stage 13.0 (TID 687) (localhost, executor driver, partition 111, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.603+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:39 INFO TaskSetManager: Starting task 113.0 in stage 13.0 (TID 688) (localhost, executor driver, partition 113, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.606+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 111.0 in stage 13.0 (TID 687)
[2024-12-14T19:41:39.608+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 113.0 in stage 13.0 (TID 688)
24/12/14 19:41:39 INFO TaskSetManager: Starting task 120.0 in stage 13.0 (TID 689) (localhost, executor driver, partition 120, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.613+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 102.0 in stage 13.0 (TID 680). 5776 bytes result sent to driver
[2024-12-14T19:41:39.615+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 120.0 in stage 13.0 (TID 689)
[2024-12-14T19:41:39.616+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 84.0 in stage 13.0 (TID 666) in 137 ms on localhost (executor driver) (56/200)
[2024-12-14T19:41:39.620+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 88.0 in stage 13.0 (TID 669) in 124 ms on localhost (executor driver) (57/200)
[2024-12-14T19:41:39.622+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 82.0 in stage 13.0 (TID 664) in 157 ms on localhost (executor driver) (58/200)
[2024-12-14T19:41:39.623+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 98.0 in stage 13.0 (TID 676) in 83 ms on localhost (executor driver) (59/200)
[2024-12-14T19:41:39.624+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 86.0 in stage 13.0 (TID 668) in 132 ms on localhost (executor driver) (60/200)
[2024-12-14T19:41:39.626+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 97.0 in stage 13.0 (TID 675) in 108 ms on localhost (executor driver) (61/200)
[2024-12-14T19:41:39.628+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.634+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:39.637+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 100.0 in stage 13.0 (TID 678). 5776 bytes result sent to driver
[2024-12-14T19:41:39.641+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 89.0 in stage 13.0 (TID 670) in 129 ms on localhost (executor driver) (62/200)
[2024-12-14T19:41:39.645+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 85.0 in stage 13.0 (TID 667) in 140 ms on localhost (executor driver) (63/200)
24/12/14 19:41:39 INFO Executor: Finished task 106.0 in stage 13.0 (TID 684). 5776 bytes result sent to driver
[2024-12-14T19:41:39.651+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 123.0 in stage 13.0 (TID 690) (localhost, executor driver, partition 123, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.654+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 123.0 in stage 13.0 (TID 690)
24/12/14 19:41:39 INFO TaskSetManager: Starting task 124.0 in stage 13.0 (TID 691) (localhost, executor driver, partition 124, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.656+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 125.0 in stage 13.0 (TID 692) (localhost, executor driver, partition 125, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.659+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 103.0 in stage 13.0 (TID 681). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO Executor: Running task 125.0 in stage 13.0 (TID 692)
24/12/14 19:41:39 INFO TaskSetManager: Starting task 127.0 in stage 13.0 (TID 693) (localhost, executor driver, partition 127, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.660+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 127.0 in stage 13.0 (TID 693)
24/12/14 19:41:39 INFO TaskSetManager: Starting task 129.0 in stage 13.0 (TID 694) (localhost, executor driver, partition 129, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.663+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 124.0 in stage 13.0 (TID 691)
[2024-12-14T19:41:39.665+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.667+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:39.669+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 95.0 in stage 13.0 (TID 673) in 130 ms on localhost (executor driver) (64/200)
24/12/14 19:41:39 INFO Executor: Running task 129.0 in stage 13.0 (TID 694)
[2024-12-14T19:41:39.671+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.673+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2024-12-14T19:41:39.676+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 130.0 in stage 13.0 (TID 695) (localhost, executor driver, partition 130, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.678+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 104.0 in stage 13.0 (TID 682). 5776 bytes result sent to driver
[2024-12-14T19:41:39.680+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 132.0 in stage 13.0 (TID 696) (localhost, executor driver, partition 132, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.681+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 96.0 in stage 13.0 (TID 674) in 135 ms on localhost (executor driver) (65/200)
[2024-12-14T19:41:39.683+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 130.0 in stage 13.0 (TID 695)
[2024-12-14T19:41:39.684+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 101.0 in stage 13.0 (TID 679) in 88 ms on localhost (executor driver) (66/200)
[2024-12-14T19:41:39.686+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 102.0 in stage 13.0 (TID 680) in 87 ms on localhost (executor driver) (67/200)
[2024-12-14T19:41:39.689+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.690+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:39.692+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 100.0 in stage 13.0 (TID 678) in 102 ms on localhost (executor driver) (68/200)
[2024-12-14T19:41:39.693+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 92.0 in stage 13.0 (TID 672) in 154 ms on localhost (executor driver) (69/200)
[2024-12-14T19:41:39.694+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO Executor: Running task 132.0 in stage 13.0 (TID 696)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO TaskSetManager: Finished task 90.0 in stage 13.0 (TID 671) in 161 ms on localhost (executor driver) (70/200)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 28 ms
[2024-12-14T19:41:39.696+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.698+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2024-12-14T19:41:39.701+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 135.0 in stage 13.0 (TID 697) (localhost, executor driver, partition 135, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.705+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.707+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 135.0 in stage 13.0 (TID 697)
[2024-12-14T19:41:39.709+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
[2024-12-14T19:41:39.710+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.712+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
[2024-12-14T19:41:39.713+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 136.0 in stage 13.0 (TID 698) (localhost, executor driver, partition 136, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.720+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 103.0 in stage 13.0 (TID 681) in 100 ms on localhost (executor driver) (71/200)
[2024-12-14T19:41:39.725+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 99.0 in stage 13.0 (TID 677) in 140 ms on localhost (executor driver) (72/200)
24/12/14 19:41:39 INFO TaskSetManager: Finished task 106.0 in stage 13.0 (TID 684) in 89 ms on localhost (executor driver) (73/200)
[2024-12-14T19:41:39.730+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 137.0 in stage 13.0 (TID 699) (localhost, executor driver, partition 137, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.733+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 104.0 in stage 13.0 (TID 682) in 104 ms on localhost (executor driver) (74/200)
[2024-12-14T19:41:39.740+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 136.0 in stage 13.0 (TID 698)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.742+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:39.743+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 108.0 in stage 13.0 (TID 685). 5776 bytes result sent to driver
[2024-12-14T19:41:39.746+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.747+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 15 ms
[2024-12-14T19:41:39.748+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 111.0 in stage 13.0 (TID 687). 5776 bytes result sent to driver
[2024-12-14T19:41:39.750+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 105.0 in stage 13.0 (TID 683). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO Executor: Running task 137.0 in stage 13.0 (TID 699)
[2024-12-14T19:41:39.753+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 26 ms
[2024-12-14T19:41:39.756+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 142.0 in stage 13.0 (TID 700) (localhost, executor driver, partition 142, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.758+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.760+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 46 ms
24/12/14 19:41:39 INFO Executor: Running task 142.0 in stage 13.0 (TID 700)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2024-12-14T19:41:39.761+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 145.0 in stage 13.0 (TID 701) (localhost, executor driver, partition 145, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.763+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 108.0 in stage 13.0 (TID 685) in 125 ms on localhost (executor driver) (75/200)
[2024-12-14T19:41:39.764+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 111.0 in stage 13.0 (TID 687) in 114 ms on localhost (executor driver) (76/200)
[2024-12-14T19:41:39.765+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 120.0 in stage 13.0 (TID 689). 5776 bytes result sent to driver
[2024-12-14T19:41:39.767+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 123.0 in stage 13.0 (TID 690). 5819 bytes result sent to driver
[2024-12-14T19:41:39.769+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 145.0 in stage 13.0 (TID 701)
[2024-12-14T19:41:39.770+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 146.0 in stage 13.0 (TID 702) (localhost, executor driver, partition 146, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.772+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 109.0 in stage 13.0 (TID 686). 5819 bytes result sent to driver
[2024-12-14T19:41:39.774+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:39.776+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.777+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 129.0 in stage 13.0 (TID 694). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 16 ms
[2024-12-14T19:41:39.779+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 125.0 in stage 13.0 (TID 692). 5776 bytes result sent to driver
[2024-12-14T19:41:39.781+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO BlockManagerInfo: Removed broadcast_10_piece0 on localhost:32963 in memory (size: 25.8 KiB, free: 434.4 MiB)
24/12/14 19:41:39 INFO TaskSetManager: Starting task 148.0 in stage 13.0 (TID 703) (localhost, executor driver, partition 148, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.782+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 146.0 in stage 13.0 (TID 702)
[2024-12-14T19:41:39.784+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 105.0 in stage 13.0 (TID 683) in 158 ms on localhost (executor driver) (77/200)
[2024-12-14T19:41:39.787+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 148.0 in stage 13.0 (TID 703)
[2024-12-14T19:41:39.789+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 113.0 in stage 13.0 (TID 688). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO Executor: Finished task 135.0 in stage 13.0 (TID 697). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2024-12-14T19:41:39.793+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 142.0 in stage 13.0 (TID 700). 5776 bytes result sent to driver
[2024-12-14T19:41:39.795+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 132.0 in stage 13.0 (TID 696). 5776 bytes result sent to driver
[2024-12-14T19:41:39.797+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 149.0 in stage 13.0 (TID 704) (localhost, executor driver, partition 149, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.799+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 120.0 in stage 13.0 (TID 689) in 138 ms on localhost (executor driver) (78/200)
[2024-12-14T19:41:39.801+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 123.0 in stage 13.0 (TID 690) in 122 ms on localhost (executor driver) (79/200)
[2024-12-14T19:41:39.803+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 127.0 in stage 13.0 (TID 693). 5776 bytes result sent to driver
[2024-12-14T19:41:39.804+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 124.0 in stage 13.0 (TID 691). 5819 bytes result sent to driver
[2024-12-14T19:41:39.808+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 130.0 in stage 13.0 (TID 695). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.810+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 149.0 in stage 13.0 (TID 704)
[2024-12-14T19:41:39.811+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:39.813+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.815+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
[2024-12-14T19:41:39.817+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 150.0 in stage 13.0 (TID 705) (localhost, executor driver, partition 150, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.818+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 145.0 in stage 13.0 (TID 701). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO TaskSetManager: Starting task 151.0 in stage 13.0 (TID 706) (localhost, executor driver, partition 151, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.820+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 150.0 in stage 13.0 (TID 705)
[2024-12-14T19:41:39.822+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 136.0 in stage 13.0 (TID 698). 5776 bytes result sent to driver
[2024-12-14T19:41:39.823+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2024-12-14T19:41:39.825+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 152.0 in stage 13.0 (TID 707) (localhost, executor driver, partition 152, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.827+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 125.0 in stage 13.0 (TID 692) in 147 ms on localhost (executor driver) (80/200)
[2024-12-14T19:41:39.830+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 109.0 in stage 13.0 (TID 686) in 183 ms on localhost (executor driver) (81/200)
[2024-12-14T19:41:39.831+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 137.0 in stage 13.0 (TID 699). 5776 bytes result sent to driver
[2024-12-14T19:41:39.833+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 154.0 in stage 13.0 (TID 708) (localhost, executor driver, partition 154, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.834+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 152.0 in stage 13.0 (TID 707)
[2024-12-14T19:41:39.836+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 154.0 in stage 13.0 (TID 708)
24/12/14 19:41:39 INFO TaskSetManager: Starting task 158.0 in stage 13.0 (TID 709) (localhost, executor driver, partition 158, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.838+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 159.0 in stage 13.0 (TID 710) (localhost, executor driver, partition 159, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO TaskSetManager: Finished task 129.0 in stage 13.0 (TID 694) in 149 ms on localhost (executor driver) (82/200)
[2024-12-14T19:41:39.839+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 151.0 in stage 13.0 (TID 706)
[2024-12-14T19:41:39.841+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 161.0 in stage 13.0 (TID 711) (localhost, executor driver, partition 161, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO TaskSetManager: Starting task 162.0 in stage 13.0 (TID 712) (localhost, executor driver, partition 162, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.846+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 161.0 in stage 13.0 (TID 711)
24/12/14 19:41:39 INFO TaskSetManager: Starting task 164.0 in stage 13.0 (TID 713) (localhost, executor driver, partition 164, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.848+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 135.0 in stage 13.0 (TID 697) in 123 ms on localhost (executor driver) (83/200)
24/12/14 19:41:39 INFO TaskSetManager: Finished task 113.0 in stage 13.0 (TID 688) in 178 ms on localhost (executor driver) (84/200)
[2024-12-14T19:41:39.850+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 164.0 in stage 13.0 (TID 713)
[2024-12-14T19:41:39.851+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 158.0 in stage 13.0 (TID 709)
24/12/14 19:41:39 INFO Executor: Running task 162.0 in stage 13.0 (TID 712)
[2024-12-14T19:41:39.856+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 127.0 in stage 13.0 (TID 693) in 157 ms on localhost (executor driver) (85/200)
24/12/14 19:41:39 INFO Executor: Running task 159.0 in stage 13.0 (TID 710)
24/12/14 19:41:39 INFO TaskSetManager: Finished task 132.0 in stage 13.0 (TID 696) in 154 ms on localhost (executor driver) (86/200)
24/12/14 19:41:39 INFO TaskSetManager: Finished task 124.0 in stage 13.0 (TID 691) in 167 ms on localhost (executor driver) (87/200)
[2024-12-14T19:41:39.858+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 142.0 in stage 13.0 (TID 700) in 82 ms on localhost (executor driver) (88/200)
[2024-12-14T19:41:39.860+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 165.0 in stage 13.0 (TID 714) (localhost, executor driver, partition 165, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.865+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 165.0 in stage 13.0 (TID 714)
24/12/14 19:41:39 INFO Executor: Finished task 146.0 in stage 13.0 (TID 702). 5776 bytes result sent to driver
[2024-12-14T19:41:39.867+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 167.0 in stage 13.0 (TID 715) (localhost, executor driver, partition 167, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.870+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 130.0 in stage 13.0 (TID 695) in 165 ms on localhost (executor driver) (89/200)
[2024-12-14T19:41:39.872+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 167.0 in stage 13.0 (TID 715)
24/12/14 19:41:39 INFO TaskSetManager: Starting task 168.0 in stage 13.0 (TID 716) (localhost, executor driver, partition 168, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO TaskSetManager: Finished task 145.0 in stage 13.0 (TID 701) in 89 ms on localhost (executor driver) (90/200)
24/12/14 19:41:39 INFO Executor: Running task 168.0 in stage 13.0 (TID 716)
[2024-12-14T19:41:39.875+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.878+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO TaskSetManager: Finished task 136.0 in stage 13.0 (TID 698) in 145 ms on localhost (executor driver) (91/200)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
[2024-12-14T19:41:39.881+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO TaskSetManager: Starting task 170.0 in stage 13.0 (TID 717) (localhost, executor driver, partition 170, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
24/12/14 19:41:39 INFO TaskSetManager: Finished task 137.0 in stage 13.0 (TID 699) in 138 ms on localhost (executor driver) (92/200)
24/12/14 19:41:39 INFO Executor: Running task 170.0 in stage 13.0 (TID 717)
[2024-12-14T19:41:39.883+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 171.0 in stage 13.0 (TID 718) (localhost, executor driver, partition 171, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.885+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 146.0 in stage 13.0 (TID 702) in 98 ms on localhost (executor driver) (93/200)
[2024-12-14T19:41:39.888+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO Executor: Running task 171.0 in stage 13.0 (TID 718)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.890+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2024-12-14T19:41:39.891+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 154.0 in stage 13.0 (TID 708). 5776 bytes result sent to driver
[2024-12-14T19:41:39.894+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:39 INFO TaskSetManager: Starting task 172.0 in stage 13.0 (TID 719) (localhost, executor driver, partition 172, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.895+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.897+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 21 ms
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
[2024-12-14T19:41:39.899+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.901+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
24/12/14 19:41:39 INFO Executor: Finished task 162.0 in stage 13.0 (TID 712). 5776 bytes result sent to driver
[2024-12-14T19:41:39.902+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.905+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO Executor: Running task 172.0 in stage 13.0 (TID 719)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
24/12/14 19:41:39 INFO TaskSetManager: Finished task 154.0 in stage 13.0 (TID 708) in 52 ms on localhost (executor driver) (94/200)
24/12/14 19:41:39 INFO Executor: Finished task 167.0 in stage 13.0 (TID 715). 5776 bytes result sent to driver
[2024-12-14T19:41:39.906+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.908+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
[2024-12-14T19:41:39.910+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 149.0 in stage 13.0 (TID 704). 5776 bytes result sent to driver
[2024-12-14T19:41:39.912+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 21 ms
[2024-12-14T19:41:39.915+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 173.0 in stage 13.0 (TID 720) (localhost, executor driver, partition 173, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.917+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2024-12-14T19:41:39.919+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 168.0 in stage 13.0 (TID 716). 5776 bytes result sent to driver
[2024-12-14T19:41:39.921+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 174.0 in stage 13.0 (TID 721) (localhost, executor driver, partition 174, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.923+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.925+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 173.0 in stage 13.0 (TID 720)
[2024-12-14T19:41:39.927+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:39.929+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 150.0 in stage 13.0 (TID 705). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO TaskSetManager: Finished task 162.0 in stage 13.0 (TID 712) in 68 ms on localhost (executor driver) (95/200)
[2024-12-14T19:41:39.930+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 165.0 in stage 13.0 (TID 714). 5776 bytes result sent to driver
[2024-12-14T19:41:39.932+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 152.0 in stage 13.0 (TID 707). 5819 bytes result sent to driver
[2024-12-14T19:41:39.934+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 174.0 in stage 13.0 (TID 721)
[2024-12-14T19:41:39.936+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 149.0 in stage 13.0 (TID 704) in 116 ms on localhost (executor driver) (96/200)
[2024-12-14T19:41:39.937+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO Executor: Finished task 148.0 in stage 13.0 (TID 703). 5819 bytes result sent to driver
[2024-12-14T19:41:39.939+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 170.0 in stage 13.0 (TID 717). 5776 bytes result sent to driver
[2024-12-14T19:41:39.940+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2024-12-14T19:41:39.942+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 175.0 in stage 13.0 (TID 722) (localhost, executor driver, partition 175, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.946+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 175.0 in stage 13.0 (TID 722)
[2024-12-14T19:41:39.948+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 167.0 in stage 13.0 (TID 715) in 64 ms on localhost (executor driver) (97/200)
24/12/14 19:41:39 INFO TaskSetManager: Finished task 168.0 in stage 13.0 (TID 716) in 62 ms on localhost (executor driver) (98/200)
[2024-12-14T19:41:39.950+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.952+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:39.953+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO TaskSetManager: Starting task 179.0 in stage 13.0 (TID 723) (localhost, executor driver, partition 179, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.956+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:39 INFO Executor: Finished task 151.0 in stage 13.0 (TID 706). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO Executor: Finished task 164.0 in stage 13.0 (TID 713). 5819 bytes result sent to driver
24/12/14 19:41:39 INFO Executor: Finished task 172.0 in stage 13.0 (TID 719). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO Executor: Finished task 158.0 in stage 13.0 (TID 709). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO TaskSetManager: Starting task 181.0 in stage 13.0 (TID 724) (localhost, executor driver, partition 181, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO Executor: Running task 179.0 in stage 13.0 (TID 723)
[2024-12-14T19:41:39.960+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 150.0 in stage 13.0 (TID 705) in 118 ms on localhost (executor driver) (99/200)
[2024-12-14T19:41:39.962+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 161.0 in stage 13.0 (TID 711). 5819 bytes result sent to driver
24/12/14 19:41:39 INFO Executor: Running task 181.0 in stage 13.0 (TID 724)
[2024-12-14T19:41:39.965+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 184.0 in stage 13.0 (TID 725) (localhost, executor driver, partition 184, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.967+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 186.0 in stage 13.0 (TID 726) (localhost, executor driver, partition 186, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.968+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 159.0 in stage 13.0 (TID 710). 5819 bytes result sent to driver
24/12/14 19:41:39 INFO Executor: Running task 184.0 in stage 13.0 (TID 725)
[2024-12-14T19:41:39.970+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 192.0 in stage 13.0 (TID 727) (localhost, executor driver, partition 192, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.974+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 174.0 in stage 13.0 (TID 721). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO Executor: Finished task 173.0 in stage 13.0 (TID 720). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO TaskSetManager: Starting task 194.0 in stage 13.0 (TID 728) (localhost, executor driver, partition 194, NODE_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO Executor: Running task 186.0 in stage 13.0 (TID 726)
[2024-12-14T19:41:39.978+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:39.981+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:39.983+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 171.0 in stage 13.0 (TID 718). 5819 bytes result sent to driver
[2024-12-14T19:41:39.985+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 192.0 in stage 13.0 (TID 727)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:39.989+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 194.0 in stage 13.0 (TID 728)
24/12/14 19:41:39 INFO TaskSetManager: Starting task 195.0 in stage 13.0 (TID 729) (localhost, executor driver, partition 195, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:39.992+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 195.0 in stage 13.0 (TID 729)
[2024-12-14T19:41:40.000+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.007+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:40.014+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 175.0 in stage 13.0 (TID 722). 5776 bytes result sent to driver
[2024-12-14T19:41:40.016+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 196.0 in stage 13.0 (TID 730) (localhost, executor driver, partition 196, NODE_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.019+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 165.0 in stage 13.0 (TID 714) in 116 ms on localhost (executor driver) (100/200)
[2024-12-14T19:41:40.021+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 181.0 in stage 13.0 (TID 724). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO Executor: Running task 196.0 in stage 13.0 (TID 730)
[2024-12-14T19:41:40.025+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 731) (localhost, executor driver, partition 1, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.030+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 148.0 in stage 13.0 (TID 703) in 194 ms on localhost (executor driver) (101/200)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
24/12/14 19:41:39 INFO TaskSetManager: Finished task 152.0 in stage 13.0 (TID 707) in 148 ms on localhost (executor driver) (102/200)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO TaskSetManager: Finished task 172.0 in stage 13.0 (TID 719) in 94 ms on localhost (executor driver) (103/200)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:39 INFO Executor: Running task 1.0 in stage 13.0 (TID 731)
[2024-12-14T19:41:40.033+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 170.0 in stage 13.0 (TID 717) in 111 ms on localhost (executor driver) (104/200)
24/12/14 19:41:39 INFO TaskSetManager: Finished task 164.0 in stage 13.0 (TID 713) in 142 ms on localhost (executor driver) (105/200)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.035+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.037+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:40.039+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.041+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2024-12-14T19:41:40.043+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 732) (localhost, executor driver, partition 2, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.048+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 179.0 in stage 13.0 (TID 723). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO Executor: Running task 2.0 in stage 13.0 (TID 732)
24/12/14 19:41:39 INFO TaskSetManager: Starting task 10.0 in stage 13.0 (TID 733) (localhost, executor driver, partition 10, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO TaskSetManager: Finished task 151.0 in stage 13.0 (TID 706) in 174 ms on localhost (executor driver) (106/200)
24/12/14 19:41:39 INFO TaskSetManager: Finished task 158.0 in stage 13.0 (TID 709) in 158 ms on localhost (executor driver) (107/200)
24/12/14 19:41:39 INFO Executor: Running task 10.0 in stage 13.0 (TID 733)
[2024-12-14T19:41:40.052+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 161.0 in stage 13.0 (TID 711) in 156 ms on localhost (executor driver) (108/200)
[2024-12-14T19:41:40.055+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 184.0 in stage 13.0 (TID 725). 5776 bytes result sent to driver
[2024-12-14T19:41:40.057+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 186.0 in stage 13.0 (TID 726). 5776 bytes result sent to driver
[2024-12-14T19:41:40.058+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 11.0 in stage 13.0 (TID 734) (localhost, executor driver, partition 11, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.064+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 11.0 in stage 13.0 (TID 734)
24/12/14 19:41:39 INFO Executor: Finished task 195.0 in stage 13.0 (TID 729). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO TaskSetManager: Starting task 13.0 in stage 13.0 (TID 735) (localhost, executor driver, partition 13, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.066+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 13.0 in stage 13.0 (TID 735)
[2024-12-14T19:41:40.068+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 192.0 in stage 13.0 (TID 727). 5776 bytes result sent to driver
[2024-12-14T19:41:40.072+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.074+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2024-12-14T19:41:40.075+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:39 INFO TaskSetManager: Starting task 15.0 in stage 13.0 (TID 736) (localhost, executor driver, partition 15, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.077+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 174.0 in stage 13.0 (TID 721) in 110 ms on localhost (executor driver) (109/200)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:39 INFO Executor: Running task 15.0 in stage 13.0 (TID 736)
[2024-12-14T19:41:40.082+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 194.0 in stage 13.0 (TID 728). 5819 bytes result sent to driver
24/12/14 19:41:39 INFO Executor: Finished task 196.0 in stage 13.0 (TID 730). 5819 bytes result sent to driver
[2024-12-14T19:41:40.088+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 17.0 in stage 13.0 (TID 737) (localhost, executor driver, partition 17, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.090+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO Executor: Running task 17.0 in stage 13.0 (TID 737)
[2024-12-14T19:41:40.096+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:40.100+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 1.0 in stage 13.0 (TID 731). 5862 bytes result sent to driver
[2024-12-14T19:41:40.104+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.109+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 18.0 in stage 13.0 (TID 738) (localhost, executor driver, partition 18, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.112+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 159.0 in stage 13.0 (TID 710) in 195 ms on localhost (executor driver) (110/200)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:40.115+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 20.0 in stage 13.0 (TID 739) (localhost, executor driver, partition 20, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO TaskSetManager: Finished task 171.0 in stage 13.0 (TID 718) in 160 ms on localhost (executor driver) (111/200)
[2024-12-14T19:41:40.116+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 18.0 in stage 13.0 (TID 738)
[2024-12-14T19:41:40.121+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 181.0 in stage 13.0 (TID 724) in 109 ms on localhost (executor driver) (112/200)
[2024-12-14T19:41:40.124+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 20.0 in stage 13.0 (TID 739)
[2024-12-14T19:41:40.126+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 11.0 in stage 13.0 (TID 734). 5819 bytes result sent to driver
[2024-12-14T19:41:40.127+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 2.0 in stage 13.0 (TID 732). 5819 bytes result sent to driver
[2024-12-14T19:41:40.129+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 21.0 in stage 13.0 (TID 740) (localhost, executor driver, partition 21, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO Executor: Finished task 13.0 in stage 13.0 (TID 735). 5819 bytes result sent to driver
24/12/14 19:41:39 INFO Executor: Running task 21.0 in stage 13.0 (TID 740)
[2024-12-14T19:41:40.133+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 23.0 in stage 13.0 (TID 741) (localhost, executor driver, partition 23, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.134+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 175.0 in stage 13.0 (TID 722) in 128 ms on localhost (executor driver) (113/200)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:40.136+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.138+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:40.139+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 173.0 in stage 13.0 (TID 720) in 147 ms on localhost (executor driver) (114/200)
[2024-12-14T19:41:40.141+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 10.0 in stage 13.0 (TID 733). 5819 bytes result sent to driver
[2024-12-14T19:41:40.145+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 23.0 in stage 13.0 (TID 741)
[2024-12-14T19:41:40.147+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.149+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2024-12-14T19:41:40.153+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 24.0 in stage 13.0 (TID 742) (localhost, executor driver, partition 24, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.155+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 17.0 in stage 13.0 (TID 737). 5776 bytes result sent to driver
[2024-12-14T19:41:40.156+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 24.0 in stage 13.0 (TID 742)
[2024-12-14T19:41:40.158+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 15.0 in stage 13.0 (TID 736). 5819 bytes result sent to driver
[2024-12-14T19:41:40.161+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 18.0 in stage 13.0 (TID 738). 5776 bytes result sent to driver
[2024-12-14T19:41:40.163+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 27.0 in stage 13.0 (TID 743) (localhost, executor driver, partition 27, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.164+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 27.0 in stage 13.0 (TID 743)
[2024-12-14T19:41:40.167+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 28.0 in stage 13.0 (TID 744) (localhost, executor driver, partition 28, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.171+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:39 INFO TaskSetManager: Finished task 184.0 in stage 13.0 (TID 725) in 131 ms on localhost (executor driver) (115/200)
24/12/14 19:41:39 INFO Executor: Running task 28.0 in stage 13.0 (TID 744)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.173+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:40.174+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 192.0 in stage 13.0 (TID 727) in 121 ms on localhost (executor driver) (116/200)
24/12/14 19:41:39 INFO TaskSetManager: Finished task 194.0 in stage 13.0 (TID 728) in 122 ms on localhost (executor driver) (117/200)
24/12/14 19:41:39 INFO TaskSetManager: Finished task 195.0 in stage 13.0 (TID 729) in 107 ms on localhost (executor driver) (118/200)
[2024-12-14T19:41:40.176+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 186.0 in stage 13.0 (TID 726) in 138 ms on localhost (executor driver) (119/200)
[2024-12-14T19:41:40.178+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 30.0 in stage 13.0 (TID 745) (localhost, executor driver, partition 30, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.179+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 20.0 in stage 13.0 (TID 739). 5776 bytes result sent to driver
[2024-12-14T19:41:40.182+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:40.184+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.186+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2024-12-14T19:41:40.188+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 23.0 in stage 13.0 (TID 741). 5776 bytes result sent to driver
[2024-12-14T19:41:40.190+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 30.0 in stage 13.0 (TID 745)
[2024-12-14T19:41:40.192+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 33.0 in stage 13.0 (TID 746) (localhost, executor driver, partition 33, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.194+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:39 INFO TaskSetManager: Finished task 179.0 in stage 13.0 (TID 723) in 155 ms on localhost (executor driver) (120/200)
24/12/14 19:41:39 INFO Executor: Finished task 21.0 in stage 13.0 (TID 740). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO TaskSetManager: Starting task 36.0 in stage 13.0 (TID 747) (localhost, executor driver, partition 36, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO Executor: Running task 33.0 in stage 13.0 (TID 746)
24/12/14 19:41:39 INFO Executor: Running task 36.0 in stage 13.0 (TID 747)
24/12/14 19:41:39 INFO TaskSetManager: Starting task 37.0 in stage 13.0 (TID 748) (localhost, executor driver, partition 37, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO Executor: Running task 37.0 in stage 13.0 (TID 748)
24/12/14 19:41:39 INFO TaskSetManager: Starting task 38.0 in stage 13.0 (TID 749) (localhost, executor driver, partition 38, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO Executor: Running task 38.0 in stage 13.0 (TID 749)
24/12/14 19:41:39 INFO TaskSetManager: Starting task 41.0 in stage 13.0 (TID 750) (localhost, executor driver, partition 41, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.198+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 44.0 in stage 13.0 (TID 751) (localhost, executor driver, partition 44, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO Executor: Running task 41.0 in stage 13.0 (TID 750)
24/12/14 19:41:39 INFO Executor: Finished task 28.0 in stage 13.0 (TID 744). 5776 bytes result sent to driver
[2024-12-14T19:41:40.199+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 44.0 in stage 13.0 (TID 751)
[2024-12-14T19:41:40.201+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 24.0 in stage 13.0 (TID 742). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO TaskSetManager: Starting task 45.0 in stage 13.0 (TID 752) (localhost, executor driver, partition 45, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.202+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 55.0 in stage 13.0 (TID 753) (localhost, executor driver, partition 55, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.203+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 55.0 in stage 13.0 (TID 753)
[2024-12-14T19:41:40.204+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 56.0 in stage 13.0 (TID 754) (localhost, executor driver, partition 56, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.206+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 45.0 in stage 13.0 (TID 752)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2024-12-14T19:41:40.208+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 56.0 in stage 13.0 (TID 754)
[2024-12-14T19:41:40.209+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 27.0 in stage 13.0 (TID 743). 5776 bytes result sent to driver
[2024-12-14T19:41:40.210+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 58.0 in stage 13.0 (TID 755) (localhost, executor driver, partition 58, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 731) in 136 ms on localhost (executor driver) (121/200)
24/12/14 19:41:39 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 732) in 126 ms on localhost (executor driver) (122/200)
[2024-12-14T19:41:40.211+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 58.0 in stage 13.0 (TID 755)
[2024-12-14T19:41:40.212+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 196.0 in stage 13.0 (TID 730) in 149 ms on localhost (executor driver) (123/200)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.213+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:39 INFO TaskSetManager: Finished task 13.0 in stage 13.0 (TID 735) in 115 ms on localhost (executor driver) (124/200)
[2024-12-14T19:41:40.214+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 17.0 in stage 13.0 (TID 737) in 102 ms on localhost (executor driver) (125/200)
[2024-12-14T19:41:40.215+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 15.0 in stage 13.0 (TID 736) in 116 ms on localhost (executor driver) (126/200)
[2024-12-14T19:41:40.216+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:39 INFO TaskSetManager: Starting task 65.0 in stage 13.0 (TID 756) (localhost, executor driver, partition 65, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.217+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 10.0 in stage 13.0 (TID 733) in 127 ms on localhost (executor driver) (127/200)
[2024-12-14T19:41:40.218+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 18.0 in stage 13.0 (TID 738) in 90 ms on localhost (executor driver) (128/200)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.219+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 22 ms
24/12/14 19:41:39 INFO TaskSetManager: Finished task 20.0 in stage 13.0 (TID 739) in 88 ms on localhost (executor driver) (129/200)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.220+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 65.0 in stage 13.0 (TID 756)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:40.222+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.223+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.225+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:40.226+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 66.0 in stage 13.0 (TID 757) (localhost, executor driver, partition 66, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:40.227+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 38.0 in stage 13.0 (TID 749). 5819 bytes result sent to driver
[2024-12-14T19:41:40.229+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 23.0 in stage 13.0 (TID 741) in 83 ms on localhost (executor driver) (130/200)
[2024-12-14T19:41:40.229+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 66.0 in stage 13.0 (TID 757)
[2024-12-14T19:41:40.230+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 67.0 in stage 13.0 (TID 758) (localhost, executor driver, partition 67, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.232+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 67.0 in stage 13.0 (TID 758)
[2024-12-14T19:41:40.233+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 87.0 in stage 13.0 (TID 759) (localhost, executor driver, partition 87, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.234+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 45.0 in stage 13.0 (TID 752). 5819 bytes result sent to driver
24/12/14 19:41:39 INFO TaskSetManager: Finished task 21.0 in stage 13.0 (TID 740) in 96 ms on localhost (executor driver) (131/200)
[2024-12-14T19:41:40.235+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 41.0 in stage 13.0 (TID 750). 5819 bytes result sent to driver
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.236+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2024-12-14T19:41:40.237+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.240+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:40.241+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 36.0 in stage 13.0 (TID 747). 5819 bytes result sent to driver
24/12/14 19:41:39 INFO Executor: Running task 87.0 in stage 13.0 (TID 759)
[2024-12-14T19:41:40.242+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 91.0 in stage 13.0 (TID 760) (localhost, executor driver, partition 91, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.243+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 11.0 in stage 13.0 (TID 734) in 144 ms on localhost (executor driver) (132/200)
[2024-12-14T19:41:40.244+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 91.0 in stage 13.0 (TID 760)
[2024-12-14T19:41:40.245+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 93.0 in stage 13.0 (TID 761) (localhost, executor driver, partition 93, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.245+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 37.0 in stage 13.0 (TID 748). 5819 bytes result sent to driver
24/12/14 19:41:39 INFO Executor: Running task 93.0 in stage 13.0 (TID 761)
[2024-12-14T19:41:40.246+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 94.0 in stage 13.0 (TID 762) (localhost, executor driver, partition 94, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.246+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 58.0 in stage 13.0 (TID 755). 5776 bytes result sent to driver
[2024-12-14T19:41:40.247+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 66.0 in stage 13.0 (TID 757). 5776 bytes result sent to driver
[2024-12-14T19:41:40.247+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 33.0 in stage 13.0 (TID 746). 5819 bytes result sent to driver
[2024-12-14T19:41:40.248+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:40.248+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 107.0 in stage 13.0 (TID 763) (localhost, executor driver, partition 107, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.248+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 30.0 in stage 13.0 (TID 745). 5819 bytes result sent to driver
[2024-12-14T19:41:40.249+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 94.0 in stage 13.0 (TID 762)
24/12/14 19:41:39 INFO Executor: Running task 107.0 in stage 13.0 (TID 763)
[2024-12-14T19:41:40.250+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.250+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:40.251+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.252+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:40.253+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 110.0 in stage 13.0 (TID 764) (localhost, executor driver, partition 110, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.254+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:40.255+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 110.0 in stage 13.0 (TID 764)
24/12/14 19:41:39 INFO TaskSetManager: Finished task 24.0 in stage 13.0 (TID 742) in 116 ms on localhost (executor driver) (133/200)
[2024-12-14T19:41:40.256+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 45.0 in stage 13.0 (TID 752) in 81 ms on localhost (executor driver) (134/200)
[2024-12-14T19:41:40.257+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.258+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:39 INFO TaskSetManager: Finished task 41.0 in stage 13.0 (TID 750) in 84 ms on localhost (executor driver) (135/200)
[2024-12-14T19:41:40.258+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 55.0 in stage 13.0 (TID 753). 5819 bytes result sent to driver
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.259+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2024-12-14T19:41:40.260+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 27.0 in stage 13.0 (TID 743) in 118 ms on localhost (executor driver) (136/200)
[2024-12-14T19:41:40.261+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 36.0 in stage 13.0 (TID 747) in 89 ms on localhost (executor driver) (137/200)
[2024-12-14T19:41:40.262+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 112.0 in stage 13.0 (TID 765) (localhost, executor driver, partition 112, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO Executor: Running task 112.0 in stage 13.0 (TID 765)
24/12/14 19:41:39 INFO TaskSetManager: Starting task 114.0 in stage 13.0 (TID 766) (localhost, executor driver, partition 114, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO Executor: Finished task 56.0 in stage 13.0 (TID 754). 5819 bytes result sent to driver
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.264+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 87.0 in stage 13.0 (TID 759). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO TaskSetManager: Starting task 115.0 in stage 13.0 (TID 767) (localhost, executor driver, partition 115, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO TaskSetManager: Finished task 28.0 in stage 13.0 (TID 744) in 112 ms on localhost (executor driver) (138/200)
[2024-12-14T19:41:40.265+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 115.0 in stage 13.0 (TID 767)
[2024-12-14T19:41:40.266+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 33.0 in stage 13.0 (TID 746) in 101 ms on localhost (executor driver) (139/200)
24/12/14 19:41:39 INFO Executor: Finished task 44.0 in stage 13.0 (TID 751). 5819 bytes result sent to driver
24/12/14 19:41:39 INFO Executor: Running task 114.0 in stage 13.0 (TID 766)
[2024-12-14T19:41:40.267+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 116.0 in stage 13.0 (TID 768) (localhost, executor driver, partition 116, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.268+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 18 ms
[2024-12-14T19:41:40.269+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 91.0 in stage 13.0 (TID 760). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO Executor: Running task 116.0 in stage 13.0 (TID 768)
24/12/14 19:41:39 INFO Executor: Finished task 107.0 in stage 13.0 (TID 763). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
24/12/14 19:41:39 INFO TaskSetManager: Starting task 117.0 in stage 13.0 (TID 769) (localhost, executor driver, partition 117, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.271+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 117.0 in stage 13.0 (TID 769)
[2024-12-14T19:41:40.272+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.274+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 118.0 in stage 13.0 (TID 770) (localhost, executor driver, partition 118, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.275+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:40.277+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 93.0 in stage 13.0 (TID 761). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO TaskSetManager: Finished task 58.0 in stage 13.0 (TID 755) in 77 ms on localhost (executor driver) (140/200)
[2024-12-14T19:41:40.278+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 38.0 in stage 13.0 (TID 749) in 107 ms on localhost (executor driver) (141/200)
[2024-12-14T19:41:40.279+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 66.0 in stage 13.0 (TID 757) in 65 ms on localhost (executor driver) (142/200)
[2024-12-14T19:41:40.280+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 55.0 in stage 13.0 (TID 753) in 99 ms on localhost (executor driver) (143/200)
[2024-12-14T19:41:40.282+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 30.0 in stage 13.0 (TID 745) in 117 ms on localhost (executor driver) (144/200)
[2024-12-14T19:41:40.283+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.284+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.286+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:39 INFO TaskSetManager: Finished task 37.0 in stage 13.0 (TID 748) in 114 ms on localhost (executor driver) (145/200)
24/12/14 19:41:39 INFO TaskSetManager: Starting task 119.0 in stage 13.0 (TID 771) (localhost, executor driver, partition 119, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.287+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 94.0 in stage 13.0 (TID 762). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO Executor: Finished task 115.0 in stage 13.0 (TID 767). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
24/12/14 19:41:39 INFO Executor: Running task 118.0 in stage 13.0 (TID 770)
[2024-12-14T19:41:40.289+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2024-12-14T19:41:40.291+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 119.0 in stage 13.0 (TID 771)
[2024-12-14T19:41:40.293+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.294+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:40.295+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 112.0 in stage 13.0 (TID 765). 5776 bytes result sent to driver
[2024-12-14T19:41:40.297+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 65.0 in stage 13.0 (TID 756). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO TaskSetManager: Starting task 121.0 in stage 13.0 (TID 772) (localhost, executor driver, partition 121, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO TaskSetManager: Finished task 87.0 in stage 13.0 (TID 759) in 76 ms on localhost (executor driver) (146/200)
[2024-12-14T19:41:40.299+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 121.0 in stage 13.0 (TID 772)
[2024-12-14T19:41:40.300+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 110.0 in stage 13.0 (TID 764). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO TaskSetManager: Finished task 44.0 in stage 13.0 (TID 751) in 127 ms on localhost (executor driver) (147/200)
[2024-12-14T19:41:40.301+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 122.0 in stage 13.0 (TID 773) (localhost, executor driver, partition 122, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.303+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 122.0 in stage 13.0 (TID 773)
[2024-12-14T19:41:40.304+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 126.0 in stage 13.0 (TID 774) (localhost, executor driver, partition 126, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.306+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 56.0 in stage 13.0 (TID 754) in 123 ms on localhost (executor driver) (148/200)
24/12/14 19:41:39 INFO TaskSetManager: Finished task 91.0 in stage 13.0 (TID 760) in 77 ms on localhost (executor driver) (149/200)
24/12/14 19:41:39 INFO Executor: Running task 126.0 in stage 13.0 (TID 774)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.308+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:40.309+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 128.0 in stage 13.0 (TID 775) (localhost, executor driver, partition 128, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.311+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 114.0 in stage 13.0 (TID 766). 5776 bytes result sent to driver
[2024-12-14T19:41:40.312+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 131.0 in stage 13.0 (TID 776) (localhost, executor driver, partition 131, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO Executor: Running task 128.0 in stage 13.0 (TID 775)
[2024-12-14T19:41:40.314+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 133.0 in stage 13.0 (TID 777) (localhost, executor driver, partition 133, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.316+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 133.0 in stage 13.0 (TID 777)
24/12/14 19:41:39 INFO Executor: Finished task 117.0 in stage 13.0 (TID 769). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO TaskSetManager: Starting task 134.0 in stage 13.0 (TID 778) (localhost, executor driver, partition 134, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO Executor: Running task 131.0 in stage 13.0 (TID 776)
[2024-12-14T19:41:40.317+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 134.0 in stage 13.0 (TID 778)
24/12/14 19:41:39 INFO TaskSetManager: Starting task 138.0 in stage 13.0 (TID 779) (localhost, executor driver, partition 138, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.319+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 107.0 in stage 13.0 (TID 763) in 70 ms on localhost (executor driver) (150/200)
[2024-12-14T19:41:40.320+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 116.0 in stage 13.0 (TID 768). 5776 bytes result sent to driver
[2024-12-14T19:41:40.321+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 94.0 in stage 13.0 (TID 762) in 78 ms on localhost (executor driver) (151/200)
[2024-12-14T19:41:40.322+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 139.0 in stage 13.0 (TID 780) (localhost, executor driver, partition 139, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.324+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 138.0 in stage 13.0 (TID 779)
24/12/14 19:41:39 INFO Executor: Running task 139.0 in stage 13.0 (TID 780)
24/12/14 19:41:39 INFO TaskSetManager: Starting task 140.0 in stage 13.0 (TID 781) (localhost, executor driver, partition 140, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.325+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 112.0 in stage 13.0 (TID 765) in 58 ms on localhost (executor driver) (152/200)
24/12/14 19:41:39 INFO Executor: Finished task 67.0 in stage 13.0 (TID 758). 5776 bytes result sent to driver
24/12/14 19:41:39 INFO TaskSetManager: Finished task 110.0 in stage 13.0 (TID 764) in 74 ms on localhost (executor driver) (153/200)
24/12/14 19:41:39 INFO TaskSetManager: Finished task 93.0 in stage 13.0 (TID 761) in 86 ms on localhost (executor driver) (154/200)
24/12/14 19:41:39 INFO Executor: Finished task 119.0 in stage 13.0 (TID 771). 5776 bytes result sent to driver
[2024-12-14T19:41:40.327+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 115.0 in stage 13.0 (TID 767) in 58 ms on localhost (executor driver) (155/200)
[2024-12-14T19:41:40.328+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 140.0 in stage 13.0 (TID 781)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:39 INFO TaskSetManager: Starting task 141.0 in stage 13.0 (TID 782) (localhost, executor driver, partition 141, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO TaskSetManager: Finished task 65.0 in stage 13.0 (TID 756) in 116 ms on localhost (executor driver) (156/200)
[2024-12-14T19:41:40.329+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 25 ms
[2024-12-14T19:41:40.330+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 141.0 in stage 13.0 (TID 782)
[2024-12-14T19:41:40.331+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.332+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 143.0 in stage 13.0 (TID 783) (localhost, executor driver, partition 143, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 24 ms
24/12/14 19:41:39 INFO TaskSetManager: Finished task 114.0 in stage 13.0 (TID 766) in 87 ms on localhost (executor driver) (157/200)
24/12/14 19:41:39 INFO TaskSetManager: Finished task 117.0 in stage 13.0 (TID 769) in 74 ms on localhost (executor driver) (158/200)
24/12/14 19:41:39 INFO TaskSetManager: Starting task 144.0 in stage 13.0 (TID 784) (localhost, executor driver, partition 144, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO TaskSetManager: Finished task 116.0 in stage 13.0 (TID 768) in 83 ms on localhost (executor driver) (159/200)
24/12/14 19:41:39 INFO Executor: Running task 144.0 in stage 13.0 (TID 784)
24/12/14 19:41:39 INFO TaskSetManager: Starting task 147.0 in stage 13.0 (TID 785) (localhost, executor driver, partition 147, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.333+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:40.334+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 147.0 in stage 13.0 (TID 785)
[2024-12-14T19:41:40.335+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:39 INFO Executor: Finished task 134.0 in stage 13.0 (TID 778). 5819 bytes result sent to driver
24/12/14 19:41:39 INFO Executor: Running task 143.0 in stage 13.0 (TID 783)
24/12/14 19:41:39 INFO TaskSetManager: Starting task 153.0 in stage 13.0 (TID 786) (localhost, executor driver, partition 153, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO TaskSetManager: Finished task 67.0 in stage 13.0 (TID 758) in 147 ms on localhost (executor driver) (160/200)
24/12/14 19:41:39 INFO TaskSetManager: Finished task 119.0 in stage 13.0 (TID 771) in 78 ms on localhost (executor driver) (161/200)
[2024-12-14T19:41:40.336+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 153.0 in stage 13.0 (TID 786)
[2024-12-14T19:41:40.338+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 122.0 in stage 13.0 (TID 773). 5819 bytes result sent to driver
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.339+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:40.340+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 133.0 in stage 13.0 (TID 777). 5819 bytes result sent to driver
24/12/14 19:41:39 INFO Executor: Finished task 118.0 in stage 13.0 (TID 770). 5819 bytes result sent to driver
24/12/14 19:41:39 INFO TaskSetManager: Starting task 155.0 in stage 13.0 (TID 787) (localhost, executor driver, partition 155, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.341+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 156.0 in stage 13.0 (TID 788) (localhost, executor driver, partition 156, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO Executor: Running task 155.0 in stage 13.0 (TID 787)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.342+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
[2024-12-14T19:41:40.344+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 156.0 in stage 13.0 (TID 788)
[2024-12-14T19:41:40.345+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
[2024-12-14T19:41:40.346+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 157.0 in stage 13.0 (TID 789) (localhost, executor driver, partition 157, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.348+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 160.0 in stage 13.0 (TID 790) (localhost, executor driver, partition 160, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO Executor: Running task 160.0 in stage 13.0 (TID 790)
24/12/14 19:41:39 INFO TaskSetManager: Finished task 134.0 in stage 13.0 (TID 778) in 71 ms on localhost (executor driver) (162/200)
[2024-12-14T19:41:40.349+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 157.0 in stage 13.0 (TID 789)
[2024-12-14T19:41:40.350+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 118.0 in stage 13.0 (TID 770) in 109 ms on localhost (executor driver) (163/200)
[2024-12-14T19:41:40.351+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Finished task 140.0 in stage 13.0 (TID 781). 5819 bytes result sent to driver
[2024-12-14T19:41:40.352+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 133.0 in stage 13.0 (TID 777) in 81 ms on localhost (executor driver) (164/200)
[2024-12-14T19:41:40.353+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:39 INFO TaskSetManager: Starting task 163.0 in stage 13.0 (TID 791) (localhost, executor driver, partition 163, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO Executor: Finished task 126.0 in stage 13.0 (TID 774). 5819 bytes result sent to driver
[2024-12-14T19:41:40.355+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO Executor: Running task 163.0 in stage 13.0 (TID 791)
[2024-12-14T19:41:40.356+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Starting task 166.0 in stage 13.0 (TID 792) (localhost, executor driver, partition 166, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
24/12/14 19:41:39 INFO TaskSetManager: Finished task 140.0 in stage 13.0 (TID 781) in 78 ms on localhost (executor driver) (165/200)
24/12/14 19:41:39 INFO Executor: Running task 166.0 in stage 13.0 (TID 792)
24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:39 INFO TaskSetManager: Finished task 122.0 in stage 13.0 (TID 773) in 96 ms on localhost (executor driver) (166/200)
[2024-12-14T19:41:40.357+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
[2024-12-14T19:41:40.358+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO TaskSetManager: Finished task 126.0 in stage 13.0 (TID 774) in 95 ms on localhost (executor driver) (167/200)
[2024-12-14T19:41:40.360+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.361+0000] {docker.py:413} INFO - 24/12/14 19:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:40.363+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.364+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Finished task 139.0 in stage 13.0 (TID 780). 5819 bytes result sent to driver
[2024-12-14T19:41:40.365+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
24/12/14 19:41:40 INFO TaskSetManager: Starting task 169.0 in stage 13.0 (TID 793) (localhost, executor driver, partition 169, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.366+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Finished task 128.0 in stage 13.0 (TID 775). 5819 bytes result sent to driver
[2024-12-14T19:41:40.367+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Finished task 155.0 in stage 13.0 (TID 787). 5776 bytes result sent to driver
[2024-12-14T19:41:40.368+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Running task 169.0 in stage 13.0 (TID 793)
24/12/14 19:41:40 INFO TaskSetManager: Starting task 176.0 in stage 13.0 (TID 794) (localhost, executor driver, partition 176, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.369+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Running task 176.0 in stage 13.0 (TID 794)
[2024-12-14T19:41:40.370+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.371+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:40.372+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Starting task 177.0 in stage 13.0 (TID 795) (localhost, executor driver, partition 177, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.372+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:40 INFO Executor: Finished task 160.0 in stage 13.0 (TID 790). 5776 bytes result sent to driver
24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:40 INFO TaskSetManager: Finished task 139.0 in stage 13.0 (TID 780) in 116 ms on localhost (executor driver) (168/200)
24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
24/12/14 19:41:40 INFO Executor: Finished task 163.0 in stage 13.0 (TID 791). 5819 bytes result sent to driver
[2024-12-14T19:41:40.373+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.375+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2024-12-14T19:41:40.375+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Starting task 178.0 in stage 13.0 (TID 796) (localhost, executor driver, partition 178, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:40 INFO Executor: Finished task 138.0 in stage 13.0 (TID 779). 5819 bytes result sent to driver
[2024-12-14T19:41:40.376+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Running task 177.0 in stage 13.0 (TID 795)
[2024-12-14T19:41:40.377+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Starting task 180.0 in stage 13.0 (TID 797) (localhost, executor driver, partition 180, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.378+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Finished task 163.0 in stage 13.0 (TID 791) in 50 ms on localhost (executor driver) (169/200)
[2024-12-14T19:41:40.379+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Finished task 153.0 in stage 13.0 (TID 786). 5776 bytes result sent to driver
[2024-12-14T19:41:40.380+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Running task 178.0 in stage 13.0 (TID 796)
24/12/14 19:41:40 INFO Executor: Finished task 166.0 in stage 13.0 (TID 792). 5776 bytes result sent to driver
[2024-12-14T19:41:40.380+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Finished task 147.0 in stage 13.0 (TID 785). 5819 bytes result sent to driver
[2024-12-14T19:41:40.380+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:40 INFO TaskSetManager: Finished task 128.0 in stage 13.0 (TID 775) in 138 ms on localhost (executor driver) (170/200)
24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 17 ms
24/12/14 19:41:40 INFO Executor: Running task 180.0 in stage 13.0 (TID 797)
[2024-12-14T19:41:40.381+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Finished task 121.0 in stage 13.0 (TID 772). 5819 bytes result sent to driver
[2024-12-14T19:41:40.382+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.382+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Finished task 143.0 in stage 13.0 (TID 783). 5776 bytes result sent to driver
[2024-12-14T19:41:40.383+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Finished task 155.0 in stage 13.0 (TID 787) in 98 ms on localhost (executor driver) (171/200)
[2024-12-14T19:41:40.384+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Finished task 144.0 in stage 13.0 (TID 784). 5776 bytes result sent to driver
24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:40.385+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Starting task 182.0 in stage 13.0 (TID 798) (localhost, executor driver, partition 182, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.386+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Finished task 176.0 in stage 13.0 (TID 794). 5776 bytes result sent to driver
[2024-12-14T19:41:40.387+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Running task 182.0 in stage 13.0 (TID 798)
[2024-12-14T19:41:40.388+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Finished task 141.0 in stage 13.0 (TID 782). 5776 bytes result sent to driver
[2024-12-14T19:41:40.390+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Starting task 183.0 in stage 13.0 (TID 799) (localhost, executor driver, partition 183, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:40 INFO Executor: Finished task 156.0 in stage 13.0 (TID 788). 5776 bytes result sent to driver
24/12/14 19:41:40 INFO TaskSetManager: Finished task 160.0 in stage 13.0 (TID 790) in 99 ms on localhost (executor driver) (172/200)
24/12/14 19:41:40 INFO Executor: Finished task 131.0 in stage 13.0 (TID 776). 5819 bytes result sent to driver
[2024-12-14T19:41:40.391+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Finished task 153.0 in stage 13.0 (TID 786) in 128 ms on localhost (executor driver) (173/200)
[2024-12-14T19:41:40.392+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:40.393+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.393+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:40.394+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Finished task 138.0 in stage 13.0 (TID 779) in 174 ms on localhost (executor driver) (174/200)
[2024-12-14T19:41:40.395+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Starting task 185.0 in stage 13.0 (TID 800) (localhost, executor driver, partition 185, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.395+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Starting task 187.0 in stage 13.0 (TID 801) (localhost, executor driver, partition 187, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:40 INFO Executor: Finished task 169.0 in stage 13.0 (TID 793). 5819 bytes result sent to driver
[2024-12-14T19:41:40.396+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Running task 187.0 in stage 13.0 (TID 801)
24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:40 INFO Executor: Running task 183.0 in stage 13.0 (TID 799)
24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
24/12/14 19:41:40 INFO Executor: Running task 185.0 in stage 13.0 (TID 800)
24/12/14 19:41:40 INFO TaskSetManager: Starting task 188.0 in stage 13.0 (TID 802) (localhost, executor driver, partition 188, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:40.396+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Finished task 166.0 in stage 13.0 (TID 792) in 114 ms on localhost (executor driver) (175/200)
24/12/14 19:41:40 INFO TaskSetManager: Starting task 189.0 in stage 13.0 (TID 803) (localhost, executor driver, partition 189, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:40 INFO Executor: Running task 188.0 in stage 13.0 (TID 802)
24/12/14 19:41:40 INFO Executor: Finished task 177.0 in stage 13.0 (TID 795). 5776 bytes result sent to driver
24/12/14 19:41:40 INFO Executor: Running task 189.0 in stage 13.0 (TID 803)
24/12/14 19:41:40 INFO TaskSetManager: Starting task 190.0 in stage 13.0 (TID 804) (localhost, executor driver, partition 190, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.397+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Finished task 121.0 in stage 13.0 (TID 772) in 228 ms on localhost (executor driver) (176/200)
[2024-12-14T19:41:40.398+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Finished task 144.0 in stage 13.0 (TID 784) in 174 ms on localhost (executor driver) (177/200)
[2024-12-14T19:41:40.398+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Running task 190.0 in stage 13.0 (TID 804)
[2024-12-14T19:41:40.399+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Finished task 147.0 in stage 13.0 (TID 785) in 174 ms on localhost (executor driver) (178/200)
[2024-12-14T19:41:40.400+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Finished task 182.0 in stage 13.0 (TID 798). 5776 bytes result sent to driver
[2024-12-14T19:41:40.400+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Starting task 191.0 in stage 13.0 (TID 805) (localhost, executor driver, partition 191, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:40 INFO Executor: Finished task 157.0 in stage 13.0 (TID 789). 5776 bytes result sent to driver
24/12/14 19:41:40 INFO Executor: Running task 191.0 in stage 13.0 (TID 805)
[2024-12-14T19:41:40.401+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Finished task 180.0 in stage 13.0 (TID 797). 5776 bytes result sent to driver
[2024-12-14T19:41:40.401+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Finished task 178.0 in stage 13.0 (TID 796). 5776 bytes result sent to driver
[2024-12-14T19:41:40.401+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Starting task 193.0 in stage 13.0 (TID 806) (localhost, executor driver, partition 193, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.402+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Running task 193.0 in stage 13.0 (TID 806)
[2024-12-14T19:41:40.402+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Finished task 141.0 in stage 13.0 (TID 782) in 228 ms on localhost (executor driver) (179/200)
[2024-12-14T19:41:40.403+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Finished task 143.0 in stage 13.0 (TID 783) in 205 ms on localhost (executor driver) (180/200)
[2024-12-14T19:41:40.403+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.403+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
24/12/14 19:41:40 INFO TaskSetManager: Starting task 197.0 in stage 13.0 (TID 807) (localhost, executor driver, partition 197, PROCESS_LOCAL, 9952 bytes) 
24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.404+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:40.404+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.405+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:40.405+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Running task 197.0 in stage 13.0 (TID 807)
[2024-12-14T19:41:40.406+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Starting task 198.0 in stage 13.0 (TID 808) (localhost, executor driver, partition 198, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.406+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Finished task 191.0 in stage 13.0 (TID 805). 5776 bytes result sent to driver
24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.407+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.407+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2024-12-14T19:41:40.408+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Finished task 176.0 in stage 13.0 (TID 794) in 149 ms on localhost (executor driver) (181/200)
[2024-12-14T19:41:40.408+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Finished task 131.0 in stage 13.0 (TID 776) in 261 ms on localhost (executor driver) (182/200)
[2024-12-14T19:41:40.409+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Finished task 156.0 in stage 13.0 (TID 788) in 200 ms on localhost (executor driver) (183/200)
24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.409+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2024-12-14T19:41:40.410+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Running task 198.0 in stage 13.0 (TID 808)
[2024-12-14T19:41:40.410+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.411+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
[2024-12-14T19:41:40.412+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Finished task 187.0 in stage 13.0 (TID 801). 5776 bytes result sent to driver
[2024-12-14T19:41:40.412+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Starting task 199.0 in stage 13.0 (TID 809) (localhost, executor driver, partition 199, PROCESS_LOCAL, 9952 bytes)
[2024-12-14T19:41:40.413+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Running task 199.0 in stage 13.0 (TID 809)
24/12/14 19:41:40 INFO TaskSetManager: Finished task 177.0 in stage 13.0 (TID 795) in 154 ms on localhost (executor driver) (184/200)
[2024-12-14T19:41:40.415+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.416+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2024-12-14T19:41:40.417+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Finished task 188.0 in stage 13.0 (TID 802). 5776 bytes result sent to driver
[2024-12-14T19:41:40.418+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Finished task 182.0 in stage 13.0 (TID 798) in 118 ms on localhost (executor driver) (185/200)
[2024-12-14T19:41:40.419+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Finished task 180.0 in stage 13.0 (TID 797) in 145 ms on localhost (executor driver) (186/200)
[2024-12-14T19:41:40.420+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Finished task 169.0 in stage 13.0 (TID 793) in 171 ms on localhost (executor driver) (187/200)
24/12/14 19:41:40 INFO TaskSetManager: Finished task 191.0 in stage 13.0 (TID 805) in 60 ms on localhost (executor driver) (188/200)
24/12/14 19:41:40 INFO TaskSetManager: Finished task 187.0 in stage 13.0 (TID 801) in 90 ms on localhost (executor driver) (189/200)
[2024-12-14T19:41:40.422+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Finished task 157.0 in stage 13.0 (TID 789) in 220 ms on localhost (executor driver) (190/200)
[2024-12-14T19:41:40.423+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:40.425+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:40.426+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Finished task 185.0 in stage 13.0 (TID 800). 5776 bytes result sent to driver
24/12/14 19:41:40 INFO TaskSetManager: Finished task 178.0 in stage 13.0 (TID 796) in 154 ms on localhost (executor driver) (191/200)
[2024-12-14T19:41:40.428+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Finished task 183.0 in stage 13.0 (TID 799). 5776 bytes result sent to driver
[2024-12-14T19:41:40.430+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Finished task 185.0 in stage 13.0 (TID 800) in 106 ms on localhost (executor driver) (192/200)
[2024-12-14T19:41:40.431+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Finished task 183.0 in stage 13.0 (TID 799) in 119 ms on localhost (executor driver) (193/200)
[2024-12-14T19:41:40.432+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Finished task 189.0 in stage 13.0 (TID 803). 5776 bytes result sent to driver
[2024-12-14T19:41:40.433+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Finished task 188.0 in stage 13.0 (TID 802) in 96 ms on localhost (executor driver) (194/200)
[2024-12-14T19:41:40.434+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Finished task 190.0 in stage 13.0 (TID 804). 5776 bytes result sent to driver
24/12/14 19:41:40 INFO TaskSetManager: Finished task 189.0 in stage 13.0 (TID 803) in 91 ms on localhost (executor driver) (195/200)
[2024-12-14T19:41:40.435+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2024-12-14T19:41:40.436+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Finished task 190.0 in stage 13.0 (TID 804) in 90 ms on localhost (executor driver) (196/200)
[2024-12-14T19:41:40.437+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Finished task 193.0 in stage 13.0 (TID 806). 5776 bytes result sent to driver
[2024-12-14T19:41:40.438+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Finished task 193.0 in stage 13.0 (TID 806) in 59 ms on localhost (executor driver) (197/200)
[2024-12-14T19:41:40.439+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Finished task 198.0 in stage 13.0 (TID 808). 5776 bytes result sent to driver
[2024-12-14T19:41:40.440+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Finished task 197.0 in stage 13.0 (TID 807). 5776 bytes result sent to driver
24/12/14 19:41:40 INFO TaskSetManager: Finished task 198.0 in stage 13.0 (TID 808) in 54 ms on localhost (executor driver) (198/200)
[2024-12-14T19:41:40.441+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Finished task 197.0 in stage 13.0 (TID 807) in 57 ms on localhost (executor driver) (199/200)
[2024-12-14T19:41:40.442+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Finished task 199.0 in stage 13.0 (TID 809). 5776 bytes result sent to driver
[2024-12-14T19:41:40.443+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Finished task 199.0 in stage 13.0 (TID 809) in 48 ms on localhost (executor driver) (200/200)
[2024-12-14T19:41:40.444+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool
[2024-12-14T19:41:40.444+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO DAGScheduler: ShuffleMapStage 13 (start at NativeMethodAccessorImpl.java:0) finished in 1.326 s
[2024-12-14T19:41:40.445+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO DAGScheduler: looking for newly runnable stages
[2024-12-14T19:41:40.446+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO DAGScheduler: running: Set()
[2024-12-14T19:41:40.447+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO DAGScheduler: waiting: Set(ResultStage 14)
24/12/14 19:41:40 INFO DAGScheduler: failed: Set()
[2024-12-14T19:41:40.447+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[43] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-12-14T19:41:40.448+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 12.5 KiB, free 434.3 MiB)
[2024-12-14T19:41:40.448+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.3 MiB)
[2024-12-14T19:41:40.449+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on localhost:32963 (size: 5.9 KiB, free: 434.4 MiB)
[2024-12-14T19:41:40.449+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1580
[2024-12-14T19:41:40.450+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[43] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/12/14 19:41:40 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
[2024-12-14T19:41:40.450+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 810) (localhost, executor driver, partition 0, NODE_LOCAL, 9963 bytes)
[2024-12-14T19:41:40.451+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Running task 0.0 in stage 14.0 (TID 810)
[2024-12-14T19:41:40.452+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Getting 200 (11.7 KiB) non-empty blocks including 200 (11.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2024-12-14T19:41:40.453+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Finished task 0.0 in stage 14.0 (TID 810). 3995 bytes result sent to driver
[2024-12-14T19:41:40.454+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 810) in 48 ms on localhost (executor driver) (1/1)
24/12/14 19:41:40 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool
[2024-12-14T19:41:40.455+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO DAGScheduler: ResultStage 14 (start at NativeMethodAccessorImpl.java:0) finished in 0.061 s
[2024-12-14T19:41:40.455+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
24/12/14 19:41:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
[2024-12-14T19:41:40.456+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO DAGScheduler: Job 5 finished: start at NativeMethodAccessorImpl.java:0, took 2.101195 s
[2024-12-14T19:41:40.457+0000] {docker.py:413} INFO - 2024-12-14 19:41:40,286 [INFO] Attempting to save 180 rows to table reddit_posts
2024-12-14 19:41:40,286 [INFO] Sample data for table reddit_posts:
[2024-12-14T19:41:40.638+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO CodeGenerator: Code generated in 34.963227 ms
[2024-12-14T19:41:40.666+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO CodeGenerator: Code generated in 17.988897 ms
[2024-12-14T19:41:40.690+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO CodeGenerator: Code generated in 17.533713 ms
[2024-12-14T19:41:40.736+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
[2024-12-14T19:41:40.739+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO DAGScheduler: Registering RDD 46 (start at NativeMethodAccessorImpl.java:0) as input to shuffle 9
[2024-12-14T19:41:40.740+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO DAGScheduler: Got job 6 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/12/14 19:41:40 INFO DAGScheduler: Final stage: ResultStage 16 (start at NativeMethodAccessorImpl.java:0)
24/12/14 19:41:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
[2024-12-14T19:41:40.742+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 15)
[2024-12-14T19:41:40.743+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[46] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-12-14T19:41:40.751+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 52.7 KiB, free 434.2 MiB)
[2024-12-14T19:41:40.753+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 20.2 KiB, free 434.2 MiB)
[2024-12-14T19:41:40.755+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on localhost:32963 (size: 20.2 KiB, free: 434.3 MiB)
[2024-12-14T19:41:40.757+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1580
[2024-12-14T19:41:40.758+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[46] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/12/14 19:41:40 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
[2024-12-14T19:41:40.761+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 811) (localhost, executor driver, partition 0, PROCESS_LOCAL, 10838 bytes)
[2024-12-14T19:41:40.763+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO Executor: Running task 0.0 in stage 15.0 (TID 811)
[2024-12-14T19:41:40.794+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO CodeGenerator: Code generated in 16.55388 ms
[2024-12-14T19:41:40.831+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO CodeGenerator: Code generated in 21.74139 ms
[2024-12-14T19:41:40.863+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO CodeGenerator: Code generated in 11.138736 ms
[2024-12-14T19:41:40.876+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=reddit_data-0 fromOffset=0 untilOffset=650, for query queryId=380f0ba5-0895-4b92-9659-cdf82c87bac4 batchId=0 taskId=811 partitionId=0
[2024-12-14T19:41:40.882+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO KafkaConsumer: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to offset 0 for partition reddit_data-0
[2024-12-14T19:41:40.893+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to earliest offset of partition reddit_data-0
[2024-12-14T19:41:40.895+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Resetting offset for partition reddit_data-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 0 rack: null)], epoch=32}}.
24/12/14 19:41:40 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to latest offset of partition reddit_data-0
[2024-12-14T19:41:40.898+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Resetting offset for partition reddit_data-0 to position FetchPosition{offset=650, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 0 rack: null)], epoch=32}}.
[2024-12-14T19:41:40.923+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO KafkaConsumer: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to offset 500 for partition reddit_data-0
[2024-12-14T19:41:40.925+0000] {docker.py:413} INFO - 24/12/14 19:41:40 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to earliest offset of partition reddit_data-0
[2024-12-14T19:41:41.429+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Resetting offset for partition reddit_data-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 0 rack: null)], epoch=32}}.
[2024-12-14T19:41:41.431+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to latest offset of partition reddit_data-0
[2024-12-14T19:41:41.432+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Resetting offset for partition reddit_data-0 to position FetchPosition{offset=650, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 0 rack: null)], epoch=32}}.
[2024-12-14T19:41:41.518+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO CodeGenerator: Code generated in 11.919505 ms
[2024-12-14T19:41:41.556+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO CodeGenerator: Code generated in 18.95454 ms
[2024-12-14T19:41:41.581+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO CodeGenerator: Code generated in 15.872132 ms
[2024-12-14T19:41:41.645+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO KafkaDataConsumer: From Kafka topicPartition=reddit_data-0 groupId=reddit_processor_group read 650 records through 2 polls (polled  out 650 records), taking 526233927 nanos, during time span of 761398935 nanos.
[2024-12-14T19:41:41.647+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO Executor: Finished task 0.0 in stage 15.0 (TID 811). 2667 bytes result sent to driver
[2024-12-14T19:41:41.649+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 811) in 886 ms on localhost (executor driver) (1/1)
24/12/14 19:41:41 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool
[2024-12-14T19:41:41.650+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO DAGScheduler: ShuffleMapStage 15 (start at NativeMethodAccessorImpl.java:0) finished in 0.905 s
[2024-12-14T19:41:41.654+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO DAGScheduler: looking for newly runnable stages
24/12/14 19:41:41 INFO DAGScheduler: running: Set()
24/12/14 19:41:41 INFO DAGScheduler: waiting: Set(ResultStage 16)
24/12/14 19:41:41 INFO DAGScheduler: failed: Set()
[2024-12-14T19:41:41.665+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[51] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-12-14T19:41:41.667+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 70.5 KiB, free 434.2 MiB)
[2024-12-14T19:41:41.669+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 27.4 KiB, free 434.1 MiB)
[2024-12-14T19:41:41.670+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on localhost:32963 (size: 27.4 KiB, free: 434.3 MiB)
[2024-12-14T19:41:41.672+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1580
[2024-12-14T19:41:41.674+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[51] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/12/14 19:41:41 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
[2024-12-14T19:41:41.676+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 812) (localhost, executor driver, partition 0, NODE_LOCAL, 9963 bytes)
[2024-12-14T19:41:41.677+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO Executor: Running task 0.0 in stage 16.0 (TID 812)
[2024-12-14T19:41:41.689+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO ShuffleBlockFetcherIterator: Getting 1 (1538.0 B) non-empty blocks including 1 (1538.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:41.706+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO CodeGenerator: Code generated in 17.642684 ms
[2024-12-14T19:41:41.774+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO CodeGenerator: Code generated in 29.821296 ms
[2024-12-14T19:41:41.795+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO CodeGenerator: Code generated in 12.187775 ms
[2024-12-14T19:41:41.814+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO CodeGenerator: Code generated in 13.777731 ms
[2024-12-14T19:41:41.846+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO CodeGenerator: Code generated in 28.649032 ms
[2024-12-14T19:41:41.860+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO Executor: Finished task 0.0 in stage 16.0 (TID 812). 6518 bytes result sent to driver
[2024-12-14T19:41:41.863+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 812) in 189 ms on localhost (executor driver) (1/1)
24/12/14 19:41:41 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool
[2024-12-14T19:41:41.867+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO DAGScheduler: ResultStage 16 (start at NativeMethodAccessorImpl.java:0) finished in 0.211 s
[2024-12-14T19:41:41.869+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
24/12/14 19:41:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 16: Stage finished
[2024-12-14T19:41:41.869+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO DAGScheduler: Job 6 finished: start at NativeMethodAccessorImpl.java:0, took 1.129359 s
[2024-12-14T19:41:41.879+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
[2024-12-14T19:41:41.883+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO DAGScheduler: Got job 7 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/12/14 19:41:41 INFO DAGScheduler: Final stage: ResultStage 18 (start at NativeMethodAccessorImpl.java:0)
24/12/14 19:41:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
[2024-12-14T19:41:41.886+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO DAGScheduler: Missing parents: List()
[2024-12-14T19:41:41.887+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[51] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-12-14T19:41:41.892+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 70.5 KiB, free 434.1 MiB)
[2024-12-14T19:41:41.895+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 27.4 KiB, free 434.0 MiB)
[2024-12-14T19:41:41.897+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on localhost:32963 (size: 27.4 KiB, free: 434.3 MiB)
[2024-12-14T19:41:41.898+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1580
[2024-12-14T19:41:41.900+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[51] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(1))
24/12/14 19:41:41 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0
[2024-12-14T19:41:41.902+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 813) (localhost, executor driver, partition 1, PROCESS_LOCAL, 9963 bytes)
[2024-12-14T19:41:41.903+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO Executor: Running task 0.0 in stage 18.0 (TID 813)
[2024-12-14T19:41:41.913+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:41.921+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO Executor: Finished task 0.0 in stage 18.0 (TID 813). 4997 bytes result sent to driver
[2024-12-14T19:41:41.923+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 813) in 22 ms on localhost (executor driver) (1/1)
24/12/14 19:41:41 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool
[2024-12-14T19:41:41.925+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO DAGScheduler: ResultStage 18 (start at NativeMethodAccessorImpl.java:0) finished in 0.037 s
[2024-12-14T19:41:41.926+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
24/12/14 19:41:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished
[2024-12-14T19:41:41.927+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO DAGScheduler: Job 7 finished: start at NativeMethodAccessorImpl.java:0, took 0.045920 s
[2024-12-14T19:41:41.937+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
[2024-12-14T19:41:41.940+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO DAGScheduler: Got job 8 (start at NativeMethodAccessorImpl.java:0) with 2 output partitions
24/12/14 19:41:41 INFO DAGScheduler: Final stage: ResultStage 20 (start at NativeMethodAccessorImpl.java:0)
24/12/14 19:41:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
[2024-12-14T19:41:41.941+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO DAGScheduler: Missing parents: List()
[2024-12-14T19:41:41.942+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[51] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-12-14T19:41:41.948+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 70.5 KiB, free 434.0 MiB)
[2024-12-14T19:41:41.950+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 27.4 KiB, free 433.9 MiB)
[2024-12-14T19:41:41.952+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on localhost:32963 (size: 27.4 KiB, free: 434.3 MiB)
[2024-12-14T19:41:41.953+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1580
[2024-12-14T19:41:41.955+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 20 (MapPartitionsRDD[51] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(2, 3))
[2024-12-14T19:41:41.956+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO TaskSchedulerImpl: Adding task set 20.0 with 2 tasks resource profile 0
[2024-12-14T19:41:41.958+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO TaskSetManager: Starting task 1.0 in stage 20.0 (TID 814) (localhost, executor driver, partition 3, NODE_LOCAL, 9963 bytes)
[2024-12-14T19:41:41.960+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 815) (localhost, executor driver, partition 2, PROCESS_LOCAL, 9963 bytes)
[2024-12-14T19:41:41.961+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO Executor: Running task 0.0 in stage 20.0 (TID 815)
[2024-12-14T19:41:41.962+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO Executor: Running task 1.0 in stage 20.0 (TID 814)
[2024-12-14T19:41:41.968+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2024-12-14T19:41:41.972+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2024-12-14T19:41:41.980+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO Executor: Finished task 0.0 in stage 20.0 (TID 815). 4997 bytes result sent to driver
[2024-12-14T19:41:41.982+0000] {docker.py:413} INFO - 24/12/14 19:41:41 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 815) in 23 ms on localhost (executor driver) (1/2)
[2024-12-14T19:41:42.002+0000] {docker.py:413} INFO - 24/12/14 19:41:42 INFO Executor: Finished task 1.0 in stage 20.0 (TID 814). 5440 bytes result sent to driver
[2024-12-14T19:41:42.005+0000] {docker.py:413} INFO - 24/12/14 19:41:42 INFO TaskSetManager: Finished task 1.0 in stage 20.0 (TID 814) in 47 ms on localhost (executor driver) (2/2)
24/12/14 19:41:42 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool
[2024-12-14T19:41:42.006+0000] {docker.py:413} INFO - 24/12/14 19:41:42 INFO DAGScheduler: ResultStage 20 (start at NativeMethodAccessorImpl.java:0) finished in 0.061 s
[2024-12-14T19:41:42.007+0000] {docker.py:413} INFO - 24/12/14 19:41:42 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
24/12/14 19:41:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
[2024-12-14T19:41:42.008+0000] {docker.py:413} INFO - 24/12/14 19:41:42 INFO DAGScheduler: Job 8 finished: start at NativeMethodAccessorImpl.java:0, took 0.068301 s
[2024-12-14T19:41:42.026+0000] {docker.py:413} INFO - 24/12/14 19:41:42 INFO CodeGenerator: Code generated in 13.419748 ms
[2024-12-14T19:41:42.072+0000] {docker.py:413} INFO - +-------+----------------------------------------------------------------------+--------------+-------------------+-------+---------+------------+-----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------+---------------------------+---------+-----------+-----------+--------------------------+
|post_id|title                                                                 |author        |post_time          |upvotes|downvotes|num_comments|score|text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |first_level_comments_count|second_level_comments_count|subreddit|hour_of_day|day_of_week|created_at                |
+-------+----------------------------------------------------------------------+--------------+-------------------+-------+---------+------------+-----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------+---------------------------+---------+-----------+-----------+--------------------------+
|1he62zw|Newcastle [3] - 0 Leicester - A. Isak 50'                             |etclassico    |2024-12-14 16:08:32|31     |0        |15          |31   |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |7                         |5                          |soccer   |16         |7          |2024-12-14 19:41:40.331448|
|1heacrt|Match Thread: SV Darmstadt 98 vs Kaiserslautern | German 2. Bundesliga|MatchThreadder|2024-12-14 19:26:56|4      |0        |0           |4    |#**3': SV Darmstadt 98  [0-0](#bar-3-white)  Kaiserslautern**\n\n\n\n\n\n--------\n\n**Venue:** Merck-Stadion am Böllenfalltor\n\n[Auto-refreshing reddit comments link](http://www.reddit-stream.com/comments/1heacrt)\n\n---------\n\n[](#icon-notes-big) **LINE-UPS**\n\n**SV Darmstadt 98**\n\nMarcel Schuhen, Aleksandar Vukotic, Clemens Riedel, Fabian Nürnberger, Sergio López, Andreas Müller, Kai Klefisch, Kilian Corredor, Philipp Förster, Fraser Hornby, Isac Lidberg.\n\n**Subs:** Tobias Kempe, Fynn-Luca Lakenmacher, Klaus Gjasula, Merveille Papela, Marco Thiede, Luca Marseiler, Guillermo Bueno, Alexander Brunst-Zöllner.\n\n^____________________________\n\n**Kaiserslautern**\n\nJulian Krahl, Boris Tomiak, Almamy Touré, Jannis Heuer, Luca Sirch, Filip Kaloc, Daisuke Yokota, Florian Kleinhansl, Frank Ronstadt, Marlon Ritter, Daniel Hanslik.\n\n**Subs:** Tobias Raschl, Leon Robinson, Richmond Tachie, Fabian Heck, Aremu Afeez, Aaron Opoku, Erik Wekesser, Jan Gyamerah, Jannik Mause.\n\n------------\n\n[](#icon-net-big) **MATCH EVENTS** | *via [ESPN](http://www.espn.com/soccer/match?gameId=711945)*\n\n\n\n\n\n--------\n\n*^(Don't see a thread for a match you're watching?) [^(Click here)](https://www.reddit.com/r/soccer/wiki/matchthreads#wiki_match_thread_bot) ^(to learn how to request a match thread from this bot.)*|0                         |0                          |soccer   |19         |7          |2024-12-14 19:41:40.331448|
+-------+----------------------------------------------------------------------+--------------+-------------------+-------+---------+------------+-----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------+---------------------------+---------+-----------+-----------+--------------------------+
only showing top 2 rows
[2024-12-14T19:41:42.740+0000] {docker.py:413} INFO - 24/12/14 19:41:42 INFO CodeGenerator: Code generated in 26.02934 ms
[2024-12-14T19:41:42.893+0000] {docker.py:413} INFO - 24/12/14 19:41:42 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
[2024-12-14T19:41:42.897+0000] {docker.py:413} INFO - 24/12/14 19:41:42 INFO DAGScheduler: Registering RDD 54 (start at NativeMethodAccessorImpl.java:0) as input to shuffle 10
[2024-12-14T19:41:42.900+0000] {docker.py:413} INFO - 24/12/14 19:41:42 INFO DAGScheduler: Got job 9 (start at NativeMethodAccessorImpl.java:0) with 200 output partitions
24/12/14 19:41:42 INFO DAGScheduler: Final stage: ResultStage 22 (start at NativeMethodAccessorImpl.java:0)
24/12/14 19:41:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
[2024-12-14T19:41:42.901+0000] {docker.py:413} INFO - 24/12/14 19:41:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 21)
[2024-12-14T19:41:42.903+0000] {docker.py:413} INFO - 24/12/14 19:41:42 INFO DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[54] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-12-14T19:41:42.909+0000] {docker.py:413} INFO - 24/12/14 19:41:42 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 52.7 KiB, free 433.9 MiB)
[2024-12-14T19:41:42.913+0000] {docker.py:413} INFO - 24/12/14 19:41:42 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 20.2 KiB, free 433.9 MiB)
[2024-12-14T19:41:42.915+0000] {docker.py:413} INFO - 24/12/14 19:41:42 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on localhost:32963 (size: 20.2 KiB, free: 434.2 MiB)
[2024-12-14T19:41:42.916+0000] {docker.py:413} INFO - 24/12/14 19:41:42 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1580
[2024-12-14T19:41:42.917+0000] {docker.py:413} INFO - 24/12/14 19:41:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[54] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/12/14 19:41:42 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks resource profile 0
[2024-12-14T19:41:42.919+0000] {docker.py:413} INFO - 24/12/14 19:41:42 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 816) (localhost, executor driver, partition 0, PROCESS_LOCAL, 10838 bytes)
[2024-12-14T19:41:42.921+0000] {docker.py:413} INFO - 24/12/14 19:41:42 INFO Executor: Running task 0.0 in stage 21.0 (TID 816)
[2024-12-14T19:41:42.936+0000] {docker.py:413} INFO - 24/12/14 19:41:42 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=reddit_data-0 fromOffset=0 untilOffset=650, for query queryId=380f0ba5-0895-4b92-9659-cdf82c87bac4 batchId=0 taskId=816 partitionId=0
[2024-12-14T19:41:42.943+0000] {docker.py:413} INFO - 24/12/14 19:41:42 INFO KafkaConsumer: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to offset 0 for partition reddit_data-0
[2024-12-14T19:41:42.954+0000] {docker.py:413} INFO - 24/12/14 19:41:42 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to earliest offset of partition reddit_data-0
[2024-12-14T19:41:42.957+0000] {docker.py:413} INFO - 24/12/14 19:41:42 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Resetting offset for partition reddit_data-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 0 rack: null)], epoch=32}}.
24/12/14 19:41:42 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to latest offset of partition reddit_data-0
[2024-12-14T19:41:42.961+0000] {docker.py:413} INFO - 24/12/14 19:41:42 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Resetting offset for partition reddit_data-0 to position FetchPosition{offset=650, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 0 rack: null)], epoch=32}}.
[2024-12-14T19:41:42.986+0000] {docker.py:413} INFO - 24/12/14 19:41:42 INFO KafkaConsumer: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to offset 500 for partition reddit_data-0
[2024-12-14T19:41:42.988+0000] {docker.py:413} INFO - 24/12/14 19:41:42 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to earliest offset of partition reddit_data-0
[2024-12-14T19:41:43.492+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Resetting offset for partition reddit_data-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 0 rack: null)], epoch=32}}.
24/12/14 19:41:43 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Seeking to latest offset of partition reddit_data-0
[2024-12-14T19:41:43.494+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO SubscriptionState: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Resetting offset for partition reddit_data-0 to position FetchPosition{offset=650, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 0 rack: null)], epoch=32}}.
[2024-12-14T19:41:43.547+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO BlockManagerInfo: Removed broadcast_14_piece0 on localhost:32963 in memory (size: 5.9 KiB, free: 434.3 MiB)
[2024-12-14T19:41:43.558+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO BlockManagerInfo: Removed broadcast_15_piece0 on localhost:32963 in memory (size: 20.2 KiB, free: 434.3 MiB)
[2024-12-14T19:41:43.567+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO KafkaDataConsumer: From Kafka topicPartition=reddit_data-0 groupId=reddit_processor_group read 650 records through 2 polls (polled  out 650 records), taking 527981452 nanos, during time span of 623894782 nanos.
[2024-12-14T19:41:43.569+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO BlockManagerInfo: Removed broadcast_18_piece0 on localhost:32963 in memory (size: 27.4 KiB, free: 434.3 MiB)
[2024-12-14T19:41:43.571+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO Executor: Finished task 0.0 in stage 21.0 (TID 816). 2710 bytes result sent to driver
[2024-12-14T19:41:43.572+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 816) in 652 ms on localhost (executor driver) (1/1)
24/12/14 19:41:43 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool
[2024-12-14T19:41:43.574+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO DAGScheduler: ShuffleMapStage 21 (start at NativeMethodAccessorImpl.java:0) finished in 0.667 s
[2024-12-14T19:41:43.576+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO DAGScheduler: looking for newly runnable stages
[2024-12-14T19:41:43.577+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO DAGScheduler: running: Set()
24/12/14 19:41:43 INFO DAGScheduler: waiting: Set(ResultStage 22)
[2024-12-14T19:41:43.578+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO DAGScheduler: failed: Set()
[2024-12-14T19:41:43.580+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[61] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-12-14T19:41:43.581+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO BlockManagerInfo: Removed broadcast_16_piece0 on localhost:32963 in memory (size: 27.4 KiB, free: 434.3 MiB)
[2024-12-14T19:41:43.584+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO BlockManagerInfo: Removed broadcast_17_piece0 on localhost:32963 in memory (size: 27.4 KiB, free: 434.4 MiB)
[2024-12-14T19:41:43.623+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 81.0 KiB, free 434.2 MiB)
[2024-12-14T19:41:43.626+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 31.8 KiB, free 434.1 MiB)
[2024-12-14T19:41:43.628+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on localhost:32963 (size: 31.8 KiB, free: 434.3 MiB)
[2024-12-14T19:41:43.630+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1580
[2024-12-14T19:41:43.631+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 22 (MapPartitionsRDD[61] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
24/12/14 19:41:43 INFO TaskSchedulerImpl: Adding task set 22.0 with 200 tasks resource profile 0
[2024-12-14T19:41:43.636+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 817) (localhost, executor driver, partition 0, NODE_LOCAL, 9963 bytes) 
24/12/14 19:41:43 INFO TaskSetManager: Starting task 3.0 in stage 22.0 (TID 818) (localhost, executor driver, partition 3, NODE_LOCAL, 9963 bytes)
[2024-12-14T19:41:43.639+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO TaskSetManager: Starting task 4.0 in stage 22.0 (TID 819) (localhost, executor driver, partition 4, NODE_LOCAL, 9963 bytes)
[2024-12-14T19:41:43.641+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO TaskSetManager: Starting task 5.0 in stage 22.0 (TID 820) (localhost, executor driver, partition 5, NODE_LOCAL, 9963 bytes)
[2024-12-14T19:41:43.643+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO TaskSetManager: Starting task 6.0 in stage 22.0 (TID 821) (localhost, executor driver, partition 6, NODE_LOCAL, 9963 bytes)
[2024-12-14T19:41:43.644+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO TaskSetManager: Starting task 7.0 in stage 22.0 (TID 822) (localhost, executor driver, partition 7, NODE_LOCAL, 9963 bytes)
[2024-12-14T19:41:43.645+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO TaskSetManager: Starting task 8.0 in stage 22.0 (TID 823) (localhost, executor driver, partition 8, NODE_LOCAL, 9963 bytes)
[2024-12-14T19:41:43.647+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO TaskSetManager: Starting task 9.0 in stage 22.0 (TID 824) (localhost, executor driver, partition 9, NODE_LOCAL, 9963 bytes) 
24/12/14 19:41:43 INFO TaskSetManager: Starting task 12.0 in stage 22.0 (TID 825) (localhost, executor driver, partition 12, NODE_LOCAL, 9963 bytes)
[2024-12-14T19:41:43.650+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO TaskSetManager: Starting task 14.0 in stage 22.0 (TID 826) (localhost, executor driver, partition 14, NODE_LOCAL, 9963 bytes)
[2024-12-14T19:41:43.652+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO TaskSetManager: Starting task 16.0 in stage 22.0 (TID 827) (localhost, executor driver, partition 16, NODE_LOCAL, 9963 bytes)
[2024-12-14T19:41:43.655+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO TaskSetManager: Starting task 19.0 in stage 22.0 (TID 828) (localhost, executor driver, partition 19, NODE_LOCAL, 9963 bytes)
[2024-12-14T19:41:43.656+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO TaskSetManager: Starting task 22.0 in stage 22.0 (TID 829) (localhost, executor driver, partition 22, NODE_LOCAL, 9963 bytes)
[2024-12-14T19:41:43.660+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO TaskSetManager: Starting task 25.0 in stage 22.0 (TID 830) (localhost, executor driver, partition 25, NODE_LOCAL, 9963 bytes)
[2024-12-14T19:41:43.662+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO TaskSetManager: Starting task 26.0 in stage 22.0 (TID 831) (localhost, executor driver, partition 26, NODE_LOCAL, 9963 bytes)
[2024-12-14T19:41:43.664+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO TaskSetManager: Starting task 29.0 in stage 22.0 (TID 832) (localhost, executor driver, partition 29, NODE_LOCAL, 9963 bytes)
[2024-12-14T19:41:43.665+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO Executor: Running task 7.0 in stage 22.0 (TID 822)
24/12/14 19:41:43 INFO Executor: Running task 6.0 in stage 22.0 (TID 821)
[2024-12-14T19:41:43.673+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO Executor: Running task 0.0 in stage 22.0 (TID 817)
24/12/14 19:41:43 INFO Executor: Running task 5.0 in stage 22.0 (TID 820)
24/12/14 19:41:43 INFO Executor: Running task 9.0 in stage 22.0 (TID 824)
[2024-12-14T19:41:43.675+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO Executor: Running task 12.0 in stage 22.0 (TID 825)
[2024-12-14T19:41:43.677+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO Executor: Running task 22.0 in stage 22.0 (TID 829)
[2024-12-14T19:41:43.678+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO Executor: Running task 26.0 in stage 22.0 (TID 831)
24/12/14 19:41:43 INFO Executor: Running task 3.0 in stage 22.0 (TID 818)
24/12/14 19:41:43 INFO Executor: Running task 25.0 in stage 22.0 (TID 830)
[2024-12-14T19:41:43.679+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO Executor: Running task 4.0 in stage 22.0 (TID 819)
[2024-12-14T19:41:43.680+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO Executor: Running task 8.0 in stage 22.0 (TID 823)
[2024-12-14T19:41:43.681+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO Executor: Running task 19.0 in stage 22.0 (TID 828)
24/12/14 19:41:43 INFO Executor: Running task 16.0 in stage 22.0 (TID 827)
24/12/14 19:41:43 INFO Executor: Running task 29.0 in stage 22.0 (TID 832)
24/12/14 19:41:43 INFO Executor: Running task 14.0 in stage 22.0 (TID 826)
[2024-12-14T19:41:43.817+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:43 INFO ShuffleBlockFetcherIterator: Getting 1 (2.0 KiB) non-empty blocks including 1 (2.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:43 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:43 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:43 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:43.826+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/12/14 19:41:43 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:43 INFO ShuffleBlockFetcherIterator: Getting 1 (2.0 KiB) non-empty blocks including 1 (2.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:43 INFO ShuffleBlockFetcherIterator: Getting 1 (2.7 KiB) non-empty blocks including 1 (2.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:43 INFO ShuffleBlockFetcherIterator: Getting 1 (1399.0 B) non-empty blocks including 1 (1399.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:43 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/12/14 19:41:43 INFO ShuffleBlockFetcherIterator: Getting 1 (1538.0 B) non-empty blocks including 1 (1538.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/12/14 19:41:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:43 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:43.830+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO ShuffleBlockFetcherIterator: Getting 1 (1692.0 B) non-empty blocks including 1 (1692.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:43.831+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/12/14 19:41:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:43.833+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO ShuffleBlockFetcherIterator: Getting 1 (1538.0 B) non-empty blocks including 1 (1538.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:43.834+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:43.835+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:43.840+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
24/12/14 19:41:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2024-12-14T19:41:43.841+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2024-12-14T19:41:43.843+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2024-12-14T19:41:43.846+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
24/12/14 19:41:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2024-12-14T19:41:43.848+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO ShuffleBlockFetcherIterator: Getting 1 (1271.0 B) non-empty blocks including 1 (1271.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:43.851+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:43.889+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO CodeGenerator: Code generated in 31.055373 ms
[2024-12-14T19:41:43.945+0000] {docker.py:413} INFO - 24/12/14 19:41:43 INFO CodeGenerator: Code generated in 37.313783 ms
[2024-12-14T19:41:44.359+0000] {docker.py:413} INFO - 24/12/14 19:41:44 ERROR Executor: Exception in task 16.0 in stage 22.0 (TID 827)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he490n','Sandhausen [3]-5 Erzgebirge Aue - Dominic Baumann 76''','suedney','2024-12-14 14:41:04+00'::timestamp,5,0,1,5,'',1,0,'soccer',14,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he490n) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he490n) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more
[2024-12-14T19:41:44.369+0000] {docker.py:413} INFO - 24/12/14 19:41:44 ERROR Executor: Exception in task 19.0 in stage 22.0 (TID 828)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he69mz','Newcastle [4] - 0 Leicester - J. Murphy 60''','etclassico','2024-12-14 16:17:04+00'::timestamp,9,0,4,9,'',4,0,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he69mz) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he69mz) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more
[2024-12-14T19:41:44.374+0000] {docker.py:413} INFO - 24/12/14 19:41:44 ERROR Executor: Exception in task 25.0 in stage 22.0 (TID 830)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season?more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more
24/12/14 19:41:44 ERROR Executor: Exception in task 3.0 in stage 22.0 (TID 818)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he4d2b','Augsburg 0 - [1] Bayer Leverkusen - Martin Terrier 14''','Dahleb','2024-12-14 14:45:20+00'::timestamp,25,0,4,25,'',4,0,'soccer',14,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he4d2b) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he4d2b) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more
24/12/14 19:41:44 ERROR Executor: Exception in task 6.0 in stage 22.0 (TID 821)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he0j1x','UK TV Games & What to Watch: Sunday 15th December','JammyMoore','2024-12-14 10:52:48+00'::timestamp,2,0,1,2,'Looking at the games on **Sunday 15th December** that are available to watch in the UK. Where to watch them and what I would watch!

Early risers can watch a tasty match from the Australian **A-League**. Newly founded **Auckland FC** are 6 wins from 6 games this season, and they travel to the seasoned **Melbourne City**.

Next up is a double header of **Serie A** matches. A relegation scrap as **Lecce**, sitting 1 point outside the drop zone face **Monza** sitting in 19th. Followed up by Derby dell'' Appennino, as Vincenzo Italiano''s **Bologna** host his former club **Fiorentina**.

The match of the day is the Manchester Derby in the **Premier League**. Out of form **Manchester City** take on a new form **Manchester United** under Ruben Amorim.

To round of the day, a big showdown in **Ligue 1**. League leaders **PSG** take on a revived **Lyon** in what surely will be a tasty match.

|Time|Fixture|Competition|Provider / Channel|
|:-|:-|:-|:-|
|06:00|Melbourne City v Auckland FC|A-League Men|TNT Sports 1|
|11:30|Lecce v Monza|Serie A|OneFootball|
|14:00|Bologna v Fiorentina|Serie A|OneFootball|
|16:30|Manchester City v Manchester United|Premier League|Sky Sports Main Event / Sky Sports Premier League / Sky Sports Ultra HDR|
|19:45|PSG v Lyon|Ligue 1|Ligue 1 Pass|

',1,0,'soccer',10,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he0j1x) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he0j1x) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more
24/12/14 19:41:44 ERROR Executor: Exception in task 26.0 in stage 22.0 (TID 831)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1hdvj0t','Daily Discussion','AutoModerator','2024-12-14 05:02:56+00'::timestamp,8,0,94,8,'##Welcome to the r/soccer Daily Discussion! 
  
###?? This is a thread for:  
  
* Discussion points that aren''t worthy of their own thread.   
* Asking small questions about football to the community.
* if you''re new to the subreddit, remember to get your **team crest** [here](https://www.reddit.com/r/soccer/wiki/set_flair) and to [read our rules and submission guidelines](/r/soccer/wiki/rules#wiki_community_rules)! 
 
---- 
    
###? This is **not** a thread for:  
  
* Comments that aren''t related to football.  
* Trolling or baiting other users or fanbases.  
* Comments about an ongoing game better suited for the Match Thread.   
* Shitposting, brigading or excessive meta discussion.      
* Any other kind of toxic or unreasonable behaviour.     
   
The moderation team will **remove** comments that violate those rules and **ban** persistent offenders.   
  
Please report comments you think that break such rules, but more than anything else, **remember the human**. The Internet is full of places to discuss football in bad faith. This community tries to be an exception.  
  
----  
  
###? Can''t find a Match Thread?  
  
* If you are using Old Reddit [click this link](https://old.reddit.com/r/soccer/search?q=flair%3Amatch%2Bthread+AND+NOT+flair%3Apost+AND+NOT+flair%3Apre&restrict_sr=on&sort=new&t=day#res-hide-options).  
* If you are using New Reddit you need to try [this other one.](https://new.reddit.com/r/soccer/search/?q=match%20thread&restrict_sr=1&sr_nsfw=&sort=new)  
* If you are using the official app [press here](https://new.reddit.com/r/soccer/search/?q=match%20thread&restrict_sr=1&sr_nsfw=&sort=new) and sort by "new".  
* If you'' are using a third-party app... ?\\_(?)_/?
  
If there''s no Match Thread for the match you''re watching you can:    

* [Create one](https://www.reddit.com/r/soccer/wiki/matchthreads) yourself.    
* Ask /u/MatchThreadder for one. You just need to send a PM to him with the subject "Match Thread" and the body "Team A vs Team B" (for example, "Inter Milan vs. Udinese") to get one from this great bot ?   

----  

###? Other useful quick links:  
  
? [**Star Posts**](https://www.reddit.com/r/soccer/search?sort=new&restrict_sr=on&q=flair%3A%E2%AD%90%2BStar%2BPost): the original content by those users that give their best to our community.   

? [**What to Watch**](https://www.reddit.com/r/soccer/search?sort=new&restrict_sr=on&q=flair%3A%F0%9F%93%BAWhat%2Bto%2BWatch): quick but extremely-useful guides of next matches.     

? [**Non-PL Daily Discussion**](https://www.reddit.com/r/soccer/search?sort=new&restrict_sr=on&q=flair%3A%F0%9F%8C%8D%F0%9F%8C%8E%2BWorld%2BFootball%2B): for small discussions and questions about everything but the English Premier League.     

? [**Serious Discussion**](https://www.reddit.com/r/soccer/search?sort=new&restrict_sr=on&q=flair%3ASerious): for high-quality discussion threads about certain topics.   

? [**Women''s Football**](https://www.reddit.com/r/soccer/search?sort=new&restrict_sr=on&q=flair%3AWomens%2BFootball): for women''s football content.    
  

? [**Ping Groups**](https://www.reddit.com/r/soccer/wiki/userpinger/documentation): Join a ping group, our new system to find the content you want to see!  ([Explanation here](https://www.reddit.com/r/soccer/comments/u8qwe8/user_ping_groups_introducing_a_new_system_to_find/))


----

*This thread is posted every 23 hours to give it a different start time each day.*',24,45,'soccer',5,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1hdvj0t) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1hdvj0t) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more
24/12/14 19:41:44 ERROR Executor: Exception in task 12.0 in stage 22.0 (TID 825)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he54ln','Cagliari 0 - [1] Atalanta - Nicolo Zaniolo 66''','Dahleb','2024-12-14 15:23:44+00',24,0,4,24,'',2,1,'soccer',15,7,'2024-12-14 19:41:42.641826+00') was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he54ln) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he54ln) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more
[2024-12-14T19:41:44.381+0000] {docker.py:413} INFO - 24/12/14 19:41:44 ERROR Executor: Exception in task 29.0 in stage 22.0 (TID 832)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he9egm','Udinese 1-[3] Napoli - Frank Anguissa 81''','MeladroitsTV','2024-12-14 18:44:16+00',28,0,5,28,'',5,0,'soccer',18,7,'2024-12-14 19:41:42.641826+00') was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he9egm) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he9egm) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more
[2024-12-14T19:41:44.386+0000] {docker.py:413} INFO - 24/12/14 19:41:44 ERROR Executor: Exception in task 22.0 in stage 22.0 (TID 829)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he7rpx','Alanyaspor 1-0 Gaziantep - Fidan Aliti 54''','MeladroitsTV','2024-12-14 17:27:28+00',3,0,1,3,'',1,0,'soccer',17,7,'2024-12-14 19:41:42.641826+00') was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he7rpx) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he7rpx) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more
[2024-12-14T19:41:44.391+0000] {docker.py:413} INFO - 24/12/14 19:41:44 ERROR Executor: Exception in task 8.0 in stage 22.0 (TID 823)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1hea5dj','Gasperini after Atalanta win against Cagliari 0-1: "Zaniolo keeps taunting the opposition with his goal celebrations. It''s happened twice already. Cagliari were stunned and he rekindled them. It''s intolerable."','Blodgharm','2024-12-14 19:18:24+00',24,0,3,24,'',2,1,'soccer',19,7,'2024-12-14 19:41:42.641826+00') was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1hea5dj) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1hea5dj) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more
24/12/14 19:41:44 ERROR Executor: Exception in task 14.0 in stage 22.0 (TID 826)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he6xdk','Arsenal penalty shout against Everton 90''','slimcase121','2024-12-14 16:49:04+00',0,0,101,0,'',46,18,'soccer',16,7,'2024-12-14 19:41:42.641826+00') was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he6xdk) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he6xdk) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more
24/12/14 19:41:44 ERROR Executor: Exception in task 5.0 in stage 22.0 (TID 820)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he7180','Post Match Thread: 1. FC Union Berlin 1-1 VfL Bochum | German Bundesliga','suedney','2024-12-14 16:53:20+00',13,0,17,13,'
#**FT: 1. FC Union Berlin  [1-1](#bar-3-white)  VfL Bochum**





--------

**Venue:** An der alten F?rsterei

[Auto-refreshing reddit comments link](http://www.reddit-stream.com/comments/1he3zyy)

---------

[](#icon-notes-big) **LINE-UPS**

**1. FC Union Berlin**

Frederik Ronnow, Kevin Vogt, Diogo Leite, Danilho Doekhi, Rani Khedira ([](#icon-sub)Yorbe Vertessen), Andr?s Sch?fer ([](#icon-sub)Aljoscha Kemlein), Tom Rothe ([](#icon-sub)Janik Haberer), Robert Skov, Tim Skarke ([](#icon-sub)Jordan Pefok), Benedict Hollerbach, Jeong Woo-Yeong ([](#icon-sub)L?szl? B?nes).

**Subs:** Alexander Schwolow, Christopher Trimmel, J?r?me Roussillon, Leopold Querfeld.

^____________________________

**VfL Bochum**

Patrick Drewes, Ivan Ordets, Bernardo, Tim Oermann, Ibrahima Sissoko ([](#icon-sub)Dani de Wit), Mat?s Bero, Maximilian Wittek ([](#icon-sub)Jakov Medic), Felix Passlack, Moritz Broschinski ([](#icon-sub)Philipp Hofmann), Gerrit Holtmann ([](#icon-sub)Anthony Losilla), Koji Miyoshi.

**Subs:** Mats Pannewig, Myron Boadu, Lukas Daschner, Noah Loosli, Timo Horn.

------------

[](#icon-net-big) **MATCH EVENTS** | *via [ESPN](http://www.espn.com/soccer/match?gameId=711556)*



**13''** [](#icon-red) Koji Miyoshi (VfL Bochum 1848) is shown the red card.

**23''** [](#icon-ball) **Goal! 1. FC Union Berlin 0, VfL Bochum 1848 1. Ibrahima Sissoko (VfL Bochum 1848) header from the centre of the box to the bottom right corner. Assisted by Felix Passlack with a cross.**

**33''** [](#icon-ball) **Goal! 1. FC Union Berlin 1, VfL Bochum 1848 1. Benedict Hollerbach (1. FC Union Berlin) left footed shot from the centre of the box to the bottom left corner. Assisted by Robert Skov.**

**37''** [](#icon-yellow) Benedict Hollerbach (1. FC Union Berlin) is shown the yellow card.

**37''** [](#icon-sub) Substitution, VfL Bochum 1848. Anthony Losilla replaces Gerrit Holtmann.

**50''** [](#icon-yellow) Moritz Broschinski (VfL Bochum 1848) is shown the yellow card for a bad foul.

**56''** [](#icon-sub) Substitution, 1. FC Union Berlin. Jordan Siebatcheu replaces Tim Skarke.

**67''** [](#icon-yellow) Kevin Vogt (1. FC Union Berlin) is shown the yellow card for a bad foul.

**68''** [](#icon-sub) Substitution, 1. FC Union Berlin. Aljoscha Kemlein replaces Andr?s Sch?fer.

**68''** [](#icon-sub) Substitution, 1. FC Union Berlin. L?szl? B?nes replaces Jeong Wooyeong.

**74''** [](#icon-sub) Substitution, VfL Bochum 1848. Jakov Medic replaces Maximilian Wittek.

**80''** [](#icon-sub) Substitution, 1. FC Union Berlin. Janik Haberer replaces Tom Rothe.

**80''** [](#icon-sub) Substitution, 1. FC Union Berlin. Yorbe Vertessen replaces Rani Khedira.

**89''** [](#icon-sub) Substitution, VfL Bochum 1848. Philipp Hofmann replaces Moritz Broschinski.

**89''** [](#icon-sub) Substitution, VfL Bochum 1848. Dani de Wit replaces Ibrahima Sissoko.

**90''+1''** [](#icon-yellow) Patrick Drewes (VfL Bochum 1848) is shown the yellow card.



--------

*^(Don''t see a thread for a match you''re watching?) [^(Click here)](https://www.reddit.com/r/soccer/wiki/matchthreads#wiki_match_thread_bot) ^(to learn how to request a match thread from this bot.)*',5,4,'soccer',16,7,'2024-12-14 19:41:42.641826+00') was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he7180) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he7180) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more
[2024-12-14T19:41:44.401+0000] {docker.py:413} INFO - 24/12/14 19:41:44 ERROR Executor: Exception in task 9.0 in stage 22.0 (TID 824)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1hdyl2v','[BBC] Heartwarming throwback to when Ian Wright reunited with former football teacher Mr. Pigden (1922?2017) who he thought had passed away','thebelsnickle1991','2024-12-14 08:34:08+00'::timestamp,1280,0,62,1280,'',31,17,'soccer',8,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1hdyl2v) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1hdyl2v) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more
[2024-12-14T19:41:44.407+0000] {docker.py:413} INFO - 24/12/14 19:41:44 ERROR Executor: Exception in task 4.0 in stage 22.0 (TID 819)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he7260','Post Match Thread: Arsenal 0-0 Everton | English Premier League','suedney','2024-12-14 16:53:20+00',216,0,537,216,'

#**FT: Arsenal  [0-0](#bar-3-white)  Everton**





--------

**Venue:** Emirates Stadium

[Auto-refreshing reddit comments link](http://www.reddit-stream.com/comments/1he4mq1)

---------

[](#icon-notes-big) **LINE-UPS**

**Arsenal**

David Raya, Gabriel Magalh?es, William Saliba, Myles Lewis-Skelly ([](#icon-sub)Thomas Partey), Jurri?n Timber, Declan Rice ([](#icon-sub)Jorginho ), Mikel Merino ([](#icon-sub)Gabriel Jesus), Martin ?degaard ([](#icon-sub)Ethan Nwaneri), Kai Havertz, Gabriel Martinelli ([](#icon-sub)Leandro Trossard), Bukayo Saka.

**Subs:** Jakub Kiwior, Kieran Tierney, Raheem Sterling, Neto .

^____________________________

**Everton**

Jordan Pickford, Jarrad Branthwaite, James Tarkowski, Vitaliy Mykolenko, Ashley Young, Idrissa Gueye, Abdoulaye Doucour?, Orel Mangala, Dominic Calvert-Lewin ([](#icon-sub)Armando Broja), Iliman Ndiaye, Jack Harrison ([](#icon-sub)Jesper Lindstrom).

**Subs:** Jo?o Virg?nia, Seamus Coleman, Harrison Armstrong, Beto , Nathan Patterson, Michael Keane, Jake O&#x27;Brien.

------------

[](#icon-net-big) **MATCH EVENTS** | *via [ESPN](http://www.espn.com/soccer/match?gameId=704429)*



**62''** [](#icon-sub) Substitution, Arsenal. Jorginho replaces Declan Rice.

**62''** [](#icon-sub) Substitution, Arsenal. Ethan Nwaneri replaces Martin ?degaard.

**66''** [](#icon-sub) Substitution, Everton. Armando Broja replaces Dominic Calvert-Lewin.

**66''** [](#icon-sub) Substitution, Everton. Jesper Lindstr?m replaces Jack Harrison.

**69''** [](#icon-sub) Substitution, Arsenal. Gabriel Jesus replaces Mikel Merino.

**69''** [](#icon-sub) Substitution, Arsenal. Thomas Partey replaces Myles Lewis-Skelly.

**72''** [](#icon-yellow) Ashley Young (Everton) is shown the yellow card for a bad foul.

**74''** [](#icon-sub) Substitution, Arsenal. Leandro Trossard replaces Gabriel Martinelli.

**77''** [](#icon-yellow) Jordan Pickford (Everton) is shown the yellow card.

**81''** [](#icon-yellow) Armando Broja (Everton) is shown the yellow card.



--------

*^(Don''t see a thread for a match you''re watching?) [^(Click here)](https://www.reddit.com/r/soccer/wiki/matchthreads#wiki_match_thread_bot) ^(to learn how to request a match thread from this bot.)*',196,160,'soccer',16,7,'2024-12-14 19:41:42.641826+00') was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he7260) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he7260) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more
[2024-12-14T19:41:44.415+0000] {docker.py:413} INFO - 24/12/14 19:41:44 ERROR Executor: Exception in task 0.0 in stage 22.0 (TID 817)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he62zw','Newcastle [3] - 0 Leicester - A. Isak 50''','etclassico','2024-12-14 16:08:32+00'::timestamp,31,0,15,31,'',7,5,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he62zw) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he62zw) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more
[2024-12-14T19:41:44.424+0000] {docker.py:413} INFO - 24/12/14 19:41:44 ERROR Executor: Exception in task 7.0 in stage 22.0 (TID 822)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he9ki3','Emiliano Mart?nez save against Nottingham Forest 60''','slimcase121','2024-12-14 18:50:40+00',540,0,110,540,'',83,13,'soccer',18,7,'2024-12-14 19:41:42.641826+00') was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he9ki3) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he9ki3) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more
[2024-12-14T19:41:44.438+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO TaskSetManager: Starting task 31.0 in stage 22.0 (TID 833) (localhost, executor driver, partition 31, NODE_LOCAL, 9963 bytes)
[2024-12-14T19:41:44.445+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO Executor: Running task 31.0 in stage 22.0 (TID 833)
[2024-12-14T19:41:44.448+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO TaskSetManager: Starting task 32.0 in stage 22.0 (TID 834) (localhost, executor driver, partition 32, NODE_LOCAL, 9963 bytes)
[2024-12-14T19:41:44.452+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO Executor: Running task 32.0 in stage 22.0 (TID 834)
[2024-12-14T19:41:44.456+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO TaskSetManager: Starting task 34.0 in stage 22.0 (TID 835) (localhost, executor driver, partition 34, NODE_LOCAL, 9963 bytes)
[2024-12-14T19:41:44.458+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO Executor: Running task 34.0 in stage 22.0 (TID 835)
[2024-12-14T19:41:44.461+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO TaskSetManager: Starting task 35.0 in stage 22.0 (TID 836) (localhost, executor driver, partition 35, NODE_LOCAL, 9963 bytes)
[2024-12-14T19:41:44.468+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO Executor: Running task 35.0 in stage 22.0 (TID 836)
24/12/14 19:41:44 INFO TaskSetManager: Starting task 39.0 in stage 22.0 (TID 837) (localhost, executor driver, partition 39, NODE_LOCAL, 9963 bytes)
[2024-12-14T19:41:44.471+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO Executor: Running task 39.0 in stage 22.0 (TID 837)
[2024-12-14T19:41:44.475+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO TaskSetManager: Starting task 40.0 in stage 22.0 (TID 838) (localhost, executor driver, partition 40, NODE_LOCAL, 9963 bytes)
[2024-12-14T19:41:44.476+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO TaskSetManager: Starting task 42.0 in stage 22.0 (TID 839) (localhost, executor driver, partition 42, NODE_LOCAL, 9963 bytes)
[2024-12-14T19:41:44.514+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO Executor: Running task 42.0 in stage 22.0 (TID 839)
[2024-12-14T19:41:44.521+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO TaskSetManager: Starting task 43.0 in stage 22.0 (TID 840) (localhost, executor driver, partition 43, NODE_LOCAL, 9963 bytes) 
24/12/14 19:41:44 INFO Executor: Running task 40.0 in stage 22.0 (TID 838)
[2024-12-14T19:41:44.535+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO Executor: Running task 43.0 in stage 22.0 (TID 840)
[2024-12-14T19:41:44.537+0000] {docker.py:413} INFO - 24/12/14 19:41:44 WARN TaskSetManager: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season?more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more
[2024-12-14T19:41:44.548+0000] {docker.py:413} INFO - 24/12/14 19:41:44 ERROR TaskSetManager: Task 25 in stage 22.0 failed 1 times; aborting job
[2024-12-14T19:41:44.553+0000] {docker.py:413} INFO - 24/12/14 19:41:44 WARN TaskSetManager: Lost task 19.0 in stage 22.0 (TID 828) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he69mz','Newcastle [4] - 0 Leicester - J. Murphy 60''','etclassico','2024-12-14 16:17:04+00'::timestamp,9,0,4,9,'',4,0,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he69mz) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he69mz) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more
[2024-12-14T19:41:44.557+0000] {docker.py:413} INFO - 24/12/14 19:41:44 WARN TaskSetManager: Lost task 5.0 in stage 22.0 (TID 820) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he7180','Post Match Thread: 1. FC Union Berlin 1-1 VfL Bochum | German Bundesliga','suedney','2024-12-14 16:53:20+00',13,0,17,13,'
#**FT: 1. FC Union Berlin  [1-1](#bar-3-white)  VfL Bochum**





--------

**Venue:** An der alten F?rsterei

[Auto-refreshing reddit comments link](http://www.reddit-stream.com/comments/1he3zyy)

---------

[](#icon-notes-big) **LINE-UPS**

**1. FC Union Berlin**

Frederik Ronnow, Kevin Vogt, Diogo Leite, Danilho Doekhi, Rani Khedira ([](#icon-sub)Yorbe Vertessen), Andr?s Sch?fer ([](#icon-sub)Aljoscha Kemlein), Tom Rothe ([](#icon-sub)Janik Haberer), Robert Skov, Tim Skarke ([](#icon-sub)Jordan Pefok), Benedict Hollerbach, Jeong Woo-Yeong ([](#icon-sub)L?szl? B?nes).

**Subs:** Alexander Schwolow, Christopher Trimmel, J?r?me Roussillon, Leopold Querfeld.

^____________________________

**VfL Bochum**

Patrick Drewes, Ivan Ordets, Bernardo, Tim Oermann, Ibrahima Sissoko ([](#icon-sub)Dani de Wit), Mat?s Bero, Maximilian Wittek ([](#icon-sub)Jakov Medic), Felix Passlack, Moritz Broschinski ([](#icon-sub)Philipp Hofmann), Gerrit Holtmann ([](#icon-sub)Anthony Losilla), Koji Miyoshi.

**Subs:** Mats Pannewig, Myron Boadu, Lukas Daschner, Noah Loosli, Timo Horn.

------------

[](#icon-net-big) **MATCH EVENTS** | *via [ESPN](http://www.espn.com/soccer/match?gameId=711556)*



**13''** [](#icon-red) Koji Miyoshi (VfL Bochum 1848) is shown the red card.

**23''** [](#icon-ball) **Goal! 1. FC Union Berlin 0, VfL Bochum 1848 1. Ibrahima Sissoko (VfL Bochum 1848) header from the centre of the box to the bottom right corner. Assisted by Felix Passlack with a cross.**

**33''** [](#icon-ball) **Goal! 1. FC Union Berlin 1, VfL Bochum 1848 1. Benedict Hollerbach (1. FC Union Berlin) left footed shot from the centre of the box to the bottom left corner. Assisted by Robert Skov.**

**37''** [](#icon-yellow) Benedict Hollerbach (1. FC Union Berlin) is shown the yellow card.

**37''** [](#icon-sub) Substitution, VfL Bochum 1848. Anthony Losilla replaces Gerrit Holtmann.

**50''** [](#icon-yellow) Moritz Broschinski (VfL Bochum 1848) is shown the yellow card for a bad foul.

**56''** [](#icon-sub) Substitution, 1. FC Union Berlin. Jordan Siebatcheu replaces Tim Skarke.

**67''** [](#icon-yellow) Kevin Vogt (1. FC Union Berlin) is shown the yellow card for a bad foul.

**68''** [](#icon-sub) Substitution, 1. FC Union Berlin. Aljoscha Kemlein replaces Andr?s Sch?fer.

**68''** [](#icon-sub) Substitution, 1. FC Union Berlin. L?szl? B?nes replaces Jeong Wooyeong.

**74''** [](#icon-sub) Substitution, VfL Bochum 1848. Jakov Medic replaces Maximilian Wittek.

**80''** [](#icon-sub) Substitution, 1. FC Union Berlin. Janik Haberer replaces Tom Rothe.

**80''** [](#icon-sub) Substitution, 1. FC Union Berlin. Yorbe Vertessen replaces Rani Khedira.

**89''** [](#icon-sub) Substitution, VfL Bochum 1848. Philipp Hofmann replaces Moritz Broschinski.

**89''** [](#icon-sub) Substitution, VfL Bochum 1848. Dani de Wit replaces Ibrahima Sissoko.

**90''+1''** [](#icon-yellow) Patrick Drewes (VfL Bochum 1848) is shown the yellow card.



--------

*^(Don''t see a thread for a match you''re watching?) [^(Click here)](https://www.reddit.com/r/soccer/wiki/matchthreads#wiki_match_thread_bot) ^(to learn how to request a match thread from this bot.)*',5,4,'soccer',16,7,'2024-12-14 19:41:42.641826+00') was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he7180) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he7180) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more
[2024-12-14T19:41:44.565+0000] {docker.py:413} INFO - 24/12/14 19:41:44 WARN TaskSetManager: Lost task 29.0 in stage 22.0 (TID 832) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he9egm','Udinese 1-[3] Napoli - Frank Anguissa 81''','MeladroitsTV','2024-12-14 18:44:16+00',28,0,5,28,'',5,0,'soccer',18,7,'2024-12-14 19:41:42.641826+00') was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he9egm) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he9egm) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more
[2024-12-14T19:41:44.569+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO TaskSchedulerImpl: Cancelling stage 22
[2024-12-14T19:41:44.577+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage cancelled: Job aborted due to stage failure: Task 25 in stage 22.0 failed 1 times, most recent failure: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season?more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Driver stacktrace:
[2024-12-14T19:41:44.582+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO Executor: Executor is trying to kill task 35.0 in stage 22.0 (TID 836), reason: Stage cancelled: Job aborted due to stage failure: Task 25 in stage 22.0 failed 1 times, most recent failure: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season?more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Driver stacktrace:
[2024-12-14T19:41:44.585+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO Executor: Executor is trying to kill task 39.0 in stage 22.0 (TID 837), reason: Stage cancelled: Job aborted due to stage failure: Task 25 in stage 22.0 failed 1 times, most recent failure: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season?more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Driver stacktrace:
[2024-12-14T19:41:44.590+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO Executor: Executor is trying to kill task 40.0 in stage 22.0 (TID 838), reason: Stage cancelled: Job aborted due to stage failure: Task 25 in stage 22.0 failed 1 times, most recent failure: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season?more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Driver stacktrace:
[2024-12-14T19:41:44.593+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO TaskSchedulerImpl: Stage 22 was cancelled
[2024-12-14T19:41:44.595+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO Executor: Executor is trying to kill task 42.0 in stage 22.0 (TID 839), reason: Stage cancelled: Job aborted due to stage failure: Task 25 in stage 22.0 failed 1 times, most recent failure: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season?more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Driver stacktrace:
24/12/14 19:41:44 INFO Executor: Executor is trying to kill task 43.0 in stage 22.0 (TID 840), reason: Stage cancelled: Job aborted due to stage failure: Task 25 in stage 22.0 failed 1 times, most recent failure: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season?more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Driver stacktrace:
[2024-12-14T19:41:44.602+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO Executor: Executor is trying to kill task 31.0 in stage 22.0 (TID 833), reason: Stage cancelled: Job aborted due to stage failure: Task 25 in stage 22.0 failed 1 times, most recent failure: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season?more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Driver stacktrace:
[2024-12-14T19:41:44.607+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO Executor: Executor is trying to kill task 32.0 in stage 22.0 (TID 834), reason: Stage cancelled: Job aborted due to stage failure: Task 25 in stage 22.0 failed 1 times, most recent failure: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season?more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Driver stacktrace:
[2024-12-14T19:41:44.609+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO Executor: Executor is trying to kill task 34.0 in stage 22.0 (TID 835), reason: Stage cancelled: Job aborted due to stage failure: Task 25 in stage 22.0 failed 1 times, most recent failure: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season?more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Driver stacktrace:
[2024-12-14T19:41:44.613+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO ShuffleBlockFetcherIterator: Getting 1 (717.0 B) non-empty blocks including 1 (717.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:44.615+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:44.617+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO ShuffleBlockFetcherIterator: Getting 1 (2.0 KiB) non-empty blocks including 1 (2.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:44.619+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:44.621+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO DAGScheduler: ResultStage 22 (start at NativeMethodAccessorImpl.java:0) failed in 0.970 s due to Job aborted due to stage failure: Task 25 in stage 22.0 failed 1 times, most recent failure: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season?more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Driver stacktrace:
[2024-12-14T19:41:44.624+0000] {docker.py:413} INFO - 24/12/14 19:41:44 WARN TaskSetManager: Lost task 26.0 in stage 22.0 (TID 831) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1hdvj0t','Daily Discussion','AutoModerator','2024-12-14 05:02:56+00'::timestamp,8,0,94,8,'##Welcome to the r/soccer Daily Discussion! 
  
###?? This is a thread for:  
  
* Discussion points that aren''t worthy of their own thread.   
* Asking small questions about football to the community.
* if you''re new to the subreddit, remember to get your **team crest** [here](https://www.reddit.com/r/soccer/wiki/set_flair) and to [read our rules and submission guidelines](/r/soccer/wiki/rules#wiki_community_rules)! 
 
---- 
    
###? This is **not** a thread for:  
  
* Comments that aren''t related to football.  
* Trolling or baiting other users or fanbases.  
* Comments about an ongoing game better suited for the Match Thread.   
* Shitposting, brigading or excessive meta discussion.      
* Any other kind of toxic or unreasonable behaviour.     
   
The moderation team will **remove** comments that violate those rules and **ban** persistent offenders.   
  
Please report comments you think that break such rules, but more than anything else, **remember the human**. The Internet is full of places to discuss football in bad faith. This community tries to be an exception.  
  
----  
  
###? Can''t find a Match Thread?  
  
* If you are using Old Reddit [click this link](https://old.reddit.com/r/soccer/search?q=flair%3Amatch%2Bthread+AND+NOT+flair%3Apost+AND+NOT+flair%3Apre&restrict_sr=on&sort=new&t=day#res-hide-options).  
* If you are using New Reddit you need to try [this other one.](https://new.reddit.com/r/soccer/search/?q=match%20thread&restrict_sr=1&sr_nsfw=&sort=new)  
* If you are using the official app [press here](https://new.reddit.com/r/soccer/search/?q=match%20thread&restrict_sr=1&sr_nsfw=&sort=new) and sort by "new".  
* If you'' are using a third-party app... ?\\_(?)_/?
  
If there''s no Match Thread for the match you''re watching you can:    

* [Create one](https://www.reddit.com/r/soccer/wiki/matchthreads) yourself.    
* Ask /u/MatchThreadder for one. You just need to send a PM to him with the subject "Match Thread" and the body "Team A vs Team B" (for example, "Inter Milan vs. Udinese") to get one from this great bot ?   

----  

###? Other useful quick links:  
  
? [**Star Posts**](https://www.reddit.com/r/soccer/search?sort=new&restrict_sr=on&q=flair%3A%E2%AD%90%2BStar%2BPost): the original content by those users that give their best to our community.   

? [**What to Watch**](https://www.reddit.com/r/soccer/search?sort=new&restrict_sr=on&q=flair%3A%F0%9F%93%BAWhat%2Bto%2BWatch): quick but extremely-useful guides of next matches.     

? [**Non-PL Daily Discussion**](https://www.reddit.com/r/soccer/search?sort=new&restrict_sr=on&q=flair%3A%F0%9F%8C%8D%F0%9F%8C%8E%2BWorld%2BFootball%2B): for small discussions and questions about everything but the English Premier League.     

? [**Serious Discussion**](https://www.reddit.com/r/soccer/search?sort=new&restrict_sr=on&q=flair%3ASerious): for high-quality discussion threads about certain topics.   

? [**Women''s Football**](https://www.reddit.com/r/soccer/search?sort=new&restrict_sr=on&q=flair%3AWomens%2BFootball): for women''s football content.    
  

? [**Ping Groups**](https://www.reddit.com/r/soccer/wiki/userpinger/documentation): Join a ping group, our new system to find the content you want to see!  ([Explanation here](https://www.reddit.com/r/soccer/comments/u8qwe8/user_ping_groups_introducing_a_new_system_to_find/))


----

*This thread is posted every 23 hours to give it a different start time each day.*',24,45,'soccer',5,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1hdvj0t) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1hdvj0t) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

24/12/14 19:41:44 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2024-12-14T19:41:44.627+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2024-12-14T19:41:44.629+0000] {docker.py:413} INFO - 24/12/14 19:41:44 ERROR ShuffleBlockFetcherIterator: Error occurred while fetching local blocks, null
24/12/14 19:41:44 ERROR ShuffleBlockFetcherIterator: Error occurred while fetching local blocks, null
24/12/14 19:41:44 ERROR ShuffleBlockFetcherIterator: Error occurred while fetching local blocks, null
[2024-12-14T19:41:44.630+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:44 INFO ShuffleBlockFetcherIterator: Getting 1 (1538.0 B) non-empty blocks including 1 (1538.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:44 ERROR ShuffleBlockFetcherIterator: Error occurred while fetching local blocks, null
[2024-12-14T19:41:44.631+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO ShuffleBlockFetcherIterator: Getting 1 (1862.0 B) non-empty blocks including 1 (1862.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:44 ERROR ShuffleBlockFetcherIterator: Error occurred while fetching local blocks, null
24/12/14 19:41:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/12/14 19:41:44 ERROR ShuffleBlockFetcherIterator: Error occurred while fetching local blocks, null
[2024-12-14T19:41:44.632+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:44.634+0000] {docker.py:413} INFO - 24/12/14 19:41:44 ERROR ShuffleBlockFetcherIterator: Error occurred while fetching local blocks, null
24/12/14 19:41:44 WARN TaskSetManager: Lost task 7.0 in stage 22.0 (TID 822) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he9ki3','Emiliano Mart?nez save against Nottingham Forest 60''','slimcase121','2024-12-14 18:50:40+00',540,0,110,540,'',83,13,'soccer',18,7,'2024-12-14 19:41:42.641826+00') was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he9ki3) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he9ki3) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more
[2024-12-14T19:41:44.637+0000] {docker.py:413} INFO - 24/12/14 19:41:44 WARN TaskSetManager: Lost task 8.0 in stage 22.0 (TID 823) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1hea5dj','Gasperini after Atalanta win against Cagliari 0-1: "Zaniolo keeps taunting the opposition with his goal celebrations. It''s happened twice already. Cagliari were stunned and he rekindled them. It''s intolerable."','Blodgharm','2024-12-14 19:18:24+00',24,0,3,24,'',2,1,'soccer',19,7,'2024-12-14 19:41:42.641826+00') was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1hea5dj) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1hea5dj) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

24/12/14 19:41:44 WARN TaskSetManager: Lost task 12.0 in stage 22.0 (TID 825) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he54ln','Cagliari 0 - [1] Atalanta - Nicolo Zaniolo 66''','Dahleb','2024-12-14 15:23:44+00',24,0,4,24,'',2,1,'soccer',15,7,'2024-12-14 19:41:42.641826+00') was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he54ln) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he54ln) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more
[2024-12-14T19:41:44.641+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/12/14 19:41:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2024-12-14T19:41:44.644+0000] {docker.py:413} INFO - 24/12/14 19:41:44 ERROR ShuffleBlockFetcherIterator: Error occurred while fetching local blocks, null
[2024-12-14T19:41:44.646+0000] {docker.py:413} INFO - 24/12/14 19:41:44 WARN TaskSetManager: Lost task 16.0 in stage 22.0 (TID 827) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he490n','Sandhausen [3]-5 Erzgebirge Aue - Dominic Baumann 76''','suedney','2024-12-14 14:41:04+00'::timestamp,5,0,1,5,'',1,0,'soccer',14,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he490n) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he490n) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more
[2024-12-14T19:41:44.649+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO Executor: Executor interrupted and killed task 43.0 in stage 22.0 (TID 840), reason: Stage cancelled: Job aborted due to stage failure: Task 25 in stage 22.0 failed 1 times, most recent failure: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season?more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Driver stacktrace:
[2024-12-14T19:41:44.652+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO Executor: Executor interrupted and killed task 34.0 in stage 22.0 (TID 835), reason: Stage cancelled: Job aborted due to stage failure: Task 25 in stage 22.0 failed 1 times, most recent failure: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season?more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Driver stacktrace:
[2024-12-14T19:41:44.654+0000] {docker.py:413} INFO - 24/12/14 19:41:44 WARN TaskSetManager: Lost task 4.0 in stage 22.0 (TID 819) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he7260','Post Match Thread: Arsenal 0-0 Everton | English Premier League','suedney','2024-12-14 16:53:20+00',216,0,537,216,'

#**FT: Arsenal  [0-0](#bar-3-white)  Everton**





--------

**Venue:** Emirates Stadium

[Auto-refreshing reddit comments link](http://www.reddit-stream.com/comments/1he4mq1)

---------

[](#icon-notes-big) **LINE-UPS**

**Arsenal**

David Raya, Gabriel Magalh?es, William Saliba, Myles Lewis-Skelly ([](#icon-sub)Thomas Partey), Jurri?n Timber, Declan Rice ([](#icon-sub)Jorginho ), Mikel Merino ([](#icon-sub)Gabriel Jesus), Martin ?degaard ([](#icon-sub)Ethan Nwaneri), Kai Havertz, Gabriel Martinelli ([](#icon-sub)Leandro Trossard), Bukayo Saka.

**Subs:** Jakub Kiwior, Kieran Tierney, Raheem Sterling, Neto .

^____________________________

**Everton**

Jordan Pickford, Jarrad Branthwaite, James Tarkowski, Vitaliy Mykolenko, Ashley Young, Idrissa Gueye, Abdoulaye Doucour?, Orel Mangala, Dominic Calvert-Lewin ([](#icon-sub)Armando Broja), Iliman Ndiaye, Jack Harrison ([](#icon-sub)Jesper Lindstrom).

**Subs:** Jo?o Virg?nia, Seamus Coleman, Harrison Armstrong, Beto , Nathan Patterson, Michael Keane, Jake O&#x27;Brien.

------------

[](#icon-net-big) **MATCH EVENTS** | *via [ESPN](http://www.espn.com/soccer/match?gameId=704429)*



**62''** [](#icon-sub) Substitution, Arsenal. Jorginho replaces Declan Rice.

**62''** [](#icon-sub) Substitution, Arsenal. Ethan Nwaneri replaces Martin ?degaard.

**66''** [](#icon-sub) Substitution, Everton. Armando Broja replaces Dominic Calvert-Lewin.

**66''** [](#icon-sub) Substitution, Everton. Jesper Lindstr?m replaces Jack Harrison.

**69''** [](#icon-sub) Substitution, Arsenal. Gabriel Jesus replaces Mikel Merino.

**69''** [](#icon-sub) Substitution, Arsenal. Thomas Partey replaces Myles Lewis-Skelly.

**72''** [](#icon-yellow) Ashley Young (Everton) is shown the yellow card for a bad foul.

**74''** [](#icon-sub) Substitution, Arsenal. Leandro Trossard replaces Gabriel Martinelli.

**77''** [](#icon-yellow) Jordan Pickford (Everton) is shown the yellow card.

**81''** [](#icon-yellow) Armando Broja (Everton) is shown the yellow card.



--------

*^(Don''t see a thread for a match you''re watching?) [^(Click here)](https://www.reddit.com/r/soccer/wiki/matchthreads#wiki_match_thread_bot) ^(to learn how to request a match thread from this bot.)*',196,160,'soccer',16,7,'2024-12-14 19:41:42.641826+00') was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he7260) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he7260) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more
[2024-12-14T19:41:44.656+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO Executor: Executor interrupted and killed task 39.0 in stage 22.0 (TID 837), reason: Stage cancelled: Job aborted due to stage failure: Task 25 in stage 22.0 failed 1 times, most recent failure: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season?more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Driver stacktrace:
24/12/14 19:41:44 INFO Executor: Executor interrupted and killed task 40.0 in stage 22.0 (TID 838), reason: Stage cancelled: Job aborted due to stage failure: Task 25 in stage 22.0 failed 1 times, most recent failure: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season?more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Driver stacktrace:
[2024-12-14T19:41:44.660+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO DAGScheduler: Job 9 failed: start at NativeMethodAccessorImpl.java:0, took 1.692644 s
[2024-12-14T19:41:44.661+0000] {docker.py:413} INFO - 24/12/14 19:41:44 WARN TaskSetManager: Lost task 9.0 in stage 22.0 (TID 824) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1hdyl2v','[BBC] Heartwarming throwback to when Ian Wright reunited with former football teacher Mr. Pigden (1922?2017) who he thought had passed away','thebelsnickle1991','2024-12-14 08:34:08+00'::timestamp,1280,0,62,1280,'',31,17,'soccer',8,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1hdyl2v) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1hdyl2v) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more
[2024-12-14T19:41:44.663+0000] {docker.py:413} INFO - 24/12/14 19:41:44 WARN TaskSetManager: Lost task 3.0 in stage 22.0 (TID 818) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he4d2b','Augsburg 0 - [1] Bayer Leverkusen - Martin Terrier 14''','Dahleb','2024-12-14 14:45:20+00'::timestamp,25,0,4,25,'',4,0,'soccer',14,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he4d2b) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he4d2b) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more
[2024-12-14T19:41:44.665+0000] {docker.py:413} INFO - 24/12/14 19:41:44 WARN TaskSetManager: Lost task 0.0 in stage 22.0 (TID 817) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he62zw','Newcastle [3] - 0 Leicester - A. Isak 50''','etclassico','2024-12-14 16:08:32+00'::timestamp,31,0,15,31,'',7,5,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he62zw) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he62zw) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more
[2024-12-14T19:41:44.667+0000] {docker.py:413} INFO - 24/12/14 19:41:44 WARN TaskSetManager: Lost task 14.0 in stage 22.0 (TID 826) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he6xdk','Arsenal penalty shout against Everton 90''','slimcase121','2024-12-14 16:49:04+00',0,0,101,0,'',46,18,'soccer',16,7,'2024-12-14 19:41:42.641826+00') was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he6xdk) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he6xdk) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more
[2024-12-14T19:41:44.669+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO Executor: Executor interrupted and killed task 32.0 in stage 22.0 (TID 834), reason: Stage cancelled: Job aborted due to stage failure: Task 25 in stage 22.0 failed 1 times, most recent failure: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season?more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Driver stacktrace:
24/12/14 19:41:44 INFO Executor: Executor interrupted and killed task 42.0 in stage 22.0 (TID 839), reason: Stage cancelled: Job aborted due to stage failure: Task 25 in stage 22.0 failed 1 times, most recent failure: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season?more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Driver stacktrace:
24/12/14 19:41:44 INFO Executor: Executor interrupted and killed task 35.0 in stage 22.0 (TID 836), reason: Stage cancelled: Job aborted due to stage failure: Task 25 in stage 22.0 failed 1 times, most recent failure: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season?more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Driver stacktrace:
[2024-12-14T19:41:44.671+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO Executor: Executor interrupted and killed task 31.0 in stage 22.0 (TID 833), reason: Stage cancelled: Job aborted due to stage failure: Task 25 in stage 22.0 failed 1 times, most recent failure: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season?more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Driver stacktrace:
24/12/14 19:41:44 WARN TaskSetManager: Lost task 6.0 in stage 22.0 (TID 821) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he0j1x','UK TV Games & What to Watch: Sunday 15th December','JammyMoore','2024-12-14 10:52:48+00'::timestamp,2,0,1,2,'Looking at the games on **Sunday 15th December** that are available to watch in the UK. Where to watch them and what I would watch!

Early risers can watch a tasty match from the Australian **A-League**. Newly founded **Auckland FC** are 6 wins from 6 games this season, and they travel to the seasoned **Melbourne City**.

Next up is a double header of **Serie A** matches. A relegation scrap as **Lecce**, sitting 1 point outside the drop zone face **Monza** sitting in 19th. Followed up by Derby dell'' Appennino, as Vincenzo Italiano''s **Bologna** host his former club **Fiorentina**.

The match of the day is the Manchester Derby in the **Premier League**. Out of form **Manchester City** take on a new form **Manchester United** under Ruben Amorim.

To round of the day, a big showdown in **Ligue 1**. League leaders **PSG** take on a revived **Lyon** in what surely will be a tasty match.

|Time|Fixture|Competition|Provider / Channel|
|:-|:-|:-|:-|
|06:00|Melbourne City v Auckland FC|A-League Men|TNT Sports 1|
|11:30|Lecce v Monza|Serie A|OneFootball|
|14:00|Bologna v Fiorentina|Serie A|OneFootball|
|16:30|Manchester City v Manchester United|Premier League|Sky Sports Main Event / Sky Sports Premier League / Sky Sports Ultra HDR|
|19:45|PSG v Lyon|Ligue 1|Ligue 1 Pass|

',1,0,'soccer',10,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he0j1x) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he0j1x) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more
[2024-12-14T19:41:44.674+0000] {docker.py:413} INFO - 24/12/14 19:41:44 WARN TaskSetManager: Lost task 22.0 in stage 22.0 (TID 829) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he7rpx','Alanyaspor 1-0 Gaziantep - Fidan Aliti 54''','MeladroitsTV','2024-12-14 17:27:28+00',3,0,1,3,'',1,0,'soccer',17,7,'2024-12-14 19:41:42.641826+00') was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he7rpx) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he7rpx) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more
[2024-12-14T19:41:44.676+0000] {docker.py:413} INFO - 24/12/14 19:41:44 WARN TaskSetManager: Lost task 39.0 in stage 22.0 (TID 837) (localhost executor driver): TaskKilled (Stage cancelled: Job aborted due to stage failure: Task 25 in stage 22.0 failed 1 times, most recent failure: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season?more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Driver stacktrace:)
[2024-12-14T19:41:44.678+0000] {docker.py:413} INFO - 24/12/14 19:41:44 WARN TaskSetManager: Lost task 42.0 in stage 22.0 (TID 839) (localhost executor driver): TaskKilled (Stage cancelled: Job aborted due to stage failure: Task 25 in stage 22.0 failed 1 times, most recent failure: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season?more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Driver stacktrace:)
[2024-12-14T19:41:44.679+0000] {docker.py:413} INFO - 24/12/14 19:41:44 WARN TaskSetManager: Lost task 34.0 in stage 22.0 (TID 835) (localhost executor driver): TaskKilled (Stage cancelled: Job aborted due to stage failure: Task 25 in stage 22.0 failed 1 times, most recent failure: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season?more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Driver stacktrace:)
[2024-12-14T19:41:44.681+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool
[2024-12-14T19:41:44.683+0000] {docker.py:413} INFO - 24/12/14 19:41:44 WARN TaskSetManager: Lost task 40.0 in stage 22.0 (TID 838) (localhost executor driver): TaskKilled (Stage cancelled: Job aborted due to stage failure: Task 25 in stage 22.0 failed 1 times, most recent failure: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season?more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Driver stacktrace:)
24/12/14 19:41:44 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool
[2024-12-14T19:41:44.685+0000] {docker.py:413} INFO - 24/12/14 19:41:44 WARN TaskSetManager: Lost task 32.0 in stage 22.0 (TID 834) (localhost executor driver): TaskKilled (Stage cancelled: Job aborted due to stage failure: Task 25 in stage 22.0 failed 1 times, most recent failure: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season?more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Driver stacktrace:)
[2024-12-14T19:41:44.686+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool
[2024-12-14T19:41:44.687+0000] {docker.py:413} INFO - 24/12/14 19:41:44 WARN TaskSetManager: Lost task 43.0 in stage 22.0 (TID 840) (localhost executor driver): TaskKilled (Stage cancelled: Job aborted due to stage failure: Task 25 in stage 22.0 failed 1 times, most recent failure: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season?more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Driver stacktrace:)
[2024-12-14T19:41:44.689+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool
[2024-12-14T19:41:44.691+0000] {docker.py:413} INFO - 24/12/14 19:41:44 WARN TaskSetManager: Lost task 31.0 in stage 22.0 (TID 833) (localhost executor driver): TaskKilled (Stage cancelled: Job aborted due to stage failure: Task 25 in stage 22.0 failed 1 times, most recent failure: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season?more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Driver stacktrace:)
[2024-12-14T19:41:44.693+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
24/12/14 19:41:44 WARN TaskSetManager: Lost task 35.0 in stage 22.0 (TID 836) (localhost executor driver): TaskKilled (Stage cancelled: Job aborted due to stage failure: Task 25 in stage 22.0 failed 1 times, most recent failure: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season?more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Driver stacktrace:)
[2024-12-14T19:41:44.695+0000] {docker.py:413} INFO - 24/12/14 19:41:44 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool
[2024-12-14T19:41:45.101+0000] {docker.py:413} INFO - 2024-12-14 19:41:45,038 [ERROR] Failed to save to PostgreSQL table reddit_posts: An error occurred while calling o105.save.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 25 in stage 22.0 failed 1 times, most recent failure: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season—more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1036)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
	at org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1034)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:901)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)
	at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:384)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)
	at org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)
	at org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)
	at org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)
	at org.apache.spark.sql.execution.streaming.SingleBatchExecutor.execute(TriggerExecutor.scala:39)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)
	at org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)
Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season—more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more
Traceback (most recent call last):
  File "/opt/bitnami/spark/transformation.py", line 453, in save_to_***
    .save()
     ^^^^^^
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 1461, in save
    self._jwrite.save()
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 179, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
    raise Py4JJavaError(
py4j.protocol.Py4JJavaError: An error occurred while calling o105.save.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 25 in stage 22.0 failed 1 times, most recent failure: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season—more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1036)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
	at org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1034)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:901)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)
	at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:384)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)
	at org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)
	at org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)
	at org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)
	at org.apache.spark.sql.execution.streaming.SingleBatchExecutor.execute(TriggerExecutor.scala:39)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)
	at org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)
Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season—more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more
[2024-12-14T19:41:45.191+0000] {docker.py:413} INFO - 2024-12-14 19:41:45,142 [ERROR] Error processing batch 0: An error occurred while calling o105.save.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 25 in stage 22.0 failed 1 times, most recent failure: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season—more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1036)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
	at org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1034)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:901)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)
	at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:384)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)
	at org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)
	at org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)
	at org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)
	at org.apache.spark.sql.execution.streaming.SingleBatchExecutor.execute(TriggerExecutor.scala:39)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)
	at org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)
Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season—more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more
Traceback (most recent call last):
  File "/opt/bitnami/spark/spark_streaming.py", line 293, in process_batch
    transformer.save_to_***(posts_df, "reddit_posts")
  File "/opt/bitnami/spark/transformation.py", line 458, in save_to_***
    raise e
  File "/opt/bitnami/spark/transformation.py", line 453, in save_to_***
    .save()
     ^^^^^^
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 1461, in save
    self._jwrite.save()
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 179, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
    raise Py4JJavaError(
py4j.protocol.Py4JJavaError: An error occurred while calling o105.save.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 25 in stage 22.0 failed 1 times, most recent failure: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season—more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1036)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
	at org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1034)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:901)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)
	at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:384)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)
	at org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)
	at org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)
	at org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)
	at org.apache.spark.sql.execution.streaming.SingleBatchExecutor.execute(TriggerExecutor.scala:39)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)
	at org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)
Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season—more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more
[2024-12-14T19:41:45.238+0000] {docker.py:413} INFO - 2024-12-14 19:41:45,188 [ERROR] There was an exception while executing the Python Proxy on the Python Side.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 617, in _call_proxy
    return_value = getattr(self.pool[obj_id], method)(*params)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 120, in call
    raise e
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in call
    self.func(DataFrame(jdf, wrapped_session_jdf), batch_id)
  File "/opt/bitnami/spark/spark_streaming.py", line 333, in process_batch
    raise e
  File "/opt/bitnami/spark/spark_streaming.py", line 293, in process_batch
    transformer.save_to_***(posts_df, "reddit_posts")
  File "/opt/bitnami/spark/transformation.py", line 458, in save_to_***
    raise e
  File "/opt/bitnami/spark/transformation.py", line 453, in save_to_***
    .save()
     ^^^^^^
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 1461, in save
    self._jwrite.save()
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 179, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
    raise Py4JJavaError(
py4j.protocol.Py4JJavaError: An error occurred while calling o105.save.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 25 in stage 22.0 failed 1 times, most recent failure: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season—more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1036)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
	at org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1034)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:901)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)
	at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:384)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)
	at org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)
	at org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)
	at org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)
	at org.apache.spark.sql.execution.streaming.SingleBatchExecutor.execute(TriggerExecutor.scala:39)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)
	at org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)
Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season—more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more
[2024-12-14T19:41:45.291+0000] {docker.py:413} INFO - 24/12/14 19:41:45 ERROR MicroBatchExecution: Query [id = 380f0ba5-0895-4b92-9659-cdf82c87bac4, runId = 119abbaf-fc84-434b-a8d5-63f33c113a14] terminated with error
py4j.Py4JException: An exception was raised by the Python Proxy. Return Message: Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 617, in _call_proxy
    return_value = getattr(self.pool[obj_id], method)(*params)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 120, in call
    raise e
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in call
    self.func(DataFrame(jdf, wrapped_session_jdf), batch_id)
  File "/opt/bitnami/spark/spark_streaming.py", line 333, in process_batch
    raise e
  File "/opt/bitnami/spark/spark_streaming.py", line 293, in process_batch
    transformer.save_to_***(posts_df, "reddit_posts")
  File "/opt/bitnami/spark/transformation.py", line 458, in save_to_***
    raise e
  File "/opt/bitnami/spark/transformation.py", line 453, in save_to_***
    .save()
     ^^^^^^
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 1461, in save
    self._jwrite.save()
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 179, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
    raise Py4JJavaError(
py4j.protocol.Py4JJavaError: An error occurred while calling o105.save.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 25 in stage 22.0 failed 1 times, most recent failure: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season?more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1036)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
	at org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1034)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:901)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)
	at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:384)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)
	at org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)
	at org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)
	at org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)
	at org.apache.spark.sql.execution.streaming.SingleBatchExecutor.execute(TriggerExecutor.scala:39)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)
	at org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)
Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season?more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more


	at py4j.Protocol.getReturnValue(Protocol.java:476)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:108)
	at jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)
	at org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)
	at org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)
	at org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)
	at org.apache.spark.sql.execution.streaming.SingleBatchExecutor.execute(TriggerExecutor.scala:39)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)
	at org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)
[2024-12-14T19:41:45.293+0000] {docker.py:413} INFO - 24/12/14 19:41:45 INFO AppInfoParser: App info kafka.admin.client for adminclient-1 unregistered
[2024-12-14T19:41:45.302+0000] {docker.py:413} INFO - 24/12/14 19:41:45 INFO Metrics: Metrics scheduler closed
24/12/14 19:41:45 INFO Metrics: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[2024-12-14T19:41:45.306+0000] {docker.py:413} INFO - 24/12/14 19:41:45 INFO Metrics: Metrics reporters closed
[2024-12-14T19:41:45.307+0000] {docker.py:413} INFO - 24/12/14 19:41:45 INFO MicroBatchExecution: Async log purge executor pool for query [id = 380f0ba5-0895-4b92-9659-cdf82c87bac4, runId = 119abbaf-fc84-434b-a8d5-63f33c113a14] has been shutdown
[2024-12-14T19:41:45.620+0000] {docker.py:413} INFO - 2024-12-14 19:41:45,607 [ERROR] Error in stream processing: [STREAM_FAILED] Query [id = 380f0ba5-0895-4b92-9659-cdf82c87bac4, runId = 119abbaf-fc84-434b-a8d5-63f33c113a14] terminated with exception: An exception was raised by the Python Proxy. Return Message: Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 617, in _call_proxy
    return_value = getattr(self.pool[obj_id], method)(*params)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 120, in call
    raise e
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in call
    self.func(DataFrame(jdf, wrapped_session_jdf), batch_id)
  File "/opt/bitnami/spark/spark_streaming.py", line 333, in process_batch
    raise e
  File "/opt/bitnami/spark/spark_streaming.py", line 293, in process_batch
    transformer.save_to_***(posts_df, "reddit_posts")
  File "/opt/bitnami/spark/transformation.py", line 458, in save_to_***
    raise e
  File "/opt/bitnami/spark/transformation.py", line 453, in save_to_***
    .save()
     ^^^^^^
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 1461, in save
    self._jwrite.save()
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 179, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
    raise Py4JJavaError(
py4j.protocol.Py4JJavaError: An error occurred while calling o105.save.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 25 in stage 22.0 failed 1 times, most recent failure: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season—more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1036)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
	at org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1034)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:901)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)
	at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:384)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)
	at org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)
	at org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)
	at org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)
	at org.apache.spark.sql.execution.streaming.SingleBatchExecutor.execute(TriggerExecutor.scala:39)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)
	at org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)
Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season—more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Traceback (most recent call last):
  File "/opt/bitnami/spark/spark_streaming.py", line 346, in process_stream
    query.awaitTermination()
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/query.py", line 221, in awaitTermination
    return self._jsq.awaitTermination()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 185, in deco
    raise converted from None
pyspark.errors.exceptions.captured.StreamingQueryException: [STREAM_FAILED] Query [id = 380f0ba5-0895-4b92-9659-cdf82c87bac4, runId = 119abbaf-fc84-434b-a8d5-63f33c113a14] terminated with exception: An exception was raised by the Python Proxy. Return Message: Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 617, in _call_proxy
    return_value = getattr(self.pool[obj_id], method)(*params)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 120, in call
    raise e
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in call
    self.func(DataFrame(jdf, wrapped_session_jdf), batch_id)
  File "/opt/bitnami/spark/spark_streaming.py", line 333, in process_batch
    raise e
  File "/opt/bitnami/spark/spark_streaming.py", line 293, in process_batch
    transformer.save_to_***(posts_df, "reddit_posts")
  File "/opt/bitnami/spark/transformation.py", line 458, in save_to_***
    raise e
  File "/opt/bitnami/spark/transformation.py", line 453, in save_to_***
    .save()
     ^^^^^^
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 1461, in save
    self._jwrite.save()
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 179, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
    raise Py4JJavaError(
py4j.protocol.Py4JJavaError: An error occurred while calling o105.save.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 25 in stage 22.0 failed 1 times, most recent failure: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season—more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1036)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
	at org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1034)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:901)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)
	at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:384)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)
	at org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)
	at org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)
	at org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)
	at org.apache.spark.sql.execution.streaming.SingleBatchExecutor.execute(TriggerExecutor.scala:39)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)
	at org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)
Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 1
[2024-12-14T19:41:45.623+0000] {docker.py:413} INFO - 1 Premier League assists since the beginning of last season—more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more
[2024-12-14T19:41:45.647+0000] {docker.py:413} INFO - 2024-12-14 19:41:45,628 [ERROR] Critical error in main: [STREAM_FAILED] Query [id = 380f0ba5-0895-4b92-9659-cdf82c87bac4, runId = 119abbaf-fc84-434b-a8d5-63f33c113a14] terminated with exception: An exception was raised by the Python Proxy. Return Message: Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 617, in _call_proxy
    return_value = getattr(self.pool[obj_id], method)(*params)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 120, in call
    raise e
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in call
    self.func(DataFrame(jdf, wrapped_session_jdf), batch_id)
  File "/opt/bitnami/spark/spark_streaming.py", line 333, in process_batch
    raise e
  File "/opt/bitnami/spark/spark_streaming.py", line 293, in process_batch
    transformer.save_to_***(posts_df, "reddit_posts")
  File "/opt/bitnami/spark/transformation.py", line 458, in save_to_***
    raise e
  File "/opt/bitnami/spark/transformation.py", line 453, in save_to_***
    .save()
     ^^^^^^
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 1461, in save
    self._jwrite.save()
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 179, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
    raise Py4JJavaError(
py4j.protocol.Py4JJavaError: An error occurred while calling o105.save.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 25 in stage 22.0 failed 1 times, most recent failure: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season—more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1036)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
	at org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1034)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:901)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)
	at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:384)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)
	at org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)
	at org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)
	at org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)
	at org.apache.spark.sql.execution.streaming.SingleBatchExecutor.execute(TriggerExecutor.scala:39)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)
	at org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)
Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season—more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Traceback (most recent call last):
  File "/opt/bitnami/spark/spark_streaming.py", line 359, in main
    process_stream()
  File "/opt/bitnami/spark/spark_streaming.py", line 351, in process_stream
    raise e
  File "/opt/bitnami/spark/spark_streaming.py", line 346, in process_stream
    query.awaitTermination()
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/query.py", line 221, in awaitTermination
    return self._jsq.awaitTermination()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 185, in deco
    raise converted from None
pyspark.errors.exceptions.captured.StreamingQueryException: [STREAM_FAILED] Query [id = 380f0ba5-0895-4b92-9659-cdf82c87bac4, runId = 119abbaf-fc84-434b-a8d5-63f33c113a14] terminated with exception: An exception was raised by the Python Proxy. Return Message: Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 617, in _call_proxy
    return_value = getattr(self.pool[obj_id], method)(*params)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 120, in call
    raise e
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in call
    self.func(DataFrame(jdf, wrapped_session_jdf), batch_id)
  File "/opt/bitnami/spark/spark_streaming.py", line 333, in process_batch
    raise e
  File "/opt/bitnami/spark/spark_streaming.py", line 293, in process_batch
    transformer.save_to_***(posts_df, "reddit_posts")
  File "/opt/bitnami/spark/transformation.py", line 458, in save_to_***
    raise e
  File "/opt/bitnami/spark/transformation.py", line 453, in save_to_***
    .save()
     ^^^^^^
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 1461, in save
    self._jwrite.save()
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 179, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
    raise Py4JJavaError(
py4j.protocol.Py4JJavaError: An error occurred while calling o105.save.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 25 in stage 22.0 failed 1 times, most recent failure: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season—more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1036)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
	at org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1034)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:901)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)
	at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:384)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)
	at org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)
	at org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)
	at org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)
	at org.apache.spark.sql.execution.streaming.SingleBatchExecutor.execute(TriggerExecutor.scala:39)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)
	at org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)
Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_
[2024-12-14T19:41:45.651+0000] {docker.py:413} INFO - level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season—more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more


2024-12-14 19:41:45,643 [INFO] Cleaning up resources...
Traceback (most recent call last):
  File "/opt/bitnami/spark/spark_streaming.py", line 369, in <module>
[2024-12-14T19:41:45.653+0000] {docker.py:413} INFO - main()
  File "/opt/bitnami/spark/spark_streaming.py", line 364, in main
[2024-12-14T19:41:45.654+0000] {docker.py:413} INFO - raise e
  File "/opt/bitnami/spark/spark_streaming.py", line 359, in main
[2024-12-14T19:41:45.654+0000] {docker.py:413} INFO - process_stream()
  File "/opt/bitnami/spark/spark_streaming.py", line 351, in process_stream
[2024-12-14T19:41:45.655+0000] {docker.py:413} INFO - raise e
[2024-12-14T19:41:45.656+0000] {docker.py:413} INFO - File "/opt/bitnami/spark/spark_streaming.py", line 346, in process_stream
[2024-12-14T19:41:45.658+0000] {docker.py:413} INFO - query.awaitTermination()
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/query.py", line 221, in awaitTermination
[2024-12-14T19:41:45.659+0000] {docker.py:413} INFO - File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
[2024-12-14T19:41:45.660+0000] {docker.py:413} INFO - File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 185, in deco
[2024-12-14T19:41:45.661+0000] {docker.py:413} INFO - pyspark.errors.exceptions.captured.StreamingQueryException
[2024-12-14T19:41:45.673+0000] {docker.py:413} INFO - : [STREAM_FAILED] Query [id = 380f0ba5-0895-4b92-9659-cdf82c87bac4, runId = 119abbaf-fc84-434b-a8d5-63f33c113a14] terminated with exception: An exception was raised by the Python Proxy. Return Message: Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 617, in _call_proxy
    return_value = getattr(self.pool[obj_id], method)(*params)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 120, in call
    raise e
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in call
    self.func(DataFrame(jdf, wrapped_session_jdf), batch_id)
  File "/opt/bitnami/spark/spark_streaming.py", line 333, in process_batch
    raise e
  File "/opt/bitnami/spark/spark_streaming.py", line 293, in process_batch
    transformer.save_to_***(posts_df, "reddit_posts")
  File "/opt/bitnami/spark/transformation.py", line 458, in save_to_***
    raise e
  File "/opt/bitnami/spark/transformation.py", line 453, in save_to_***
    .save()
     ^^^^^^
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 1461, in save
    self._jwrite.save()
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 179, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
    raise Py4JJavaError(
py4j.protocol.Py4JJavaError: An error occurred while calling o105.save.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 25 in stage 22.0 failed 1 times, most recent failure: Lost task 25.0 in stage 22.0 (TID 830) (localhost executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season—more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1036)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
	at org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1034)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:901)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)
	at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:384)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at jdk.proxy3/jdk.proxy3.$Proxy30.call(Unknown Source)
	at org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)
	at org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)
	at org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)
	at org.apache.spark.sql.execution.streaming.SingleBatchExecutor.execute(TriggerExecutor.scala:39)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)
	at org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)
Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO reddit_posts ("post_id","title","author","post_time","upvotes","downvotes","num_comments","score","text","first_level_comments_count","second_level_comments_count","subreddit","hour_of_day","day_of_week","created_at") VALUES ('1he61m9','[Opta] Fulham left-back Antonee Robinson has 11 Premier League assists since the beginning of last season—more than any defender in that time-span','nicko_rico','2024-12-14 16:06:24+00'::timestamp,18,0,8,18,'',4,2,'soccer',16,7,'2024-12-14 19:41:42.641826+00'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.  Call getNextException to see other errors in the batch.
	at org.***ql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)
	at org.***ql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:573)
	at org.***ql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:896)
	at org.***ql.jdbc.PgStatement.executeBatch(PgStatement.java:919)
	at org.***ql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1677)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.***ql.util.PSQLException: ERROR: duplicate key value violates unique constraint "reddit_posts_pkey"
  Detail: Key (post_id)=(1he61m9) already exists.
	at org.***ql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)
	at org.***ql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)
	... 21 more
[2024-12-14T19:41:45.676+0000] {docker.py:413} INFO - 2024-12-14 19:41:45,670 [INFO] Closing down clientserver connection
[2024-12-14T19:41:46.287+0000] {docker.py:413} INFO - 24/12/14 19:41:46 INFO ConsumerCoordinator: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Resetting generation and member id due to: consumer pro-actively leaving the group
24/12/14 19:41:46 INFO ConsumerCoordinator: [Consumer clientId=consumer-reddit_processor_group-1, groupId=reddit_processor_group] Request joining group due to: consumer pro-actively leaving the group
[2024-12-14T19:41:46.301+0000] {docker.py:413} INFO - 24/12/14 19:41:46 INFO Metrics: Metrics scheduler closed
24/12/14 19:41:46 INFO Metrics: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[2024-12-14T19:41:46.302+0000] {docker.py:413} INFO - 24/12/14 19:41:46 INFO Metrics: Metrics reporters closed
[2024-12-14T19:41:46.307+0000] {docker.py:413} INFO - 24/12/14 19:41:46 INFO AppInfoParser: App info kafka.consumer for consumer-reddit_processor_group-1 unregistered
[2024-12-14T19:41:46.309+0000] {docker.py:413} INFO - 24/12/14 19:41:46 INFO SparkContext: Invoking stop() from shutdown hook
[2024-12-14T19:41:46.311+0000] {docker.py:413} INFO - 24/12/14 19:41:46 INFO SparkContext: SparkContext is stopping with exitCode 0.
[2024-12-14T19:41:46.367+0000] {docker.py:413} INFO - 24/12/14 19:41:46 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
[2024-12-14T19:41:46.404+0000] {docker.py:413} INFO - 24/12/14 19:41:46 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2024-12-14T19:41:46.451+0000] {docker.py:413} INFO - 24/12/14 19:41:46 INFO MemoryStore: MemoryStore cleared
[2024-12-14T19:41:46.453+0000] {docker.py:413} INFO - 24/12/14 19:41:46 INFO BlockManager: BlockManager stopped
[2024-12-14T19:41:46.467+0000] {docker.py:413} INFO - 24/12/14 19:41:46 INFO BlockManagerMaster: BlockManagerMaster stopped
[2024-12-14T19:41:46.479+0000] {docker.py:413} INFO - 24/12/14 19:41:46 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2024-12-14T19:41:46.510+0000] {docker.py:413} INFO - 24/12/14 19:41:46 INFO SparkContext: Successfully stopped SparkContext
[2024-12-14T19:41:46.512+0000] {docker.py:413} INFO - 24/12/14 19:41:46 INFO ShutdownHookManager: Shutdown hook called
[2024-12-14T19:41:46.513+0000] {docker.py:413} INFO - 24/12/14 19:41:46 INFO ShutdownHookManager: Deleting directory /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4
[2024-12-14T19:41:46.519+0000] {docker.py:413} INFO - 24/12/14 19:41:46 INFO ShutdownHookManager: Deleting directory /tmp/spark-083bbc0f-4c23-4d8c-9986-cd18c1564164
[2024-12-14T19:41:46.527+0000] {docker.py:413} INFO - 24/12/14 19:41:46 INFO ShutdownHookManager: Deleting directory /tmp/spark-5c82c41a-d0d9-40dd-8398-f49fdf5c4eb4/pyspark-7324f706-5cdd-40d1-961b-9e708814250d
[2024-12-14T19:41:47.201+0000] {taskinstance.py:1937} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/docker/api/client.py", line 268, in _raise_for_status
    response.raise_for_status()
  File "/home/airflow/.local/lib/python3.8/site-packages/requests/models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: http://docker-proxy:2375/v1.47/containers/create

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 348, in _run_image
    return self._run_image_with_mounts([*self.mounts, tmp_mount], add_tmp_variable=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 375, in _run_image_with_mounts
    self.container = self.cli.create_container(
  File "/home/airflow/.local/lib/python3.8/site-packages/docker/api/container.py", line 431, in create_container
    return self.create_container_from_config(config, name, platform)
  File "/home/airflow/.local/lib/python3.8/site-packages/docker/api/container.py", line 448, in create_container_from_config
    return self._result(res, True)
  File "/home/airflow/.local/lib/python3.8/site-packages/docker/api/client.py", line 274, in _result
    self._raise_for_status(response)
  File "/home/airflow/.local/lib/python3.8/site-packages/docker/api/client.py", line 270, in _raise_for_status
    raise create_api_error_from_http_exception(e) from e
  File "/home/airflow/.local/lib/python3.8/site-packages/docker/errors.py", line 39, in create_api_error_from_http_exception
    raise cls(e, response=response, explanation=explanation) from e
docker.errors.APIError: 400 Client Error for http://docker-proxy:2375/v1.47/containers/create: Bad Request ("invalid mount config for type "bind": bind source path does not exist: /tmp/airflowtmptrnvp64e")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 486, in execute
    return self._run_image()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 357, in _run_image
    return self._run_image_with_mounts(self.mounts, add_tmp_variable=False)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 421, in _run_image_with_mounts
    raise DockerContainerFailedException(f"Docker container failed: {result!r}", logs=log_lines)
airflow.providers.docker.exceptions.DockerContainerFailedException: Docker container failed: {'StatusCode': 1}
[2024-12-14T19:41:47.215+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=kafka_spark_dag, task_id=pyspark_consumer, execution_date=20241214T193559, start_date=20241214T193948, end_date=20241214T194147
[2024-12-14T19:41:47.254+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 5 for task pyspark_consumer (Docker container failed: {'StatusCode': 1}; 2515)
[2024-12-14T19:41:47.312+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1
[2024-12-14T19:41:47.389+0000] {taskinstance.py:2778} INFO - 0 downstream tasks scheduled from follow-on schedule check
